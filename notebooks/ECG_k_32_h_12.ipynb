{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 32\n",
    "tree_depth = 12\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "train_data_path = r'<>/mitbih_train.csv'  # replace <> with the correct path of the dataset\n",
    "test_data_path = r'<>/mitbih_test.csv'  # replace <> with the correct path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.318262577056885 | KNN Loss: 5.820803642272949 | CLS Loss: 1.497458815574646\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 5.080780982971191 | KNN Loss: 4.2764387130737305 | CLS Loss: 0.8043422698974609\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 4.642612934112549 | KNN Loss: 3.95671010017395 | CLS Loss: 0.6859029531478882\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 4.5135345458984375 | KNN Loss: 3.8869571685791016 | CLS Loss: 0.6265771985054016\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 4.441784858703613 | KNN Loss: 3.8211803436279297 | CLS Loss: 0.6206047534942627\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 4.345569133758545 | KNN Loss: 3.8533806800842285 | CLS Loss: 0.49218854308128357\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 4.419981002807617 | KNN Loss: 3.8789937496185303 | CLS Loss: 0.5409873127937317\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 4.247969150543213 | KNN Loss: 3.846813678741455 | CLS Loss: 0.4011552929878235\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 4.298824310302734 | KNN Loss: 3.8414320945739746 | CLS Loss: 0.4573923647403717\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 4.3548502922058105 | KNN Loss: 3.838470220565796 | CLS Loss: 0.5163798928260803\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 4.230166435241699 | KNN Loss: 3.794656276702881 | CLS Loss: 0.43551039695739746\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 4.240954399108887 | KNN Loss: 3.8630099296569824 | CLS Loss: 0.3779442310333252\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 4.102506637573242 | KNN Loss: 3.798346757888794 | CLS Loss: 0.3041599690914154\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 4.1090779304504395 | KNN Loss: 3.7636618614196777 | CLS Loss: 0.34541594982147217\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 4.174545764923096 | KNN Loss: 3.7737255096435547 | CLS Loss: 0.4008200764656067\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 4.072052478790283 | KNN Loss: 3.7385404109954834 | CLS Loss: 0.33351218700408936\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 4.062241077423096 | KNN Loss: 3.7374205589294434 | CLS Loss: 0.32482048869132996\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 4.096349239349365 | KNN Loss: 3.7354674339294434 | CLS Loss: 0.3608819842338562\n",
      "Epoch: 001, Loss: 4.4192, Train: 0.9190, Valid: 0.9206, Best: 0.9206\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 4.040299415588379 | KNN Loss: 3.7545459270477295 | CLS Loss: 0.2857532501220703\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 4.072932243347168 | KNN Loss: 3.7262771129608154 | CLS Loss: 0.34665489196777344\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 4.00243616104126 | KNN Loss: 3.7018961906433105 | CLS Loss: 0.3005399703979492\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 3.979806661605835 | KNN Loss: 3.711756944656372 | CLS Loss: 0.2680497467517853\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 3.969761848449707 | KNN Loss: 3.7284817695617676 | CLS Loss: 0.24128013849258423\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 3.9837942123413086 | KNN Loss: 3.7285773754119873 | CLS Loss: 0.25521689653396606\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 4.007078170776367 | KNN Loss: 3.730334997177124 | CLS Loss: 0.2767431139945984\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 3.9529552459716797 | KNN Loss: 3.703907012939453 | CLS Loss: 0.24904826283454895\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 3.9403200149536133 | KNN Loss: 3.715059518814087 | CLS Loss: 0.22526058554649353\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 3.9978268146514893 | KNN Loss: 3.7239017486572266 | CLS Loss: 0.2739250361919403\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 3.9779462814331055 | KNN Loss: 3.7421987056732178 | CLS Loss: 0.23574748635292053\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 3.9149484634399414 | KNN Loss: 3.705307960510254 | CLS Loss: 0.2096404880285263\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 3.8794708251953125 | KNN Loss: 3.7084391117095947 | CLS Loss: 0.17103174328804016\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 3.9207420349121094 | KNN Loss: 3.7354769706726074 | CLS Loss: 0.18526512384414673\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 3.8729090690612793 | KNN Loss: 3.696795701980591 | CLS Loss: 0.1761133074760437\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 3.944303512573242 | KNN Loss: 3.6850805282592773 | CLS Loss: 0.25922301411628723\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 3.913278102874756 | KNN Loss: 3.711358070373535 | CLS Loss: 0.20191997289657593\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 3.8697028160095215 | KNN Loss: 3.7542335987091064 | CLS Loss: 0.11546917259693146\n",
      "Epoch: 002, Loss: 3.9596, Train: 0.9572, Valid: 0.9559, Best: 0.9559\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 3.851881980895996 | KNN Loss: 3.6832661628723145 | CLS Loss: 0.16861578822135925\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 3.8667891025543213 | KNN Loss: 3.674683094024658 | CLS Loss: 0.19210611283779144\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 3.8867790699005127 | KNN Loss: 3.7202649116516113 | CLS Loss: 0.16651420295238495\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 3.9368491172790527 | KNN Loss: 3.6868655681610107 | CLS Loss: 0.24998345971107483\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 3.873581647872925 | KNN Loss: 3.663062572479248 | CLS Loss: 0.21051917970180511\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 3.879906177520752 | KNN Loss: 3.706569194793701 | CLS Loss: 0.1733369082212448\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 3.917341709136963 | KNN Loss: 3.714998483657837 | CLS Loss: 0.20234329998493195\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 3.871218204498291 | KNN Loss: 3.7014317512512207 | CLS Loss: 0.16978642344474792\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 3.8870065212249756 | KNN Loss: 3.704030752182007 | CLS Loss: 0.18297570943832397\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 3.89231538772583 | KNN Loss: 3.68887996673584 | CLS Loss: 0.20343542098999023\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 3.829009532928467 | KNN Loss: 3.6986212730407715 | CLS Loss: 0.1303882896900177\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 3.846909284591675 | KNN Loss: 3.6578471660614014 | CLS Loss: 0.18906201422214508\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 3.8341565132141113 | KNN Loss: 3.698148727416992 | CLS Loss: 0.13600781559944153\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 3.850677013397217 | KNN Loss: 3.696234703063965 | CLS Loss: 0.15444225072860718\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 3.889519691467285 | KNN Loss: 3.7395429611206055 | CLS Loss: 0.14997665584087372\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 3.8357865810394287 | KNN Loss: 3.6992931365966797 | CLS Loss: 0.13649336993694305\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 3.8123083114624023 | KNN Loss: 3.682119131088257 | CLS Loss: 0.13018925487995148\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 3.8192028999328613 | KNN Loss: 3.6686036586761475 | CLS Loss: 0.15059921145439148\n",
      "Epoch: 003, Loss: 3.8643, Train: 0.9637, Valid: 0.9609, Best: 0.9609\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 3.8182568550109863 | KNN Loss: 3.670436382293701 | CLS Loss: 0.1478203535079956\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 3.8166768550872803 | KNN Loss: 3.6664490699768066 | CLS Loss: 0.15022775530815125\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 3.8464720249176025 | KNN Loss: 3.719886302947998 | CLS Loss: 0.12658576667308807\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 3.805629253387451 | KNN Loss: 3.681823492050171 | CLS Loss: 0.12380567938089371\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 3.83010196685791 | KNN Loss: 3.661400556564331 | CLS Loss: 0.16870133578777313\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 3.8146071434020996 | KNN Loss: 3.6662063598632812 | CLS Loss: 0.14840079843997955\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 3.779374122619629 | KNN Loss: 3.679901599884033 | CLS Loss: 0.09947250783443451\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 3.8153207302093506 | KNN Loss: 3.7046897411346436 | CLS Loss: 0.11063109338283539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 3.79848575592041 | KNN Loss: 3.689203977584839 | CLS Loss: 0.10928184539079666\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 3.8146355152130127 | KNN Loss: 3.6692540645599365 | CLS Loss: 0.14538134634494781\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 3.789215564727783 | KNN Loss: 3.7060489654541016 | CLS Loss: 0.08316660672426224\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 3.8082547187805176 | KNN Loss: 3.6728105545043945 | CLS Loss: 0.13544407486915588\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 3.847170114517212 | KNN Loss: 3.7044966220855713 | CLS Loss: 0.1426735818386078\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 3.7556545734405518 | KNN Loss: 3.6470677852630615 | CLS Loss: 0.10858669877052307\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 3.7774887084960938 | KNN Loss: 3.6704304218292236 | CLS Loss: 0.10705823451280594\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 3.7957208156585693 | KNN Loss: 3.708414316177368 | CLS Loss: 0.08730651438236237\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 3.8040318489074707 | KNN Loss: 3.689338445663452 | CLS Loss: 0.11469336599111557\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 3.7836718559265137 | KNN Loss: 3.6988632678985596 | CLS Loss: 0.08480857312679291\n",
      "Epoch: 004, Loss: 3.8125, Train: 0.9705, Valid: 0.9669, Best: 0.9669\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 3.837987184524536 | KNN Loss: 3.7203495502471924 | CLS Loss: 0.11763773113489151\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 3.793447256088257 | KNN Loss: 3.676441192626953 | CLS Loss: 0.11700598150491714\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 3.787536144256592 | KNN Loss: 3.649498462677002 | CLS Loss: 0.13803762197494507\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 3.7594892978668213 | KNN Loss: 3.6868929862976074 | CLS Loss: 0.07259626686573029\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 3.7295734882354736 | KNN Loss: 3.633305549621582 | CLS Loss: 0.0962679386138916\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 3.784975051879883 | KNN Loss: 3.6920580863952637 | CLS Loss: 0.0929170623421669\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 3.7942748069763184 | KNN Loss: 3.6988048553466797 | CLS Loss: 0.09546997398138046\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 3.783909320831299 | KNN Loss: 3.677382469177246 | CLS Loss: 0.10652676969766617\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 3.8088300228118896 | KNN Loss: 3.729283332824707 | CLS Loss: 0.07954663783311844\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 3.805795192718506 | KNN Loss: 3.6875288486480713 | CLS Loss: 0.11826642602682114\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 3.840191125869751 | KNN Loss: 3.693169116973877 | CLS Loss: 0.14702196419239044\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 3.8155627250671387 | KNN Loss: 3.6960065364837646 | CLS Loss: 0.11955612897872925\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 3.7774386405944824 | KNN Loss: 3.662506103515625 | CLS Loss: 0.11493248492479324\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 3.780782461166382 | KNN Loss: 3.6991326808929443 | CLS Loss: 0.08164969086647034\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 3.7956955432891846 | KNN Loss: 3.6941475868225098 | CLS Loss: 0.10154794156551361\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 3.8196184635162354 | KNN Loss: 3.669191598892212 | CLS Loss: 0.15042677521705627\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 3.791536569595337 | KNN Loss: 3.6747243404388428 | CLS Loss: 0.11681212484836578\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 3.796653985977173 | KNN Loss: 3.6726491451263428 | CLS Loss: 0.12400473654270172\n",
      "Epoch: 005, Loss: 3.7893, Train: 0.9737, Valid: 0.9704, Best: 0.9704\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 3.763188362121582 | KNN Loss: 3.6173253059387207 | CLS Loss: 0.14586302638053894\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 3.7384634017944336 | KNN Loss: 3.6175975799560547 | CLS Loss: 0.12086586654186249\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 3.7757606506347656 | KNN Loss: 3.67962384223938 | CLS Loss: 0.09613674879074097\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 3.7693445682525635 | KNN Loss: 3.6931893825531006 | CLS Loss: 0.07615513354539871\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 3.7770416736602783 | KNN Loss: 3.686284065246582 | CLS Loss: 0.09075753390789032\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 3.7485172748565674 | KNN Loss: 3.650369644165039 | CLS Loss: 0.09814774245023727\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 3.745262622833252 | KNN Loss: 3.6695024967193604 | CLS Loss: 0.07576005905866623\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 3.713557720184326 | KNN Loss: 3.667903184890747 | CLS Loss: 0.04565451666712761\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 3.7761268615722656 | KNN Loss: 3.6449453830718994 | CLS Loss: 0.13118141889572144\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 3.7901504039764404 | KNN Loss: 3.719607353210449 | CLS Loss: 0.07054293900728226\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 3.7225265502929688 | KNN Loss: 3.6528704166412354 | CLS Loss: 0.06965620070695877\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 3.7308082580566406 | KNN Loss: 3.6593940258026123 | CLS Loss: 0.07141431421041489\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 3.7608509063720703 | KNN Loss: 3.6561367511749268 | CLS Loss: 0.1047140434384346\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 3.7904930114746094 | KNN Loss: 3.7209019660949707 | CLS Loss: 0.06959115713834763\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 3.745187282562256 | KNN Loss: 3.652360677719116 | CLS Loss: 0.0928264930844307\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 3.7596917152404785 | KNN Loss: 3.6536049842834473 | CLS Loss: 0.1060866117477417\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 3.7653512954711914 | KNN Loss: 3.675431966781616 | CLS Loss: 0.0899193212389946\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 3.781714677810669 | KNN Loss: 3.6761600971221924 | CLS Loss: 0.10555451363325119\n",
      "Epoch: 006, Loss: 3.7634, Train: 0.9761, Valid: 0.9731, Best: 0.9731\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 3.7926876544952393 | KNN Loss: 3.665886878967285 | CLS Loss: 0.12680083513259888\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 3.7328202724456787 | KNN Loss: 3.677504062652588 | CLS Loss: 0.05531609430909157\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 3.714445114135742 | KNN Loss: 3.6251730918884277 | CLS Loss: 0.08927202224731445\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 3.7784950733184814 | KNN Loss: 3.647296667098999 | CLS Loss: 0.13119831681251526\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 3.7132909297943115 | KNN Loss: 3.629312515258789 | CLS Loss: 0.08397839218378067\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 3.742345094680786 | KNN Loss: 3.690061330795288 | CLS Loss: 0.05228367820382118\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 3.7579150199890137 | KNN Loss: 3.6660897731781006 | CLS Loss: 0.09182527661323547\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 3.7077126502990723 | KNN Loss: 3.6549196243286133 | CLS Loss: 0.0527929849922657\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 3.7654664516448975 | KNN Loss: 3.650240898132324 | CLS Loss: 0.11522544175386429\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 3.7825145721435547 | KNN Loss: 3.686405897140503 | CLS Loss: 0.09610863029956818\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 3.7571444511413574 | KNN Loss: 3.6640524864196777 | CLS Loss: 0.09309207648038864\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 3.7457003593444824 | KNN Loss: 3.682467460632324 | CLS Loss: 0.06323285400867462\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 3.7298402786254883 | KNN Loss: 3.65181303024292 | CLS Loss: 0.07802730798721313\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 3.8372385501861572 | KNN Loss: 3.695244312286377 | CLS Loss: 0.14199432730674744\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 3.7461812496185303 | KNN Loss: 3.642259359359741 | CLS Loss: 0.10392197966575623\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 3.782830238342285 | KNN Loss: 3.6570987701416016 | CLS Loss: 0.12573136389255524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 3.7533836364746094 | KNN Loss: 3.643889904022217 | CLS Loss: 0.1094936728477478\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 3.759463310241699 | KNN Loss: 3.6787896156311035 | CLS Loss: 0.08067367225885391\n",
      "Epoch: 007, Loss: 3.7559, Train: 0.9793, Valid: 0.9760, Best: 0.9760\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 3.738450288772583 | KNN Loss: 3.6555938720703125 | CLS Loss: 0.08285630494356155\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 3.70348858833313 | KNN Loss: 3.6520161628723145 | CLS Loss: 0.05147242546081543\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 3.7704567909240723 | KNN Loss: 3.6611456871032715 | CLS Loss: 0.10931115597486496\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 3.7452759742736816 | KNN Loss: 3.672139883041382 | CLS Loss: 0.07313603907823563\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 3.708233594894409 | KNN Loss: 3.630563497543335 | CLS Loss: 0.07767011225223541\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 3.7623116970062256 | KNN Loss: 3.66747784614563 | CLS Loss: 0.09483382105827332\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 3.75553560256958 | KNN Loss: 3.654106855392456 | CLS Loss: 0.10142877697944641\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 3.773454427719116 | KNN Loss: 3.6775803565979004 | CLS Loss: 0.09587403386831284\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 3.79412841796875 | KNN Loss: 3.715953826904297 | CLS Loss: 0.07817460596561432\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 3.7613182067871094 | KNN Loss: 3.6796908378601074 | CLS Loss: 0.08162733912467957\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 3.706986665725708 | KNN Loss: 3.62211275100708 | CLS Loss: 0.08487382531166077\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 3.7525532245635986 | KNN Loss: 3.6920907497406006 | CLS Loss: 0.060462530702352524\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 3.699083089828491 | KNN Loss: 3.616337776184082 | CLS Loss: 0.0827452763915062\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 3.7130253314971924 | KNN Loss: 3.6517646312713623 | CLS Loss: 0.06126073747873306\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 3.7185070514678955 | KNN Loss: 3.667008399963379 | CLS Loss: 0.051498547196388245\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 3.740346908569336 | KNN Loss: 3.639343738555908 | CLS Loss: 0.10100320726633072\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 3.806117057800293 | KNN Loss: 3.7012760639190674 | CLS Loss: 0.10484091937541962\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 3.7731356620788574 | KNN Loss: 3.650575876235962 | CLS Loss: 0.12255967408418655\n",
      "Epoch: 008, Loss: 3.7382, Train: 0.9798, Valid: 0.9770, Best: 0.9770\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 3.810453176498413 | KNN Loss: 3.7060606479644775 | CLS Loss: 0.10439259558916092\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 3.761962413787842 | KNN Loss: 3.688728094100952 | CLS Loss: 0.07323439419269562\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 3.7180614471435547 | KNN Loss: 3.661663055419922 | CLS Loss: 0.056398361921310425\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 3.747915506362915 | KNN Loss: 3.659679651260376 | CLS Loss: 0.08823589980602264\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 3.7411365509033203 | KNN Loss: 3.6728899478912354 | CLS Loss: 0.06824660301208496\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 3.6960792541503906 | KNN Loss: 3.644343852996826 | CLS Loss: 0.05173542723059654\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 3.729400396347046 | KNN Loss: 3.6951634883880615 | CLS Loss: 0.03423689305782318\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 3.8161308765411377 | KNN Loss: 3.7213211059570312 | CLS Loss: 0.09480966627597809\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 3.6993863582611084 | KNN Loss: 3.6524417400360107 | CLS Loss: 0.04694453254342079\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 3.7536895275115967 | KNN Loss: 3.653259038925171 | CLS Loss: 0.10043051838874817\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 3.728595733642578 | KNN Loss: 3.610105514526367 | CLS Loss: 0.11849019676446915\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 3.6714489459991455 | KNN Loss: 3.633570432662964 | CLS Loss: 0.03787851333618164\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 3.754920482635498 | KNN Loss: 3.633063793182373 | CLS Loss: 0.12185676395893097\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 3.770353078842163 | KNN Loss: 3.648653507232666 | CLS Loss: 0.12169964611530304\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 3.6948578357696533 | KNN Loss: 3.6365180015563965 | CLS Loss: 0.05833994597196579\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 3.72438907623291 | KNN Loss: 3.653463840484619 | CLS Loss: 0.07092522084712982\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 3.68564510345459 | KNN Loss: 3.6408185958862305 | CLS Loss: 0.04482639208436012\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 3.6986002922058105 | KNN Loss: 3.629697799682617 | CLS Loss: 0.06890261173248291\n",
      "Epoch: 009, Loss: 3.7292, Train: 0.9830, Valid: 0.9794, Best: 0.9794\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 3.7097673416137695 | KNN Loss: 3.653106451034546 | CLS Loss: 0.056660816073417664\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 3.682656764984131 | KNN Loss: 3.6550445556640625 | CLS Loss: 0.027612296864390373\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 3.7126662731170654 | KNN Loss: 3.6571433544158936 | CLS Loss: 0.05552283674478531\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 3.7151191234588623 | KNN Loss: 3.662923812866211 | CLS Loss: 0.05219535902142525\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 3.721723794937134 | KNN Loss: 3.638214111328125 | CLS Loss: 0.08350975811481476\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 3.706054925918579 | KNN Loss: 3.6478590965270996 | CLS Loss: 0.058195777237415314\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 3.7034757137298584 | KNN Loss: 3.665524959564209 | CLS Loss: 0.0379507914185524\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 3.6764419078826904 | KNN Loss: 3.6429073810577393 | CLS Loss: 0.03353443741798401\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 3.7499678134918213 | KNN Loss: 3.671224594116211 | CLS Loss: 0.07874315977096558\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 3.7227094173431396 | KNN Loss: 3.6755425930023193 | CLS Loss: 0.04716693237423897\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 3.7457032203674316 | KNN Loss: 3.6413207054138184 | CLS Loss: 0.10438239574432373\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 3.744062662124634 | KNN Loss: 3.6690280437469482 | CLS Loss: 0.07503459602594376\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 3.7007882595062256 | KNN Loss: 3.6641485691070557 | CLS Loss: 0.03663964197039604\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 3.6630661487579346 | KNN Loss: 3.615586280822754 | CLS Loss: 0.04747988283634186\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 3.672983169555664 | KNN Loss: 3.6209568977355957 | CLS Loss: 0.05202621966600418\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 3.7282145023345947 | KNN Loss: 3.6320338249206543 | CLS Loss: 0.09618063271045685\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 3.7403032779693604 | KNN Loss: 3.675858974456787 | CLS Loss: 0.06444432586431503\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 3.7372307777404785 | KNN Loss: 3.6452512741088867 | CLS Loss: 0.09197958558797836\n",
      "Epoch: 010, Loss: 3.7169, Train: 0.9806, Valid: 0.9769, Best: 0.9794\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 3.708540678024292 | KNN Loss: 3.6518795490264893 | CLS Loss: 0.056661155074834824\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 3.7282373905181885 | KNN Loss: 3.646352767944336 | CLS Loss: 0.08188451081514359\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 3.7319517135620117 | KNN Loss: 3.657268762588501 | CLS Loss: 0.07468288391828537\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 3.695528030395508 | KNN Loss: 3.6484358310699463 | CLS Loss: 0.04709216207265854\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 3.7105963230133057 | KNN Loss: 3.687664031982422 | CLS Loss: 0.022932305932044983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 3.7627627849578857 | KNN Loss: 3.675680160522461 | CLS Loss: 0.08708266913890839\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 3.7342638969421387 | KNN Loss: 3.6771769523620605 | CLS Loss: 0.05708690732717514\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 3.7306833267211914 | KNN Loss: 3.6280019283294678 | CLS Loss: 0.1026814728975296\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 3.719848871231079 | KNN Loss: 3.638535737991333 | CLS Loss: 0.0813131183385849\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 3.70465350151062 | KNN Loss: 3.6479318141937256 | CLS Loss: 0.05672163888812065\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 3.710153579711914 | KNN Loss: 3.6282947063446045 | CLS Loss: 0.08185885101556778\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 3.698760509490967 | KNN Loss: 3.644787073135376 | CLS Loss: 0.05397352576255798\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 3.728572368621826 | KNN Loss: 3.6468844413757324 | CLS Loss: 0.08168789744377136\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 3.686629056930542 | KNN Loss: 3.626237392425537 | CLS Loss: 0.06039164215326309\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 3.6617329120635986 | KNN Loss: 3.619797706604004 | CLS Loss: 0.04193511977791786\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 3.686556816101074 | KNN Loss: 3.625101327896118 | CLS Loss: 0.06145542114973068\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 3.768745183944702 | KNN Loss: 3.66337513923645 | CLS Loss: 0.10536998510360718\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 3.6865079402923584 | KNN Loss: 3.634002923965454 | CLS Loss: 0.05250508338212967\n",
      "Epoch: 011, Loss: 3.7092, Train: 0.9826, Valid: 0.9791, Best: 0.9794\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 3.7087912559509277 | KNN Loss: 3.653289556503296 | CLS Loss: 0.05550173297524452\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 3.7364518642425537 | KNN Loss: 3.6780385971069336 | CLS Loss: 0.0584133118391037\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 3.6890830993652344 | KNN Loss: 3.6112101078033447 | CLS Loss: 0.07787292450666428\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 3.731199026107788 | KNN Loss: 3.668769359588623 | CLS Loss: 0.06242973357439041\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 3.671358823776245 | KNN Loss: 3.6229655742645264 | CLS Loss: 0.04839333891868591\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 3.6794662475585938 | KNN Loss: 3.621995449066162 | CLS Loss: 0.05747073143720627\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 3.6989223957061768 | KNN Loss: 3.6071484088897705 | CLS Loss: 0.09177395701408386\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 3.69807505607605 | KNN Loss: 3.6345531940460205 | CLS Loss: 0.06352180242538452\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 3.7141387462615967 | KNN Loss: 3.6080501079559326 | CLS Loss: 0.10608866810798645\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 3.6826958656311035 | KNN Loss: 3.637742519378662 | CLS Loss: 0.04495345056056976\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 3.701107978820801 | KNN Loss: 3.6351277828216553 | CLS Loss: 0.06598016619682312\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 3.6801295280456543 | KNN Loss: 3.6429731845855713 | CLS Loss: 0.03715645521879196\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 3.703768253326416 | KNN Loss: 3.6603336334228516 | CLS Loss: 0.043434590101242065\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 3.733798027038574 | KNN Loss: 3.6762564182281494 | CLS Loss: 0.05754169076681137\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 3.702136516571045 | KNN Loss: 3.6452789306640625 | CLS Loss: 0.0568576343357563\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 3.800410509109497 | KNN Loss: 3.7085072994232178 | CLS Loss: 0.09190323203802109\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 3.68074631690979 | KNN Loss: 3.615948438644409 | CLS Loss: 0.06479784846305847\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 3.7049129009246826 | KNN Loss: 3.6191556453704834 | CLS Loss: 0.08575722575187683\n",
      "Epoch: 012, Loss: 3.7108, Train: 0.9828, Valid: 0.9801, Best: 0.9801\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 3.678016185760498 | KNN Loss: 3.6196558475494385 | CLS Loss: 0.05836033448576927\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 3.7594902515411377 | KNN Loss: 3.674800157546997 | CLS Loss: 0.08469019830226898\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 3.76643443107605 | KNN Loss: 3.6794626712799072 | CLS Loss: 0.08697175234556198\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 3.7261595726013184 | KNN Loss: 3.6731691360473633 | CLS Loss: 0.052990492433309555\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 3.7425448894500732 | KNN Loss: 3.689142942428589 | CLS Loss: 0.053401850163936615\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 3.719712972640991 | KNN Loss: 3.6479384899139404 | CLS Loss: 0.07177451252937317\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 3.698942184448242 | KNN Loss: 3.6589348316192627 | CLS Loss: 0.040007296949625015\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 3.6589138507843018 | KNN Loss: 3.617643356323242 | CLS Loss: 0.04127045348286629\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 3.6641438007354736 | KNN Loss: 3.6289150714874268 | CLS Loss: 0.03522871062159538\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 3.6876606941223145 | KNN Loss: 3.6524486541748047 | CLS Loss: 0.03521193936467171\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 3.705413579940796 | KNN Loss: 3.650224447250366 | CLS Loss: 0.05518908053636551\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 3.741976499557495 | KNN Loss: 3.6499786376953125 | CLS Loss: 0.09199783205986023\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 3.6936147212982178 | KNN Loss: 3.6521973609924316 | CLS Loss: 0.041417255997657776\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 3.7425296306610107 | KNN Loss: 3.632903814315796 | CLS Loss: 0.10962571203708649\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 3.6922049522399902 | KNN Loss: 3.6480319499969482 | CLS Loss: 0.0441729761660099\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 3.697467565536499 | KNN Loss: 3.6390609741210938 | CLS Loss: 0.05840650200843811\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 3.6855263710021973 | KNN Loss: 3.6092214584350586 | CLS Loss: 0.07630497217178345\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 3.694849729537964 | KNN Loss: 3.6393978595733643 | CLS Loss: 0.055451784282922745\n",
      "Epoch: 013, Loss: 3.7003, Train: 0.9848, Valid: 0.9814, Best: 0.9814\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 3.670212745666504 | KNN Loss: 3.6420013904571533 | CLS Loss: 0.028211425989866257\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 3.682504653930664 | KNN Loss: 3.6241466999053955 | CLS Loss: 0.05835789069533348\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 3.703371047973633 | KNN Loss: 3.639733076095581 | CLS Loss: 0.063637875020504\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 3.7024166584014893 | KNN Loss: 3.6339643001556396 | CLS Loss: 0.06845235824584961\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 3.718240976333618 | KNN Loss: 3.6748502254486084 | CLS Loss: 0.04339069500565529\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 3.7072198390960693 | KNN Loss: 3.657562732696533 | CLS Loss: 0.04965701326727867\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 3.6747446060180664 | KNN Loss: 3.637826919555664 | CLS Loss: 0.036917801946401596\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 3.6781749725341797 | KNN Loss: 3.6238932609558105 | CLS Loss: 0.054281823337078094\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 3.7136900424957275 | KNN Loss: 3.649653196334839 | CLS Loss: 0.0640367791056633\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 3.7456347942352295 | KNN Loss: 3.6718461513519287 | CLS Loss: 0.07378870248794556\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 3.680976629257202 | KNN Loss: 3.6304426193237305 | CLS Loss: 0.05053408443927765\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 3.7443408966064453 | KNN Loss: 3.664808988571167 | CLS Loss: 0.07953180372714996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 3.6565840244293213 | KNN Loss: 3.6200175285339355 | CLS Loss: 0.03656653314828873\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 3.672551155090332 | KNN Loss: 3.6199028491973877 | CLS Loss: 0.052648186683654785\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 3.731665849685669 | KNN Loss: 3.6519761085510254 | CLS Loss: 0.07968978583812714\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 3.680635452270508 | KNN Loss: 3.608729600906372 | CLS Loss: 0.07190591841936111\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 3.754255771636963 | KNN Loss: 3.6525609493255615 | CLS Loss: 0.10169482231140137\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 3.693587064743042 | KNN Loss: 3.6085550785064697 | CLS Loss: 0.0850318968296051\n",
      "Epoch: 014, Loss: 3.6998, Train: 0.9820, Valid: 0.9783, Best: 0.9814\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 3.724168300628662 | KNN Loss: 3.647566556930542 | CLS Loss: 0.07660174369812012\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 3.6731040477752686 | KNN Loss: 3.622272491455078 | CLS Loss: 0.050831619650125504\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 3.70475697517395 | KNN Loss: 3.658036947250366 | CLS Loss: 0.04671994596719742\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 3.6573455333709717 | KNN Loss: 3.623807668685913 | CLS Loss: 0.033537790179252625\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 3.6790053844451904 | KNN Loss: 3.6193504333496094 | CLS Loss: 0.059655044227838516\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 3.677747964859009 | KNN Loss: 3.621094226837158 | CLS Loss: 0.056653764098882675\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 3.661033868789673 | KNN Loss: 3.6296801567077637 | CLS Loss: 0.03135376051068306\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 3.7012863159179688 | KNN Loss: 3.613044500350952 | CLS Loss: 0.08824179321527481\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 3.6991307735443115 | KNN Loss: 3.6314921379089355 | CLS Loss: 0.06763860583305359\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 3.7123360633850098 | KNN Loss: 3.6602513790130615 | CLS Loss: 0.05208462476730347\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 3.6815290451049805 | KNN Loss: 3.6303741931915283 | CLS Loss: 0.05115479230880737\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 3.7300848960876465 | KNN Loss: 3.657399892807007 | CLS Loss: 0.07268501818180084\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 3.6622071266174316 | KNN Loss: 3.57901930809021 | CLS Loss: 0.08318771421909332\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 3.7031495571136475 | KNN Loss: 3.642982244491577 | CLS Loss: 0.0601673498749733\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 3.6728878021240234 | KNN Loss: 3.6027770042419434 | CLS Loss: 0.07011070847511292\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 3.6718852519989014 | KNN Loss: 3.6362879276275635 | CLS Loss: 0.03559742495417595\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 3.697028875350952 | KNN Loss: 3.6089136600494385 | CLS Loss: 0.08811520040035248\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 3.7112209796905518 | KNN Loss: 3.6558303833007812 | CLS Loss: 0.05539051070809364\n",
      "Epoch: 015, Loss: 3.6893, Train: 0.9867, Valid: 0.9822, Best: 0.9822\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 3.7093846797943115 | KNN Loss: 3.6348700523376465 | CLS Loss: 0.07451453804969788\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 3.668261766433716 | KNN Loss: 3.635660171508789 | CLS Loss: 0.03260154649615288\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 3.680513381958008 | KNN Loss: 3.618335485458374 | CLS Loss: 0.06217784434556961\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 3.6790735721588135 | KNN Loss: 3.6256563663482666 | CLS Loss: 0.053417280316352844\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 3.7264273166656494 | KNN Loss: 3.6314079761505127 | CLS Loss: 0.0950194001197815\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 3.67170786857605 | KNN Loss: 3.627056837081909 | CLS Loss: 0.04465103521943092\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 3.650118827819824 | KNN Loss: 3.6276779174804688 | CLS Loss: 0.022440917789936066\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 3.682162046432495 | KNN Loss: 3.6352858543395996 | CLS Loss: 0.04687627777457237\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 3.6756346225738525 | KNN Loss: 3.6099324226379395 | CLS Loss: 0.06570212543010712\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 3.689742088317871 | KNN Loss: 3.624281406402588 | CLS Loss: 0.06546079367399216\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 3.7238833904266357 | KNN Loss: 3.647444009780884 | CLS Loss: 0.07643947005271912\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 3.6764161586761475 | KNN Loss: 3.641733169555664 | CLS Loss: 0.03468303382396698\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 3.7149927616119385 | KNN Loss: 3.645138740539551 | CLS Loss: 0.0698540136218071\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 3.6590449810028076 | KNN Loss: 3.6264936923980713 | CLS Loss: 0.032551318407058716\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 3.674650192260742 | KNN Loss: 3.6121768951416016 | CLS Loss: 0.06247332692146301\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 3.7127931118011475 | KNN Loss: 3.658409833908081 | CLS Loss: 0.05438319593667984\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 3.695924997329712 | KNN Loss: 3.612006187438965 | CLS Loss: 0.08391880244016647\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 3.6855077743530273 | KNN Loss: 3.6080329418182373 | CLS Loss: 0.07747484743595123\n",
      "Epoch: 016, Loss: 3.6884, Train: 0.9875, Valid: 0.9830, Best: 0.9830\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 3.6501662731170654 | KNN Loss: 3.629751205444336 | CLS Loss: 0.02041509747505188\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 3.67935848236084 | KNN Loss: 3.6276583671569824 | CLS Loss: 0.05170018598437309\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 3.6701958179473877 | KNN Loss: 3.6409718990325928 | CLS Loss: 0.029224000871181488\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 3.6581478118896484 | KNN Loss: 3.6177818775177 | CLS Loss: 0.04036586731672287\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 3.7063355445861816 | KNN Loss: 3.6501240730285645 | CLS Loss: 0.05621153116226196\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 3.7136504650115967 | KNN Loss: 3.6471011638641357 | CLS Loss: 0.06654919683933258\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 3.6412947177886963 | KNN Loss: 3.593498945236206 | CLS Loss: 0.04779581353068352\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 3.6527130603790283 | KNN Loss: 3.6125755310058594 | CLS Loss: 0.040137432515621185\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 3.6768958568573 | KNN Loss: 3.637533187866211 | CLS Loss: 0.03936270624399185\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 3.679281234741211 | KNN Loss: 3.6166348457336426 | CLS Loss: 0.06264633685350418\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 3.6597766876220703 | KNN Loss: 3.6231305599212646 | CLS Loss: 0.036646194756031036\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 3.710812568664551 | KNN Loss: 3.665379524230957 | CLS Loss: 0.0454329289495945\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 3.652265787124634 | KNN Loss: 3.600316047668457 | CLS Loss: 0.05194978043437004\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 3.685396671295166 | KNN Loss: 3.5959551334381104 | CLS Loss: 0.08944154530763626\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 3.6887125968933105 | KNN Loss: 3.655424118041992 | CLS Loss: 0.03328851982951164\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 3.6825311183929443 | KNN Loss: 3.6373887062072754 | CLS Loss: 0.04514240473508835\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 3.6982667446136475 | KNN Loss: 3.616147994995117 | CLS Loss: 0.08211870491504669\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 3.63407564163208 | KNN Loss: 3.605480432510376 | CLS Loss: 0.02859528921544552\n",
      "Epoch: 017, Loss: 3.6837, Train: 0.9876, Valid: 0.9827, Best: 0.9830\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 3.7283687591552734 | KNN Loss: 3.6692957878112793 | CLS Loss: 0.05907304584980011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 3.638951063156128 | KNN Loss: 3.6093945503234863 | CLS Loss: 0.02955649234354496\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 3.6590747833251953 | KNN Loss: 3.617400646209717 | CLS Loss: 0.04167410731315613\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 3.6594011783599854 | KNN Loss: 3.617701768875122 | CLS Loss: 0.041699472814798355\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 3.6963508129119873 | KNN Loss: 3.63618540763855 | CLS Loss: 0.06016538292169571\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 3.6822354793548584 | KNN Loss: 3.6098101139068604 | CLS Loss: 0.07242526113986969\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 3.6879372596740723 | KNN Loss: 3.6214959621429443 | CLS Loss: 0.06644134223461151\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 3.671886444091797 | KNN Loss: 3.611564874649048 | CLS Loss: 0.060321662575006485\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 3.6674792766571045 | KNN Loss: 3.644805908203125 | CLS Loss: 0.02267344482243061\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 3.6978695392608643 | KNN Loss: 3.6475441455841064 | CLS Loss: 0.05032527819275856\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 3.6996586322784424 | KNN Loss: 3.6369247436523438 | CLS Loss: 0.06273385882377625\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 3.6872518062591553 | KNN Loss: 3.6339821815490723 | CLS Loss: 0.05326973274350166\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 3.662184953689575 | KNN Loss: 3.6231327056884766 | CLS Loss: 0.03905215114355087\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 3.674250364303589 | KNN Loss: 3.6327199935913086 | CLS Loss: 0.041530344635248184\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 3.6927223205566406 | KNN Loss: 3.6537299156188965 | CLS Loss: 0.03899248689413071\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 3.6611344814300537 | KNN Loss: 3.630783796310425 | CLS Loss: 0.030350614339113235\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 3.6759302616119385 | KNN Loss: 3.5971360206604004 | CLS Loss: 0.0787942111492157\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 3.7023322582244873 | KNN Loss: 3.6509199142456055 | CLS Loss: 0.051412250846624374\n",
      "Epoch: 018, Loss: 3.6777, Train: 0.9854, Valid: 0.9805, Best: 0.9830\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 3.6599185466766357 | KNN Loss: 3.633394956588745 | CLS Loss: 0.026523519307374954\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 3.653028964996338 | KNN Loss: 3.5987956523895264 | CLS Loss: 0.05423329770565033\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 3.6637558937072754 | KNN Loss: 3.626380681991577 | CLS Loss: 0.03737524896860123\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 3.6775059700012207 | KNN Loss: 3.639726161956787 | CLS Loss: 0.037779875099658966\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 3.7069549560546875 | KNN Loss: 3.632906198501587 | CLS Loss: 0.07404874265193939\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 3.698122501373291 | KNN Loss: 3.6275765895843506 | CLS Loss: 0.07054585218429565\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 3.6580917835235596 | KNN Loss: 3.619767189025879 | CLS Loss: 0.03832467645406723\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 3.669163465499878 | KNN Loss: 3.5825397968292236 | CLS Loss: 0.08662371337413788\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 3.6963043212890625 | KNN Loss: 3.652233600616455 | CLS Loss: 0.044070713222026825\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 3.660625696182251 | KNN Loss: 3.629136562347412 | CLS Loss: 0.031489040702581406\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 3.69415545463562 | KNN Loss: 3.6433465480804443 | CLS Loss: 0.050808850675821304\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 3.6549184322357178 | KNN Loss: 3.607236862182617 | CLS Loss: 0.04768158495426178\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 3.7492308616638184 | KNN Loss: 3.6873621940612793 | CLS Loss: 0.061868682503700256\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 3.672147512435913 | KNN Loss: 3.620745897293091 | CLS Loss: 0.0514015331864357\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 3.693199634552002 | KNN Loss: 3.6580872535705566 | CLS Loss: 0.03511246293783188\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 3.677889823913574 | KNN Loss: 3.6114895343780518 | CLS Loss: 0.06640031933784485\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 3.660825490951538 | KNN Loss: 3.6011834144592285 | CLS Loss: 0.0596420057117939\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 3.720431089401245 | KNN Loss: 3.6741204261779785 | CLS Loss: 0.046310581266880035\n",
      "Epoch: 019, Loss: 3.6766, Train: 0.9881, Valid: 0.9831, Best: 0.9831\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 3.7012252807617188 | KNN Loss: 3.625141143798828 | CLS Loss: 0.07608412206172943\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 3.6151578426361084 | KNN Loss: 3.5730488300323486 | CLS Loss: 0.042108990252017975\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 3.668302536010742 | KNN Loss: 3.617286443710327 | CLS Loss: 0.05101611837744713\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 3.6872427463531494 | KNN Loss: 3.648620128631592 | CLS Loss: 0.038622595369815826\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 3.7122464179992676 | KNN Loss: 3.666029453277588 | CLS Loss: 0.046216949820518494\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 3.6871745586395264 | KNN Loss: 3.6496925354003906 | CLS Loss: 0.03748209774494171\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 3.68113112449646 | KNN Loss: 3.618692636489868 | CLS Loss: 0.062438394874334335\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 3.627357006072998 | KNN Loss: 3.5790810585021973 | CLS Loss: 0.0482759028673172\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 3.676499366760254 | KNN Loss: 3.6112496852874756 | CLS Loss: 0.06524967402219772\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 3.661576986312866 | KNN Loss: 3.630315065383911 | CLS Loss: 0.03126193583011627\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 3.624204158782959 | KNN Loss: 3.581256151199341 | CLS Loss: 0.04294803366065025\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 3.646631956100464 | KNN Loss: 3.626850128173828 | CLS Loss: 0.01978190243244171\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 3.695774555206299 | KNN Loss: 3.6575396060943604 | CLS Loss: 0.038234859704971313\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 3.6752336025238037 | KNN Loss: 3.631755828857422 | CLS Loss: 0.043477870523929596\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 3.730475664138794 | KNN Loss: 3.6434688568115234 | CLS Loss: 0.08700691908597946\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 3.667435646057129 | KNN Loss: 3.6367433071136475 | CLS Loss: 0.030692437663674355\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 3.66266131401062 | KNN Loss: 3.6264514923095703 | CLS Loss: 0.03620989993214607\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 3.659733533859253 | KNN Loss: 3.651529550552368 | CLS Loss: 0.008203941397368908\n",
      "Epoch: 020, Loss: 3.6728, Train: 0.9893, Valid: 0.9845, Best: 0.9845\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 3.6516671180725098 | KNN Loss: 3.5842959880828857 | CLS Loss: 0.06737120449542999\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 3.679260015487671 | KNN Loss: 3.648672342300415 | CLS Loss: 0.030587639659643173\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 3.647947311401367 | KNN Loss: 3.616023302078247 | CLS Loss: 0.03192398324608803\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 3.7064056396484375 | KNN Loss: 3.666334390640259 | CLS Loss: 0.040071334689855576\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 3.676034688949585 | KNN Loss: 3.642042636871338 | CLS Loss: 0.03399208188056946\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 3.638322591781616 | KNN Loss: 3.6230170726776123 | CLS Loss: 0.015305578708648682\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 3.666628837585449 | KNN Loss: 3.629812240600586 | CLS Loss: 0.036816611886024475\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 3.688681125640869 | KNN Loss: 3.650392770767212 | CLS Loss: 0.038288287818431854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 3.6557419300079346 | KNN Loss: 3.6284549236297607 | CLS Loss: 0.02728702314198017\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 3.6604034900665283 | KNN Loss: 3.6110756397247314 | CLS Loss: 0.04932793974876404\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 3.6701767444610596 | KNN Loss: 3.587149143218994 | CLS Loss: 0.08302749693393707\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 3.6688661575317383 | KNN Loss: 3.635118007659912 | CLS Loss: 0.0337480790913105\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 3.712132215499878 | KNN Loss: 3.6369788646698 | CLS Loss: 0.07515344023704529\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 3.647012948989868 | KNN Loss: 3.5717649459838867 | CLS Loss: 0.07524795085191727\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 3.6938745975494385 | KNN Loss: 3.630488395690918 | CLS Loss: 0.06338613480329514\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 3.6343488693237305 | KNN Loss: 3.6040680408477783 | CLS Loss: 0.03028077818453312\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 3.6529455184936523 | KNN Loss: 3.629474639892578 | CLS Loss: 0.02347096987068653\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 3.6754536628723145 | KNN Loss: 3.62931489944458 | CLS Loss: 0.046138737350702286\n",
      "Epoch: 021, Loss: 3.6680, Train: 0.9898, Valid: 0.9838, Best: 0.9845\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 3.6781651973724365 | KNN Loss: 3.6459577083587646 | CLS Loss: 0.032207515090703964\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 3.6609461307525635 | KNN Loss: 3.623239278793335 | CLS Loss: 0.03770676627755165\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 3.724561929702759 | KNN Loss: 3.657409906387329 | CLS Loss: 0.06715210527181625\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 3.64635968208313 | KNN Loss: 3.627453327178955 | CLS Loss: 0.018906245008111\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 3.652743101119995 | KNN Loss: 3.6227869987487793 | CLS Loss: 0.029956120997667313\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 3.610095262527466 | KNN Loss: 3.5735886096954346 | CLS Loss: 0.03650675714015961\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 3.654083013534546 | KNN Loss: 3.602231502532959 | CLS Loss: 0.051851410418748856\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 3.6660237312316895 | KNN Loss: 3.6015822887420654 | CLS Loss: 0.06444136798381805\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 3.6490423679351807 | KNN Loss: 3.62652587890625 | CLS Loss: 0.022516470402479172\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 3.6788442134857178 | KNN Loss: 3.644796848297119 | CLS Loss: 0.03404729813337326\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 3.659698247909546 | KNN Loss: 3.643949508666992 | CLS Loss: 0.015748856589198112\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 3.643360137939453 | KNN Loss: 3.5995028018951416 | CLS Loss: 0.04385724291205406\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 3.654770612716675 | KNN Loss: 3.6204073429107666 | CLS Loss: 0.034363336861133575\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 3.655980110168457 | KNN Loss: 3.6012027263641357 | CLS Loss: 0.0547773614525795\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 3.7021842002868652 | KNN Loss: 3.652512550354004 | CLS Loss: 0.04967176914215088\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 3.6322333812713623 | KNN Loss: 3.6128623485565186 | CLS Loss: 0.019371097907423973\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 3.713189125061035 | KNN Loss: 3.664707660675049 | CLS Loss: 0.04848151654005051\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 3.6299996376037598 | KNN Loss: 3.5944113731384277 | CLS Loss: 0.03558814525604248\n",
      "Epoch: 022, Loss: 3.6664, Train: 0.9873, Valid: 0.9825, Best: 0.9845\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 3.6887197494506836 | KNN Loss: 3.63118577003479 | CLS Loss: 0.05753402039408684\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 3.671272039413452 | KNN Loss: 3.628945827484131 | CLS Loss: 0.04232632741332054\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 3.702331781387329 | KNN Loss: 3.628180980682373 | CLS Loss: 0.07415083050727844\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 3.672419786453247 | KNN Loss: 3.631868362426758 | CLS Loss: 0.0405513234436512\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 3.6965858936309814 | KNN Loss: 3.651275634765625 | CLS Loss: 0.04531029611825943\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 3.6457488536834717 | KNN Loss: 3.5891811847686768 | CLS Loss: 0.056567758321762085\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 3.634941577911377 | KNN Loss: 3.6055729389190674 | CLS Loss: 0.029368745163083076\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 3.6837470531463623 | KNN Loss: 3.621738910675049 | CLS Loss: 0.06200811266899109\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 3.640010356903076 | KNN Loss: 3.603581666946411 | CLS Loss: 0.036428604274988174\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 3.673396110534668 | KNN Loss: 3.5975775718688965 | CLS Loss: 0.07581856101751328\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 3.6805708408355713 | KNN Loss: 3.648343563079834 | CLS Loss: 0.03222723305225372\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 3.67234468460083 | KNN Loss: 3.6388323307037354 | CLS Loss: 0.03351236507296562\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 3.7021708488464355 | KNN Loss: 3.6172049045562744 | CLS Loss: 0.08496583253145218\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 3.6334359645843506 | KNN Loss: 3.606290340423584 | CLS Loss: 0.02714562974870205\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 3.6769208908081055 | KNN Loss: 3.6282527446746826 | CLS Loss: 0.04866814613342285\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 3.6426873207092285 | KNN Loss: 3.6179158687591553 | CLS Loss: 0.02477150224149227\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 3.665320873260498 | KNN Loss: 3.625760078430176 | CLS Loss: 0.03956073150038719\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 3.630870819091797 | KNN Loss: 3.606919765472412 | CLS Loss: 0.023951109498739243\n",
      "Epoch: 023, Loss: 3.6634, Train: 0.9905, Valid: 0.9841, Best: 0.9845\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 3.6621930599212646 | KNN Loss: 3.608224391937256 | CLS Loss: 0.053968749940395355\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 3.616975784301758 | KNN Loss: 3.593743324279785 | CLS Loss: 0.023232579231262207\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 3.6431963443756104 | KNN Loss: 3.590541362762451 | CLS Loss: 0.05265496298670769\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 3.659006357192993 | KNN Loss: 3.6353180408477783 | CLS Loss: 0.02368830516934395\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 3.6598703861236572 | KNN Loss: 3.628660202026367 | CLS Loss: 0.031210139393806458\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 3.600343704223633 | KNN Loss: 3.568472146987915 | CLS Loss: 0.03187156468629837\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 3.647514581680298 | KNN Loss: 3.6237599849700928 | CLS Loss: 0.023754650726914406\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 3.634504556655884 | KNN Loss: 3.608055353164673 | CLS Loss: 0.026449237018823624\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 3.668004274368286 | KNN Loss: 3.6267542839050293 | CLS Loss: 0.04124988615512848\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 3.6588308811187744 | KNN Loss: 3.644788980484009 | CLS Loss: 0.014041814021766186\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 3.6513357162475586 | KNN Loss: 3.629910945892334 | CLS Loss: 0.02142472378909588\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 3.6585986614227295 | KNN Loss: 3.634270668029785 | CLS Loss: 0.024327987805008888\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 3.636977434158325 | KNN Loss: 3.5981650352478027 | CLS Loss: 0.038812439888715744\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 3.7170331478118896 | KNN Loss: 3.6347806453704834 | CLS Loss: 0.08225242793560028\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 3.65114164352417 | KNN Loss: 3.605837345123291 | CLS Loss: 0.04530439153313637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 3.6566600799560547 | KNN Loss: 3.6270554065704346 | CLS Loss: 0.02960479073226452\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 3.639728307723999 | KNN Loss: 3.614372968673706 | CLS Loss: 0.025355232879519463\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 3.651150941848755 | KNN Loss: 3.602566719055176 | CLS Loss: 0.048584215342998505\n",
      "Epoch: 024, Loss: 3.6587, Train: 0.9890, Valid: 0.9834, Best: 0.9845\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 3.635643243789673 | KNN Loss: 3.615349292755127 | CLS Loss: 0.020293917506933212\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 3.6388304233551025 | KNN Loss: 3.6025454998016357 | CLS Loss: 0.0362849161028862\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 3.6316399574279785 | KNN Loss: 3.587451219558716 | CLS Loss: 0.04418875649571419\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 3.6823229789733887 | KNN Loss: 3.646953582763672 | CLS Loss: 0.03536949306726456\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 3.6367716789245605 | KNN Loss: 3.6195151805877686 | CLS Loss: 0.017256522551178932\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 3.6521263122558594 | KNN Loss: 3.6077053546905518 | CLS Loss: 0.044420983642339706\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 3.6557154655456543 | KNN Loss: 3.6142542362213135 | CLS Loss: 0.04146122559905052\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 3.6807408332824707 | KNN Loss: 3.6513266563415527 | CLS Loss: 0.029414111748337746\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 3.6625967025756836 | KNN Loss: 3.6356377601623535 | CLS Loss: 0.026958953589200974\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 3.667667865753174 | KNN Loss: 3.629718542098999 | CLS Loss: 0.03794942423701286\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 3.7167813777923584 | KNN Loss: 3.659747838973999 | CLS Loss: 0.05703365430235863\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 3.7272958755493164 | KNN Loss: 3.659787178039551 | CLS Loss: 0.06750870496034622\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 3.700369358062744 | KNN Loss: 3.6454288959503174 | CLS Loss: 0.054940368980169296\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 3.6868340969085693 | KNN Loss: 3.6301345825195312 | CLS Loss: 0.056699488312006\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 3.69932222366333 | KNN Loss: 3.65120005607605 | CLS Loss: 0.048122160136699677\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 3.6354217529296875 | KNN Loss: 3.608308792114258 | CLS Loss: 0.027112891897559166\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 3.7244114875793457 | KNN Loss: 3.651904821395874 | CLS Loss: 0.0725066140294075\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 3.64931058883667 | KNN Loss: 3.626084566116333 | CLS Loss: 0.023225942626595497\n",
      "Epoch: 025, Loss: 3.6657, Train: 0.9907, Valid: 0.9845, Best: 0.9845\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 3.665736198425293 | KNN Loss: 3.629594326019287 | CLS Loss: 0.036141835153102875\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 3.634432315826416 | KNN Loss: 3.6060452461242676 | CLS Loss: 0.028387045487761497\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 3.6845524311065674 | KNN Loss: 3.6523942947387695 | CLS Loss: 0.03215818479657173\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 3.6799635887145996 | KNN Loss: 3.5869452953338623 | CLS Loss: 0.09301824122667313\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 3.6777920722961426 | KNN Loss: 3.6419241428375244 | CLS Loss: 0.035868026316165924\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 3.6869072914123535 | KNN Loss: 3.6487183570861816 | CLS Loss: 0.03818901255726814\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 3.640354871749878 | KNN Loss: 3.6139049530029297 | CLS Loss: 0.026449905708432198\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 3.68945050239563 | KNN Loss: 3.637708902359009 | CLS Loss: 0.05174151062965393\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 3.6394944190979004 | KNN Loss: 3.59238862991333 | CLS Loss: 0.04710590839385986\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 3.6927988529205322 | KNN Loss: 3.667301893234253 | CLS Loss: 0.025496993213891983\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 3.6376771926879883 | KNN Loss: 3.6064460277557373 | CLS Loss: 0.031231069937348366\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 3.704925298690796 | KNN Loss: 3.6529533863067627 | CLS Loss: 0.05197197198867798\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 3.6426539421081543 | KNN Loss: 3.612856388092041 | CLS Loss: 0.029797540977597237\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 3.65605092048645 | KNN Loss: 3.5916943550109863 | CLS Loss: 0.06435656547546387\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 3.6975722312927246 | KNN Loss: 3.645085334777832 | CLS Loss: 0.05248698592185974\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 3.65216064453125 | KNN Loss: 3.6270129680633545 | CLS Loss: 0.025147633627057076\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 3.699125051498413 | KNN Loss: 3.6240413188934326 | CLS Loss: 0.0750836655497551\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 3.6496658325195312 | KNN Loss: 3.6236329078674316 | CLS Loss: 0.02603285387158394\n",
      "Epoch: 026, Loss: 3.6611, Train: 0.9894, Valid: 0.9831, Best: 0.9845\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 3.6956980228424072 | KNN Loss: 3.6498003005981445 | CLS Loss: 0.04589769244194031\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 3.6765737533569336 | KNN Loss: 3.6329662799835205 | CLS Loss: 0.04360755532979965\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 3.6285669803619385 | KNN Loss: 3.606654167175293 | CLS Loss: 0.02191290818154812\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 3.6201207637786865 | KNN Loss: 3.592298746109009 | CLS Loss: 0.027822008356451988\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 3.6679701805114746 | KNN Loss: 3.5954792499542236 | CLS Loss: 0.07249094545841217\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 3.644272565841675 | KNN Loss: 3.6302614212036133 | CLS Loss: 0.014011134393513203\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 3.6206412315368652 | KNN Loss: 3.5806939601898193 | CLS Loss: 0.03994721174240112\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 3.614023208618164 | KNN Loss: 3.582711696624756 | CLS Loss: 0.03131147474050522\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 3.6406333446502686 | KNN Loss: 3.609706401824951 | CLS Loss: 0.030926916748285294\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 3.6338205337524414 | KNN Loss: 3.5898165702819824 | CLS Loss: 0.04400385171175003\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 3.6728689670562744 | KNN Loss: 3.6370701789855957 | CLS Loss: 0.03579872474074364\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 3.6461546421051025 | KNN Loss: 3.615341901779175 | CLS Loss: 0.03081282041966915\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 3.6619985103607178 | KNN Loss: 3.637044668197632 | CLS Loss: 0.024953734129667282\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 3.645059108734131 | KNN Loss: 3.6341233253479004 | CLS Loss: 0.010935881175100803\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 3.6947402954101562 | KNN Loss: 3.6332874298095703 | CLS Loss: 0.0614529512822628\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 3.7245142459869385 | KNN Loss: 3.6894030570983887 | CLS Loss: 0.03511125221848488\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 3.6819660663604736 | KNN Loss: 3.6305341720581055 | CLS Loss: 0.05143185332417488\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 3.689340114593506 | KNN Loss: 3.6628360748291016 | CLS Loss: 0.026503922417759895\n",
      "Epoch: 027, Loss: 3.6665, Train: 0.9874, Valid: 0.9814, Best: 0.9845\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 3.682168483734131 | KNN Loss: 3.645326852798462 | CLS Loss: 0.03684157878160477\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 3.648193120956421 | KNN Loss: 3.602389335632324 | CLS Loss: 0.04580375552177429\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 3.6951701641082764 | KNN Loss: 3.664400339126587 | CLS Loss: 0.030769873410463333\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 3.6482136249542236 | KNN Loss: 3.6195638179779053 | CLS Loss: 0.028649771586060524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 3.6517903804779053 | KNN Loss: 3.6172561645507812 | CLS Loss: 0.03453418239951134\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 3.6446778774261475 | KNN Loss: 3.618469715118408 | CLS Loss: 0.026208214461803436\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 3.6588780879974365 | KNN Loss: 3.629643678665161 | CLS Loss: 0.0292343832552433\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 3.671288251876831 | KNN Loss: 3.6366539001464844 | CLS Loss: 0.03463425859808922\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 3.6374566555023193 | KNN Loss: 3.608553886413574 | CLS Loss: 0.02890276536345482\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 3.6206307411193848 | KNN Loss: 3.610518217086792 | CLS Loss: 0.010112565942108631\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 3.6882412433624268 | KNN Loss: 3.6393935680389404 | CLS Loss: 0.04884764179587364\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 3.6753103733062744 | KNN Loss: 3.6366565227508545 | CLS Loss: 0.03865378350019455\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 3.622725486755371 | KNN Loss: 3.6047089099884033 | CLS Loss: 0.018016478046774864\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 3.645376682281494 | KNN Loss: 3.571521282196045 | CLS Loss: 0.07385535538196564\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 3.659054756164551 | KNN Loss: 3.5951762199401855 | CLS Loss: 0.06387858837842941\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 3.612706422805786 | KNN Loss: 3.5718278884887695 | CLS Loss: 0.04087856039404869\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 3.640292167663574 | KNN Loss: 3.592341184616089 | CLS Loss: 0.04795100539922714\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 3.6472833156585693 | KNN Loss: 3.6359190940856934 | CLS Loss: 0.011364233680069447\n",
      "Epoch: 028, Loss: 3.6649, Train: 0.9914, Valid: 0.9849, Best: 0.9849\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 3.6556057929992676 | KNN Loss: 3.633251667022705 | CLS Loss: 0.022354209795594215\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 3.6322944164276123 | KNN Loss: 3.5978927612304688 | CLS Loss: 0.03440173342823982\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 3.6232588291168213 | KNN Loss: 3.580500364303589 | CLS Loss: 0.042758360505104065\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 3.6404125690460205 | KNN Loss: 3.6160502433776855 | CLS Loss: 0.024362225085496902\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 3.7222235202789307 | KNN Loss: 3.6424758434295654 | CLS Loss: 0.07974765449762344\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 3.6327764987945557 | KNN Loss: 3.623774766921997 | CLS Loss: 0.009001710452139378\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 3.660832405090332 | KNN Loss: 3.60359525680542 | CLS Loss: 0.05723721161484718\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 3.6770172119140625 | KNN Loss: 3.628721237182617 | CLS Loss: 0.04829602688550949\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 3.7058231830596924 | KNN Loss: 3.649082660675049 | CLS Loss: 0.05674058198928833\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 3.6692986488342285 | KNN Loss: 3.6061174869537354 | CLS Loss: 0.06318122148513794\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 3.6392822265625 | KNN Loss: 3.6201629638671875 | CLS Loss: 0.01911914348602295\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 3.7158260345458984 | KNN Loss: 3.6465282440185547 | CLS Loss: 0.0692976713180542\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 3.6648495197296143 | KNN Loss: 3.635403871536255 | CLS Loss: 0.029445718973875046\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 3.6448678970336914 | KNN Loss: 3.620157241821289 | CLS Loss: 0.0247106421738863\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 3.6536104679107666 | KNN Loss: 3.6239688396453857 | CLS Loss: 0.02964172326028347\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 3.6343374252319336 | KNN Loss: 3.58298659324646 | CLS Loss: 0.05135093629360199\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 3.6352739334106445 | KNN Loss: 3.6093742847442627 | CLS Loss: 0.025899672880768776\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 3.669140100479126 | KNN Loss: 3.5963921546936035 | CLS Loss: 0.07274788618087769\n",
      "Epoch: 029, Loss: 3.6598, Train: 0.9895, Valid: 0.9837, Best: 0.9849\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 3.6244266033172607 | KNN Loss: 3.608358144760132 | CLS Loss: 0.016068365424871445\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 3.6546030044555664 | KNN Loss: 3.617762565612793 | CLS Loss: 0.03684047609567642\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 3.72560453414917 | KNN Loss: 3.6460092067718506 | CLS Loss: 0.07959528267383575\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 3.695511817932129 | KNN Loss: 3.6663310527801514 | CLS Loss: 0.02918081358075142\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 3.6901590824127197 | KNN Loss: 3.634319543838501 | CLS Loss: 0.05583957955241203\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 3.6502702236175537 | KNN Loss: 3.638057231903076 | CLS Loss: 0.012213018722832203\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 3.651660442352295 | KNN Loss: 3.6286392211914062 | CLS Loss: 0.023021234199404716\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 3.618027448654175 | KNN Loss: 3.597458839416504 | CLS Loss: 0.020568659529089928\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 3.6957337856292725 | KNN Loss: 3.6400177478790283 | CLS Loss: 0.05571597442030907\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 3.6572532653808594 | KNN Loss: 3.617347002029419 | CLS Loss: 0.03990615904331207\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 3.6436147689819336 | KNN Loss: 3.6340272426605225 | CLS Loss: 0.009587573818862438\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 3.6482112407684326 | KNN Loss: 3.6133503913879395 | CLS Loss: 0.03486090898513794\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 3.6787426471710205 | KNN Loss: 3.619417190551758 | CLS Loss: 0.05932548642158508\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 3.6697304248809814 | KNN Loss: 3.6027145385742188 | CLS Loss: 0.06701581180095673\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 3.6768479347229004 | KNN Loss: 3.6356351375579834 | CLS Loss: 0.04121273383498192\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 3.657961368560791 | KNN Loss: 3.641204595565796 | CLS Loss: 0.016756759956479073\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 3.685230255126953 | KNN Loss: 3.6501452922821045 | CLS Loss: 0.03508494421839714\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 3.629876136779785 | KNN Loss: 3.6011998653411865 | CLS Loss: 0.028676174581050873\n",
      "Epoch: 030, Loss: 3.6603, Train: 0.9921, Valid: 0.9848, Best: 0.9849\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 3.62797212600708 | KNN Loss: 3.605916976928711 | CLS Loss: 0.022055061534047127\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 3.6412806510925293 | KNN Loss: 3.607546091079712 | CLS Loss: 0.03373444452881813\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 3.641491413116455 | KNN Loss: 3.6007895469665527 | CLS Loss: 0.040701813995838165\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 3.6708343029022217 | KNN Loss: 3.604342460632324 | CLS Loss: 0.06649179011583328\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 3.7242095470428467 | KNN Loss: 3.656226873397827 | CLS Loss: 0.06798262894153595\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 3.616048574447632 | KNN Loss: 3.5841920375823975 | CLS Loss: 0.03185658156871796\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 3.6403894424438477 | KNN Loss: 3.627094030380249 | CLS Loss: 0.013295457698404789\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 3.6386172771453857 | KNN Loss: 3.5950939655303955 | CLS Loss: 0.04352334141731262\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 3.648920774459839 | KNN Loss: 3.641808032989502 | CLS Loss: 0.00711267814040184\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 3.642333507537842 | KNN Loss: 3.587087631225586 | CLS Loss: 0.055245984345674515\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 3.6826796531677246 | KNN Loss: 3.6390528678894043 | CLS Loss: 0.043626733124256134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 3.686310291290283 | KNN Loss: 3.6592633724212646 | CLS Loss: 0.027047021314501762\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 3.6658778190612793 | KNN Loss: 3.618687391281128 | CLS Loss: 0.04719039425253868\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 3.7259602546691895 | KNN Loss: 3.6905179023742676 | CLS Loss: 0.0354422889649868\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 3.6128954887390137 | KNN Loss: 3.5914816856384277 | CLS Loss: 0.021413851529359818\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 3.659183979034424 | KNN Loss: 3.6283867359161377 | CLS Loss: 0.030797215178608894\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 3.671973943710327 | KNN Loss: 3.6387782096862793 | CLS Loss: 0.033195625990629196\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 3.6727097034454346 | KNN Loss: 3.6313233375549316 | CLS Loss: 0.04138626158237457\n",
      "Epoch: 031, Loss: 3.6592, Train: 0.9915, Valid: 0.9844, Best: 0.9849\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 3.6669700145721436 | KNN Loss: 3.6402268409729004 | CLS Loss: 0.0267430879175663\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 3.6777596473693848 | KNN Loss: 3.629885673522949 | CLS Loss: 0.04787398502230644\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 3.672558546066284 | KNN Loss: 3.625401258468628 | CLS Loss: 0.04715739190578461\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 3.640063524246216 | KNN Loss: 3.6199562549591064 | CLS Loss: 0.020107155665755272\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 3.7039618492126465 | KNN Loss: 3.671461343765259 | CLS Loss: 0.03250055015087128\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 3.6872451305389404 | KNN Loss: 3.653395652770996 | CLS Loss: 0.03384954109787941\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 3.6531054973602295 | KNN Loss: 3.6283926963806152 | CLS Loss: 0.0247128177434206\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 3.6445603370666504 | KNN Loss: 3.595038890838623 | CLS Loss: 0.04952140524983406\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 3.6687610149383545 | KNN Loss: 3.6220779418945312 | CLS Loss: 0.04668308421969414\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 3.6725986003875732 | KNN Loss: 3.6560606956481934 | CLS Loss: 0.016537858173251152\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 3.695173501968384 | KNN Loss: 3.624087333679199 | CLS Loss: 0.07108619064092636\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 3.636406421661377 | KNN Loss: 3.598018169403076 | CLS Loss: 0.038388147950172424\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 3.6548268795013428 | KNN Loss: 3.6284968852996826 | CLS Loss: 0.026330001652240753\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 3.680591344833374 | KNN Loss: 3.6252410411834717 | CLS Loss: 0.05535023659467697\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 3.647531270980835 | KNN Loss: 3.613603353500366 | CLS Loss: 0.03392782807350159\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 3.625715970993042 | KNN Loss: 3.603119134902954 | CLS Loss: 0.02259676717221737\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 3.687404155731201 | KNN Loss: 3.648775815963745 | CLS Loss: 0.03862845152616501\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 3.6715760231018066 | KNN Loss: 3.6542868614196777 | CLS Loss: 0.017289163544774055\n",
      "Epoch: 032, Loss: 3.6602, Train: 0.9921, Valid: 0.9854, Best: 0.9854\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 3.661651134490967 | KNN Loss: 3.6139426231384277 | CLS Loss: 0.04770848527550697\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 3.665010929107666 | KNN Loss: 3.6350979804992676 | CLS Loss: 0.02991306595504284\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 3.6565334796905518 | KNN Loss: 3.626706838607788 | CLS Loss: 0.029826529324054718\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 3.6416704654693604 | KNN Loss: 3.612579345703125 | CLS Loss: 0.029091190546751022\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 3.679370403289795 | KNN Loss: 3.651385545730591 | CLS Loss: 0.027984878048300743\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 3.657344341278076 | KNN Loss: 3.6300034523010254 | CLS Loss: 0.027340808883309364\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 3.6407010555267334 | KNN Loss: 3.6290338039398193 | CLS Loss: 0.01166736613959074\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 3.6765668392181396 | KNN Loss: 3.623599052429199 | CLS Loss: 0.05296768993139267\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 3.6308035850524902 | KNN Loss: 3.600440740585327 | CLS Loss: 0.03036274015903473\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 3.6700804233551025 | KNN Loss: 3.6356825828552246 | CLS Loss: 0.03439784795045853\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 3.681779384613037 | KNN Loss: 3.648785352706909 | CLS Loss: 0.03299406170845032\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 3.657289505004883 | KNN Loss: 3.630089044570923 | CLS Loss: 0.027200475335121155\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 3.6858201026916504 | KNN Loss: 3.6644327640533447 | CLS Loss: 0.021387405693531036\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 3.6764070987701416 | KNN Loss: 3.6533000469207764 | CLS Loss: 0.023106956854462624\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 3.7006499767303467 | KNN Loss: 3.6731820106506348 | CLS Loss: 0.027467871084809303\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 3.6631827354431152 | KNN Loss: 3.623852491378784 | CLS Loss: 0.039330288767814636\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 3.647871255874634 | KNN Loss: 3.6034839153289795 | CLS Loss: 0.04438737407326698\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 3.628994941711426 | KNN Loss: 3.598750591278076 | CLS Loss: 0.03024441935122013\n",
      "Epoch: 033, Loss: 3.6617, Train: 0.9918, Valid: 0.9852, Best: 0.9854\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 3.674731731414795 | KNN Loss: 3.628722906112671 | CLS Loss: 0.04600884020328522\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 3.6821675300598145 | KNN Loss: 3.644174337387085 | CLS Loss: 0.03799314796924591\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 3.6549530029296875 | KNN Loss: 3.62438702583313 | CLS Loss: 0.030565861612558365\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 3.6433935165405273 | KNN Loss: 3.614820718765259 | CLS Loss: 0.028572840616106987\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 3.649257183074951 | KNN Loss: 3.622969150543213 | CLS Loss: 0.026288021355867386\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 3.682408332824707 | KNN Loss: 3.61710262298584 | CLS Loss: 0.06530559062957764\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 3.662384510040283 | KNN Loss: 3.6365020275115967 | CLS Loss: 0.025882404297590256\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 3.6238327026367188 | KNN Loss: 3.6007015705108643 | CLS Loss: 0.02313103713095188\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 3.682934045791626 | KNN Loss: 3.666416645050049 | CLS Loss: 0.016517288982868195\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 3.668142080307007 | KNN Loss: 3.6407406330108643 | CLS Loss: 0.027401408180594444\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 3.6419990062713623 | KNN Loss: 3.6154022216796875 | CLS Loss: 0.02659686841070652\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 3.689906358718872 | KNN Loss: 3.6385223865509033 | CLS Loss: 0.051384080201387405\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 3.6310975551605225 | KNN Loss: 3.613100051879883 | CLS Loss: 0.017997408285737038\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 3.618063449859619 | KNN Loss: 3.5882411003112793 | CLS Loss: 0.029822276905179024\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 3.626234292984009 | KNN Loss: 3.617002010345459 | CLS Loss: 0.009232166223227978\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 3.6342220306396484 | KNN Loss: 3.6142807006835938 | CLS Loss: 0.01994139887392521\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 3.6474270820617676 | KNN Loss: 3.6130318641662598 | CLS Loss: 0.03439510241150856\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 3.6601922512054443 | KNN Loss: 3.641176223754883 | CLS Loss: 0.01901613175868988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 3.6557, Train: 0.9927, Valid: 0.9858, Best: 0.9858\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 3.6351327896118164 | KNN Loss: 3.611428737640381 | CLS Loss: 0.023704133927822113\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 3.6505351066589355 | KNN Loss: 3.6283681392669678 | CLS Loss: 0.02216694876551628\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 3.664210081100464 | KNN Loss: 3.624635934829712 | CLS Loss: 0.03957405686378479\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 3.6433396339416504 | KNN Loss: 3.614870071411133 | CLS Loss: 0.02846948616206646\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 3.6094255447387695 | KNN Loss: 3.589462995529175 | CLS Loss: 0.01996249333024025\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 3.6713778972625732 | KNN Loss: 3.6424942016601562 | CLS Loss: 0.02888377010822296\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 3.6588034629821777 | KNN Loss: 3.6262643337249756 | CLS Loss: 0.03253912553191185\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 3.648172378540039 | KNN Loss: 3.6224143505096436 | CLS Loss: 0.025758113712072372\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 3.690500259399414 | KNN Loss: 3.659149169921875 | CLS Loss: 0.03135102614760399\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 3.660853624343872 | KNN Loss: 3.6542413234710693 | CLS Loss: 0.006612249184399843\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 3.683274507522583 | KNN Loss: 3.643247604370117 | CLS Loss: 0.04002690315246582\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 3.604149103164673 | KNN Loss: 3.5983972549438477 | CLS Loss: 0.00575190270319581\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 3.6183958053588867 | KNN Loss: 3.58074688911438 | CLS Loss: 0.03764897212386131\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 3.655052423477173 | KNN Loss: 3.640778064727783 | CLS Loss: 0.014274363406002522\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 3.653615951538086 | KNN Loss: 3.6102583408355713 | CLS Loss: 0.043357621878385544\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 3.672196865081787 | KNN Loss: 3.634749174118042 | CLS Loss: 0.03744759038090706\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 3.6850099563598633 | KNN Loss: 3.6532955169677734 | CLS Loss: 0.03171447664499283\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 3.6422080993652344 | KNN Loss: 3.6138782501220703 | CLS Loss: 0.028329869732260704\n",
      "Epoch: 035, Loss: 3.6521, Train: 0.9911, Valid: 0.9831, Best: 0.9858\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 3.646358013153076 | KNN Loss: 3.6136114597320557 | CLS Loss: 0.032746586948633194\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 3.63211727142334 | KNN Loss: 3.5835678577423096 | CLS Loss: 0.048549339175224304\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 3.626997232437134 | KNN Loss: 3.603423833847046 | CLS Loss: 0.02357349544763565\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 3.666215658187866 | KNN Loss: 3.6380367279052734 | CLS Loss: 0.028178980574011803\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 3.6285877227783203 | KNN Loss: 3.589094638824463 | CLS Loss: 0.03949308767914772\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 3.6225156784057617 | KNN Loss: 3.606875419616699 | CLS Loss: 0.015640363097190857\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 3.629035234451294 | KNN Loss: 3.614405870437622 | CLS Loss: 0.014629455283284187\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 3.630685329437256 | KNN Loss: 3.608121395111084 | CLS Loss: 0.022563932463526726\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 3.622293472290039 | KNN Loss: 3.602684736251831 | CLS Loss: 0.019608767703175545\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 3.7064766883850098 | KNN Loss: 3.655597448348999 | CLS Loss: 0.05087912827730179\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 3.631514549255371 | KNN Loss: 3.5827622413635254 | CLS Loss: 0.04875228554010391\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 3.639333486557007 | KNN Loss: 3.6129000186920166 | CLS Loss: 0.026433464139699936\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 3.6621527671813965 | KNN Loss: 3.6175084114074707 | CLS Loss: 0.04464443773031235\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 3.6617441177368164 | KNN Loss: 3.6233723163604736 | CLS Loss: 0.03837186470627785\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 3.6782782077789307 | KNN Loss: 3.6255338191986084 | CLS Loss: 0.05274436995387077\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 3.6233346462249756 | KNN Loss: 3.5997085571289062 | CLS Loss: 0.02362619712948799\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 3.623692750930786 | KNN Loss: 3.5955333709716797 | CLS Loss: 0.02815932035446167\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 3.666234016418457 | KNN Loss: 3.6347365379333496 | CLS Loss: 0.031497564166784286\n",
      "Epoch: 036, Loss: 3.6548, Train: 0.9911, Valid: 0.9840, Best: 0.9858\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 3.6985316276550293 | KNN Loss: 3.669480323791504 | CLS Loss: 0.029051221907138824\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 3.6695961952209473 | KNN Loss: 3.6528022289276123 | CLS Loss: 0.016793865710496902\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 3.660123348236084 | KNN Loss: 3.6457526683807373 | CLS Loss: 0.014370772987604141\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 3.693164348602295 | KNN Loss: 3.665372610092163 | CLS Loss: 0.027791740372776985\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 3.7231733798980713 | KNN Loss: 3.6835570335388184 | CLS Loss: 0.03961623087525368\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 3.682934284210205 | KNN Loss: 3.647993803024292 | CLS Loss: 0.03494048863649368\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 3.651503324508667 | KNN Loss: 3.630300998687744 | CLS Loss: 0.02120223455131054\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 3.6927525997161865 | KNN Loss: 3.66666579246521 | CLS Loss: 0.0260867178440094\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 3.671607732772827 | KNN Loss: 3.6480913162231445 | CLS Loss: 0.02351653203368187\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 3.6554794311523438 | KNN Loss: 3.6500461101531982 | CLS Loss: 0.005433403886854649\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 3.6383020877838135 | KNN Loss: 3.6239750385284424 | CLS Loss: 0.014326963573694229\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 3.6267457008361816 | KNN Loss: 3.6025006771087646 | CLS Loss: 0.024245072156190872\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 3.664573907852173 | KNN Loss: 3.6346192359924316 | CLS Loss: 0.029954707249999046\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 3.664278268814087 | KNN Loss: 3.6471073627471924 | CLS Loss: 0.017170943319797516\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 3.6460773944854736 | KNN Loss: 3.6175100803375244 | CLS Loss: 0.02856726571917534\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 3.6835010051727295 | KNN Loss: 3.6424169540405273 | CLS Loss: 0.041084010154008865\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 3.65744948387146 | KNN Loss: 3.629610538482666 | CLS Loss: 0.02783883921802044\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 3.626922607421875 | KNN Loss: 3.5779869556427 | CLS Loss: 0.04893571510910988\n",
      "Epoch: 037, Loss: 3.6646, Train: 0.9908, Valid: 0.9836, Best: 0.9858\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 3.6570870876312256 | KNN Loss: 3.6154861450195312 | CLS Loss: 0.04160096123814583\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 3.6839771270751953 | KNN Loss: 3.6417903900146484 | CLS Loss: 0.0421866774559021\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 3.623988389968872 | KNN Loss: 3.6043338775634766 | CLS Loss: 0.019654501229524612\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 3.6295382976531982 | KNN Loss: 3.6091363430023193 | CLS Loss: 0.020401928573846817\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 3.6919901371002197 | KNN Loss: 3.6548757553100586 | CLS Loss: 0.03711439296603203\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 3.6708850860595703 | KNN Loss: 3.6572678089141846 | CLS Loss: 0.013617304153740406\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 3.6783673763275146 | KNN Loss: 3.634249210357666 | CLS Loss: 0.04411820322275162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 3.6182613372802734 | KNN Loss: 3.594242572784424 | CLS Loss: 0.024018676951527596\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 3.6807491779327393 | KNN Loss: 3.634270191192627 | CLS Loss: 0.04647887125611305\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 3.674145460128784 | KNN Loss: 3.62239408493042 | CLS Loss: 0.05175129324197769\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 3.6495323181152344 | KNN Loss: 3.6389074325561523 | CLS Loss: 0.010624919086694717\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 3.6816635131835938 | KNN Loss: 3.652076005935669 | CLS Loss: 0.02958747372031212\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 3.6377005577087402 | KNN Loss: 3.6228861808776855 | CLS Loss: 0.014814487658441067\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 3.7147233486175537 | KNN Loss: 3.680055856704712 | CLS Loss: 0.03466740995645523\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 3.7258317470550537 | KNN Loss: 3.70797061920166 | CLS Loss: 0.01786109246313572\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 3.677720785140991 | KNN Loss: 3.626765727996826 | CLS Loss: 0.05095502361655235\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 3.692426919937134 | KNN Loss: 3.6429355144500732 | CLS Loss: 0.049491386860609055\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 3.6283931732177734 | KNN Loss: 3.611109972000122 | CLS Loss: 0.017283247783780098\n",
      "Epoch: 038, Loss: 3.6657, Train: 0.9927, Valid: 0.9863, Best: 0.9863\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 3.654374361038208 | KNN Loss: 3.639683961868286 | CLS Loss: 0.014690479263663292\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 3.672527551651001 | KNN Loss: 3.630776882171631 | CLS Loss: 0.041750647127628326\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 3.632638931274414 | KNN Loss: 3.618424654006958 | CLS Loss: 0.014214211143553257\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 3.6888465881347656 | KNN Loss: 3.6549696922302246 | CLS Loss: 0.03387681022286415\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 3.679560422897339 | KNN Loss: 3.6231608390808105 | CLS Loss: 0.05639960244297981\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 3.6530420780181885 | KNN Loss: 3.638796806335449 | CLS Loss: 0.014245280995965004\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 3.666059970855713 | KNN Loss: 3.6398448944091797 | CLS Loss: 0.02621498703956604\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 3.6789450645446777 | KNN Loss: 3.6440067291259766 | CLS Loss: 0.034938372671604156\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 3.6768267154693604 | KNN Loss: 3.582076072692871 | CLS Loss: 0.09475064277648926\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 3.7193427085876465 | KNN Loss: 3.6764981746673584 | CLS Loss: 0.04284454509615898\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 3.6533443927764893 | KNN Loss: 3.6377429962158203 | CLS Loss: 0.01560143381357193\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 3.678893804550171 | KNN Loss: 3.630368232727051 | CLS Loss: 0.04852565377950668\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 3.658404588699341 | KNN Loss: 3.6298904418945312 | CLS Loss: 0.028514089062809944\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 3.652909517288208 | KNN Loss: 3.626737594604492 | CLS Loss: 0.026171894744038582\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 3.6808509826660156 | KNN Loss: 3.6314327716827393 | CLS Loss: 0.049418117851018906\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 3.739542007446289 | KNN Loss: 3.7143497467041016 | CLS Loss: 0.025192338973283768\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 3.6850266456604004 | KNN Loss: 3.627142906188965 | CLS Loss: 0.05788370966911316\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 3.640892267227173 | KNN Loss: 3.616344451904297 | CLS Loss: 0.024547720327973366\n",
      "Epoch: 039, Loss: 3.6657, Train: 0.9927, Valid: 0.9848, Best: 0.9863\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 3.640782117843628 | KNN Loss: 3.617358922958374 | CLS Loss: 0.023423148319125175\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 3.6768457889556885 | KNN Loss: 3.6488611698150635 | CLS Loss: 0.02798464708030224\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 3.6471128463745117 | KNN Loss: 3.6135590076446533 | CLS Loss: 0.03355373069643974\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 3.6619508266448975 | KNN Loss: 3.6320230960845947 | CLS Loss: 0.029927676543593407\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 3.6708903312683105 | KNN Loss: 3.6246962547302246 | CLS Loss: 0.04619408771395683\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 3.6816132068634033 | KNN Loss: 3.651954412460327 | CLS Loss: 0.029658908024430275\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 3.669938802719116 | KNN Loss: 3.606348991394043 | CLS Loss: 0.06358972191810608\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 3.6730401515960693 | KNN Loss: 3.6470839977264404 | CLS Loss: 0.0259561650454998\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 3.6312007904052734 | KNN Loss: 3.6103951930999756 | CLS Loss: 0.020805511623620987\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 3.654019355773926 | KNN Loss: 3.6175050735473633 | CLS Loss: 0.03651440143585205\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 3.6633808612823486 | KNN Loss: 3.6275899410247803 | CLS Loss: 0.03579089790582657\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 3.6126813888549805 | KNN Loss: 3.600743293762207 | CLS Loss: 0.011938119307160378\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 3.6713449954986572 | KNN Loss: 3.649811029434204 | CLS Loss: 0.021534014493227005\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 3.624453067779541 | KNN Loss: 3.597576379776001 | CLS Loss: 0.026876715943217278\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 3.6818699836730957 | KNN Loss: 3.649296998977661 | CLS Loss: 0.03257308155298233\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 3.621380090713501 | KNN Loss: 3.601574659347534 | CLS Loss: 0.019805381074547768\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 3.6776845455169678 | KNN Loss: 3.618917226791382 | CLS Loss: 0.05876724049448967\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 3.6586248874664307 | KNN Loss: 3.6166810989379883 | CLS Loss: 0.041943762451410294\n",
      "Epoch: 040, Loss: 3.6541, Train: 0.9924, Valid: 0.9841, Best: 0.9863\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 3.6318602561950684 | KNN Loss: 3.6164298057556152 | CLS Loss: 0.015430383384227753\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 3.6513378620147705 | KNN Loss: 3.611398696899414 | CLS Loss: 0.0399392694234848\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 3.671919822692871 | KNN Loss: 3.637355089187622 | CLS Loss: 0.03456474095582962\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 3.681744337081909 | KNN Loss: 3.6359918117523193 | CLS Loss: 0.045752622187137604\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 3.6638636589050293 | KNN Loss: 3.645646810531616 | CLS Loss: 0.018216798081994057\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 3.697822093963623 | KNN Loss: 3.653735399246216 | CLS Loss: 0.04408664628863335\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 3.6795670986175537 | KNN Loss: 3.646415948867798 | CLS Loss: 0.03315126523375511\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 3.647921323776245 | KNN Loss: 3.631815195083618 | CLS Loss: 0.016106173396110535\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 3.6970760822296143 | KNN Loss: 3.6335394382476807 | CLS Loss: 0.06353668868541718\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 3.6359059810638428 | KNN Loss: 3.6141574382781982 | CLS Loss: 0.02174857258796692\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 3.6780056953430176 | KNN Loss: 3.633763551712036 | CLS Loss: 0.044242095202207565\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 3.6606640815734863 | KNN Loss: 3.6366469860076904 | CLS Loss: 0.024017060175538063\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 3.6934940814971924 | KNN Loss: 3.6441869735717773 | CLS Loss: 0.04930715262889862\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 3.626861810684204 | KNN Loss: 3.6059465408325195 | CLS Loss: 0.020915355533361435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 3.7075746059417725 | KNN Loss: 3.659881353378296 | CLS Loss: 0.0476931557059288\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 3.6322319507598877 | KNN Loss: 3.607978582382202 | CLS Loss: 0.02425335720181465\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 3.649883508682251 | KNN Loss: 3.6193301677703857 | CLS Loss: 0.030553355813026428\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 3.6559553146362305 | KNN Loss: 3.6211116313934326 | CLS Loss: 0.034843720495700836\n",
      "Epoch: 041, Loss: 3.6586, Train: 0.9932, Valid: 0.9850, Best: 0.9863\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 3.6240220069885254 | KNN Loss: 3.605971574783325 | CLS Loss: 0.018050508573651314\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 3.702122688293457 | KNN Loss: 3.6732213497161865 | CLS Loss: 0.02890133112668991\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 3.659257411956787 | KNN Loss: 3.6155362129211426 | CLS Loss: 0.04372125118970871\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 3.6778383255004883 | KNN Loss: 3.636369228363037 | CLS Loss: 0.041469212621450424\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 3.6945838928222656 | KNN Loss: 3.682509660720825 | CLS Loss: 0.012074307538568974\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 3.679619789123535 | KNN Loss: 3.6084799766540527 | CLS Loss: 0.07113993167877197\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 3.6553714275360107 | KNN Loss: 3.643580913543701 | CLS Loss: 0.011790581047534943\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 3.6978919506073 | KNN Loss: 3.667384386062622 | CLS Loss: 0.030507469549775124\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 3.6816205978393555 | KNN Loss: 3.6606132984161377 | CLS Loss: 0.02100726030766964\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 3.6240170001983643 | KNN Loss: 3.5854647159576416 | CLS Loss: 0.038552314043045044\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 3.635392427444458 | KNN Loss: 3.623260736465454 | CLS Loss: 0.012131728231906891\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 3.6795575618743896 | KNN Loss: 3.619659900665283 | CLS Loss: 0.05989774316549301\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 3.6343021392822266 | KNN Loss: 3.6067280769348145 | CLS Loss: 0.027574069797992706\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 3.6540169715881348 | KNN Loss: 3.637150287628174 | CLS Loss: 0.016866689547896385\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 3.629915714263916 | KNN Loss: 3.6117987632751465 | CLS Loss: 0.018116949126124382\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 3.6720879077911377 | KNN Loss: 3.6331214904785156 | CLS Loss: 0.03896639496088028\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 3.6315627098083496 | KNN Loss: 3.61183762550354 | CLS Loss: 0.019725069403648376\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 3.6652894020080566 | KNN Loss: 3.649482488632202 | CLS Loss: 0.01580684445798397\n",
      "Epoch: 042, Loss: 3.6549, Train: 0.9943, Valid: 0.9861, Best: 0.9863\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 3.6469902992248535 | KNN Loss: 3.631808042526245 | CLS Loss: 0.01518215797841549\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 3.6800549030303955 | KNN Loss: 3.6614747047424316 | CLS Loss: 0.018580177798867226\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 3.656384229660034 | KNN Loss: 3.6244451999664307 | CLS Loss: 0.0319390594959259\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 3.6614761352539062 | KNN Loss: 3.6443099975585938 | CLS Loss: 0.0171661339700222\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 3.6955883502960205 | KNN Loss: 3.6651670932769775 | CLS Loss: 0.03042123094201088\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 3.716064214706421 | KNN Loss: 3.659986734390259 | CLS Loss: 0.05607747659087181\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 3.619856357574463 | KNN Loss: 3.600627899169922 | CLS Loss: 0.01922834850847721\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 3.6503543853759766 | KNN Loss: 3.6433846950531006 | CLS Loss: 0.006969626992940903\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 3.6151230335235596 | KNN Loss: 3.590975522994995 | CLS Loss: 0.024147622287273407\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 3.6473374366760254 | KNN Loss: 3.625636339187622 | CLS Loss: 0.021701013669371605\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 3.635373115539551 | KNN Loss: 3.6201422214508057 | CLS Loss: 0.015230958350002766\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 3.6812233924865723 | KNN Loss: 3.6589317321777344 | CLS Loss: 0.022291718050837517\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 3.6629724502563477 | KNN Loss: 3.6530487537384033 | CLS Loss: 0.009923704899847507\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 3.6521384716033936 | KNN Loss: 3.6260242462158203 | CLS Loss: 0.02611417882144451\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 3.662670612335205 | KNN Loss: 3.6450164318084717 | CLS Loss: 0.01765422709286213\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 3.6983799934387207 | KNN Loss: 3.6353142261505127 | CLS Loss: 0.06306588649749756\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 3.6831247806549072 | KNN Loss: 3.6443254947662354 | CLS Loss: 0.03879940137267113\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 3.627514600753784 | KNN Loss: 3.6141843795776367 | CLS Loss: 0.013330337591469288\n",
      "Epoch: 043, Loss: 3.6620, Train: 0.9932, Valid: 0.9853, Best: 0.9863\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 3.658158779144287 | KNN Loss: 3.6533186435699463 | CLS Loss: 0.004840245470404625\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 3.647378921508789 | KNN Loss: 3.6174139976501465 | CLS Loss: 0.029965022578835487\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 3.647233486175537 | KNN Loss: 3.619981050491333 | CLS Loss: 0.027252551168203354\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 3.6577959060668945 | KNN Loss: 3.630587339401245 | CLS Loss: 0.027208644896745682\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 3.667776346206665 | KNN Loss: 3.6199309825897217 | CLS Loss: 0.04784535616636276\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 3.6055617332458496 | KNN Loss: 3.5805726051330566 | CLS Loss: 0.024989185854792595\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 3.702160358428955 | KNN Loss: 3.6549947261810303 | CLS Loss: 0.047165703028440475\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 3.736096143722534 | KNN Loss: 3.6843340396881104 | CLS Loss: 0.051762185990810394\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 3.660159111022949 | KNN Loss: 3.6145336627960205 | CLS Loss: 0.04562535881996155\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 3.681508779525757 | KNN Loss: 3.6341896057128906 | CLS Loss: 0.04731927067041397\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 3.7196505069732666 | KNN Loss: 3.6949915885925293 | CLS Loss: 0.024658866226673126\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 3.623368501663208 | KNN Loss: 3.610872507095337 | CLS Loss: 0.012495890259742737\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 3.6610705852508545 | KNN Loss: 3.6461846828460693 | CLS Loss: 0.014885872602462769\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 3.654635429382324 | KNN Loss: 3.642317056655884 | CLS Loss: 0.0123183224350214\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 3.676720142364502 | KNN Loss: 3.6238529682159424 | CLS Loss: 0.05286720395088196\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 3.654482126235962 | KNN Loss: 3.6218063831329346 | CLS Loss: 0.03267564997076988\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 3.665678024291992 | KNN Loss: 3.6237668991088867 | CLS Loss: 0.04191101714968681\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 3.635983943939209 | KNN Loss: 3.6209683418273926 | CLS Loss: 0.015015638433396816\n",
      "Epoch: 044, Loss: 3.6544, Train: 0.9925, Valid: 0.9860, Best: 0.9863\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 3.6335997581481934 | KNN Loss: 3.625443696975708 | CLS Loss: 0.00815604068338871\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 3.6123247146606445 | KNN Loss: 3.5936686992645264 | CLS Loss: 0.018655939027667046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 3.606844186782837 | KNN Loss: 3.5996198654174805 | CLS Loss: 0.00722424266859889\n",
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 3.646623373031616 | KNN Loss: 3.611558198928833 | CLS Loss: 0.035065069794654846\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 3.631519079208374 | KNN Loss: 3.6012954711914062 | CLS Loss: 0.030223648995161057\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 3.649301767349243 | KNN Loss: 3.6111438274383545 | CLS Loss: 0.038157861679792404\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 3.6337218284606934 | KNN Loss: 3.6242470741271973 | CLS Loss: 0.009474842809140682\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 3.592681646347046 | KNN Loss: 3.579632520675659 | CLS Loss: 0.013049175031483173\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 3.647430181503296 | KNN Loss: 3.582977533340454 | CLS Loss: 0.0644526258111\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 3.6700057983398438 | KNN Loss: 3.64081072807312 | CLS Loss: 0.02919502928853035\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 3.66192364692688 | KNN Loss: 3.639284372329712 | CLS Loss: 0.02263934724032879\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 3.6698219776153564 | KNN Loss: 3.647223472595215 | CLS Loss: 0.02259845659136772\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 3.62859845161438 | KNN Loss: 3.593722105026245 | CLS Loss: 0.03487640991806984\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 3.6643102169036865 | KNN Loss: 3.615817070007324 | CLS Loss: 0.04849319905042648\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 3.624194622039795 | KNN Loss: 3.602980375289917 | CLS Loss: 0.021214308217167854\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 3.632861852645874 | KNN Loss: 3.6182806491851807 | CLS Loss: 0.014581169933080673\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 3.6416549682617188 | KNN Loss: 3.631132125854492 | CLS Loss: 0.010522833094000816\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 3.6774704456329346 | KNN Loss: 3.6511476039886475 | CLS Loss: 0.0263228639960289\n",
      "Epoch: 045, Loss: 3.6516, Train: 0.9922, Valid: 0.9855, Best: 0.9863\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 3.6532669067382812 | KNN Loss: 3.6176300048828125 | CLS Loss: 0.03563692420721054\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 3.643949270248413 | KNN Loss: 3.604217052459717 | CLS Loss: 0.03973212093114853\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 3.632261037826538 | KNN Loss: 3.589885950088501 | CLS Loss: 0.04237499460577965\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 3.6408607959747314 | KNN Loss: 3.6073014736175537 | CLS Loss: 0.033559225499629974\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 3.6497678756713867 | KNN Loss: 3.6218886375427246 | CLS Loss: 0.027879321947693825\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 3.64542293548584 | KNN Loss: 3.6244959831237793 | CLS Loss: 0.020927056670188904\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 3.6973116397857666 | KNN Loss: 3.673434257507324 | CLS Loss: 0.023877425119280815\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 3.649519920349121 | KNN Loss: 3.6281440258026123 | CLS Loss: 0.02137584425508976\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 3.6489412784576416 | KNN Loss: 3.638442277908325 | CLS Loss: 0.010499095544219017\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 3.690647840499878 | KNN Loss: 3.643765926361084 | CLS Loss: 0.04688191041350365\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 3.630420446395874 | KNN Loss: 3.5967214107513428 | CLS Loss: 0.03369913622736931\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 3.6117303371429443 | KNN Loss: 3.6001129150390625 | CLS Loss: 0.01161748357117176\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 3.65002703666687 | KNN Loss: 3.6092336177825928 | CLS Loss: 0.040793366730213165\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 3.6283092498779297 | KNN Loss: 3.611006021499634 | CLS Loss: 0.01730327121913433\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 3.649280071258545 | KNN Loss: 3.626169204711914 | CLS Loss: 0.02311084233224392\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 3.628512144088745 | KNN Loss: 3.6011111736297607 | CLS Loss: 0.027400974184274673\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 3.6714093685150146 | KNN Loss: 3.6334784030914307 | CLS Loss: 0.03793088346719742\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 3.633986711502075 | KNN Loss: 3.6043875217437744 | CLS Loss: 0.02959909848868847\n",
      "Epoch: 046, Loss: 3.6519, Train: 0.9928, Valid: 0.9840, Best: 0.9863\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 3.6538827419281006 | KNN Loss: 3.6168360710144043 | CLS Loss: 0.037046756595373154\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 3.6121177673339844 | KNN Loss: 3.594010829925537 | CLS Loss: 0.01810700260102749\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 3.6668901443481445 | KNN Loss: 3.6404078006744385 | CLS Loss: 0.026482271030545235\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 3.667017936706543 | KNN Loss: 3.6507561206817627 | CLS Loss: 0.016261806711554527\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 3.631270170211792 | KNN Loss: 3.5987820625305176 | CLS Loss: 0.032488081604242325\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 3.665611982345581 | KNN Loss: 3.6182470321655273 | CLS Loss: 0.04736486077308655\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 3.6114425659179688 | KNN Loss: 3.6013317108154297 | CLS Loss: 0.01011088490486145\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 3.611431121826172 | KNN Loss: 3.6057584285736084 | CLS Loss: 0.005672747734934092\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 3.642815351486206 | KNN Loss: 3.631053924560547 | CLS Loss: 0.011761423200368881\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 3.6273458003997803 | KNN Loss: 3.6145687103271484 | CLS Loss: 0.012777052819728851\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 3.6116552352905273 | KNN Loss: 3.57719349861145 | CLS Loss: 0.03446178883314133\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 3.640829086303711 | KNN Loss: 3.5913021564483643 | CLS Loss: 0.04952693730592728\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 3.610863208770752 | KNN Loss: 3.589599609375 | CLS Loss: 0.021263668313622475\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 3.6222195625305176 | KNN Loss: 3.610677719116211 | CLS Loss: 0.011541738174855709\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 3.6542701721191406 | KNN Loss: 3.639505624771118 | CLS Loss: 0.014764624647796154\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 3.639510154724121 | KNN Loss: 3.608569622039795 | CLS Loss: 0.030940528959035873\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 3.7613906860351562 | KNN Loss: 3.7228870391845703 | CLS Loss: 0.03850356861948967\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 3.6041221618652344 | KNN Loss: 3.59224534034729 | CLS Loss: 0.011876816861331463\n",
      "Epoch: 047, Loss: 3.6519, Train: 0.9932, Valid: 0.9848, Best: 0.9863\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 3.661764621734619 | KNN Loss: 3.637331485748291 | CLS Loss: 0.024433135986328125\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 3.6301963329315186 | KNN Loss: 3.621452569961548 | CLS Loss: 0.008743783459067345\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 3.7204599380493164 | KNN Loss: 3.707993507385254 | CLS Loss: 0.012466346845030785\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 3.638185977935791 | KNN Loss: 3.6143429279327393 | CLS Loss: 0.02384306490421295\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 3.6302263736724854 | KNN Loss: 3.6163063049316406 | CLS Loss: 0.013920157216489315\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 3.658510446548462 | KNN Loss: 3.6397998332977295 | CLS Loss: 0.018710505217313766\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 3.7269446849823 | KNN Loss: 3.68204665184021 | CLS Loss: 0.04489807039499283\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 3.6849498748779297 | KNN Loss: 3.6018638610839844 | CLS Loss: 0.08308590203523636\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 3.6464121341705322 | KNN Loss: 3.6272025108337402 | CLS Loss: 0.01920958422124386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 3.63954496383667 | KNN Loss: 3.621581792831421 | CLS Loss: 0.017963232472538948\n",
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 3.6340675354003906 | KNN Loss: 3.605264663696289 | CLS Loss: 0.028802908957004547\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 3.63861346244812 | KNN Loss: 3.6154401302337646 | CLS Loss: 0.023173406720161438\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 3.679769277572632 | KNN Loss: 3.641517400741577 | CLS Loss: 0.038251809775829315\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 3.6917829513549805 | KNN Loss: 3.675417423248291 | CLS Loss: 0.016365446150302887\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 3.6352436542510986 | KNN Loss: 3.6241824626922607 | CLS Loss: 0.01106125395745039\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 3.627027750015259 | KNN Loss: 3.5985138416290283 | CLS Loss: 0.028513982892036438\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 3.662531614303589 | KNN Loss: 3.6320717334747314 | CLS Loss: 0.030459847301244736\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 3.6411821842193604 | KNN Loss: 3.6284258365631104 | CLS Loss: 0.01275627687573433\n",
      "Epoch: 048, Loss: 3.6527, Train: 0.9924, Valid: 0.9836, Best: 0.9863\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 3.697768211364746 | KNN Loss: 3.646545171737671 | CLS Loss: 0.05122314393520355\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 3.6351819038391113 | KNN Loss: 3.6244618892669678 | CLS Loss: 0.010719971731305122\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 3.668790578842163 | KNN Loss: 3.6280643939971924 | CLS Loss: 0.040726106613874435\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 3.7410523891448975 | KNN Loss: 3.7231383323669434 | CLS Loss: 0.017914146184921265\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 3.6573233604431152 | KNN Loss: 3.631744861602783 | CLS Loss: 0.025578530505299568\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 3.6294543743133545 | KNN Loss: 3.6083312034606934 | CLS Loss: 0.021123062819242477\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 3.619748115539551 | KNN Loss: 3.5930674076080322 | CLS Loss: 0.026680603623390198\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 3.6607465744018555 | KNN Loss: 3.6395602226257324 | CLS Loss: 0.02118632383644581\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 3.6556711196899414 | KNN Loss: 3.629915714263916 | CLS Loss: 0.02575547806918621\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 3.6651322841644287 | KNN Loss: 3.61655855178833 | CLS Loss: 0.048573706299066544\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 3.6843597888946533 | KNN Loss: 3.6515445709228516 | CLS Loss: 0.03281513601541519\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 3.6765010356903076 | KNN Loss: 3.6434779167175293 | CLS Loss: 0.03302321583032608\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 3.639280080795288 | KNN Loss: 3.6267285346984863 | CLS Loss: 0.012551439926028252\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 3.6136109828948975 | KNN Loss: 3.5941617488861084 | CLS Loss: 0.019449206069111824\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 3.7113513946533203 | KNN Loss: 3.648189067840576 | CLS Loss: 0.06316225230693817\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 3.624202251434326 | KNN Loss: 3.618793249130249 | CLS Loss: 0.005408926866948605\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 3.6260437965393066 | KNN Loss: 3.6139719486236572 | CLS Loss: 0.012071805074810982\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 3.636582136154175 | KNN Loss: 3.6279194355010986 | CLS Loss: 0.008662788197398186\n",
      "Epoch: 049, Loss: 3.6492, Train: 0.9948, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 3.6467437744140625 | KNN Loss: 3.613652467727661 | CLS Loss: 0.03309138864278793\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 3.6048736572265625 | KNN Loss: 3.5990660190582275 | CLS Loss: 0.0058076814748346806\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 3.6379761695861816 | KNN Loss: 3.6184275150299072 | CLS Loss: 0.019548561424016953\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 3.649507999420166 | KNN Loss: 3.6089367866516113 | CLS Loss: 0.040571097284555435\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 3.6483757495880127 | KNN Loss: 3.620075225830078 | CLS Loss: 0.028300637379288673\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 3.644688606262207 | KNN Loss: 3.613192081451416 | CLS Loss: 0.031496524810791016\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 3.6188552379608154 | KNN Loss: 3.60616135597229 | CLS Loss: 0.012693995609879494\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 3.65281081199646 | KNN Loss: 3.61600923538208 | CLS Loss: 0.036801520735025406\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 3.6391704082489014 | KNN Loss: 3.607611894607544 | CLS Loss: 0.031558532267808914\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 3.6407182216644287 | KNN Loss: 3.6195900440216064 | CLS Loss: 0.02112826332449913\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 3.6567111015319824 | KNN Loss: 3.622637987136841 | CLS Loss: 0.034073129296302795\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 3.6215920448303223 | KNN Loss: 3.5682473182678223 | CLS Loss: 0.05334465205669403\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 3.6274139881134033 | KNN Loss: 3.6011083126068115 | CLS Loss: 0.02630576305091381\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 3.679774045944214 | KNN Loss: 3.652467966079712 | CLS Loss: 0.02730615995824337\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 3.648913621902466 | KNN Loss: 3.635331630706787 | CLS Loss: 0.013581942766904831\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 3.633688449859619 | KNN Loss: 3.617650032043457 | CLS Loss: 0.016038503497838974\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 3.637561321258545 | KNN Loss: 3.590210199356079 | CLS Loss: 0.04735110327601433\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 3.706218719482422 | KNN Loss: 3.6840124130249023 | CLS Loss: 0.022206377238035202\n",
      "Epoch: 050, Loss: 3.6492, Train: 0.9943, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 3.59941029548645 | KNN Loss: 3.5913331508636475 | CLS Loss: 0.008077203296124935\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 3.685964822769165 | KNN Loss: 3.6641345024108887 | CLS Loss: 0.02183036506175995\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 3.6392011642456055 | KNN Loss: 3.608515977859497 | CLS Loss: 0.030685098841786385\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 3.6208322048187256 | KNN Loss: 3.6007869243621826 | CLS Loss: 0.020045258104801178\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 3.62722110748291 | KNN Loss: 3.623577117919922 | CLS Loss: 0.0036440042313188314\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 3.6263251304626465 | KNN Loss: 3.6011812686920166 | CLS Loss: 0.02514396235346794\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 3.647986650466919 | KNN Loss: 3.619858503341675 | CLS Loss: 0.02812817320227623\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 3.6849300861358643 | KNN Loss: 3.623654365539551 | CLS Loss: 0.06127580627799034\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 3.6267940998077393 | KNN Loss: 3.6067898273468018 | CLS Loss: 0.02000434510409832\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 3.645634174346924 | KNN Loss: 3.624506711959839 | CLS Loss: 0.021127518266439438\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 3.672501802444458 | KNN Loss: 3.647336959838867 | CLS Loss: 0.025164838880300522\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 3.663057565689087 | KNN Loss: 3.642066478729248 | CLS Loss: 0.020991194993257523\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 3.632058620452881 | KNN Loss: 3.617934465408325 | CLS Loss: 0.014124062843620777\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 3.616164445877075 | KNN Loss: 3.587754964828491 | CLS Loss: 0.02840944193303585\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 3.615297317504883 | KNN Loss: 3.603410482406616 | CLS Loss: 0.01188687328249216\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 3.6930038928985596 | KNN Loss: 3.672405481338501 | CLS Loss: 0.020598480477929115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 3.706047534942627 | KNN Loss: 3.6429874897003174 | CLS Loss: 0.06306011229753494\n",
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 3.6699507236480713 | KNN Loss: 3.644773244857788 | CLS Loss: 0.025177521631121635\n",
      "Epoch: 051, Loss: 3.6483, Train: 0.9939, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 3.6316661834716797 | KNN Loss: 3.607577323913574 | CLS Loss: 0.024088917300105095\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 3.6518542766571045 | KNN Loss: 3.618896007537842 | CLS Loss: 0.03295822814106941\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 3.6706149578094482 | KNN Loss: 3.6519784927368164 | CLS Loss: 0.018636571243405342\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 3.651196241378784 | KNN Loss: 3.639460325241089 | CLS Loss: 0.011735948733985424\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 3.6370701789855957 | KNN Loss: 3.6106810569763184 | CLS Loss: 0.02638903819024563\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 3.678068161010742 | KNN Loss: 3.6392276287078857 | CLS Loss: 0.03884061798453331\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 3.641695737838745 | KNN Loss: 3.6175191402435303 | CLS Loss: 0.02417660877108574\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 3.631826639175415 | KNN Loss: 3.616116523742676 | CLS Loss: 0.015710139647126198\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 3.6688547134399414 | KNN Loss: 3.650054454803467 | CLS Loss: 0.01880037784576416\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 3.6316921710968018 | KNN Loss: 3.6124565601348877 | CLS Loss: 0.019235575571656227\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 3.6301181316375732 | KNN Loss: 3.6078455448150635 | CLS Loss: 0.02227257937192917\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 3.693467855453491 | KNN Loss: 3.6500585079193115 | CLS Loss: 0.04340924322605133\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 3.6475634574890137 | KNN Loss: 3.623518466949463 | CLS Loss: 0.024045070633292198\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 3.6319949626922607 | KNN Loss: 3.597796678543091 | CLS Loss: 0.03419823572039604\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 3.6666667461395264 | KNN Loss: 3.6522819995880127 | CLS Loss: 0.01438471395522356\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 3.6183676719665527 | KNN Loss: 3.600369930267334 | CLS Loss: 0.017997773364186287\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 3.643172025680542 | KNN Loss: 3.6195287704467773 | CLS Loss: 0.023643266409635544\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 3.650050163269043 | KNN Loss: 3.6383273601531982 | CLS Loss: 0.011722762137651443\n",
      "Epoch: 052, Loss: 3.6480, Train: 0.9938, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 3.6460251808166504 | KNN Loss: 3.6351747512817383 | CLS Loss: 0.010850388556718826\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 3.67730712890625 | KNN Loss: 3.6681911945343018 | CLS Loss: 0.009115912020206451\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 3.6697428226470947 | KNN Loss: 3.63742733001709 | CLS Loss: 0.03231541067361832\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 3.6821022033691406 | KNN Loss: 3.667994737625122 | CLS Loss: 0.014107427559792995\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 3.6350138187408447 | KNN Loss: 3.6245357990264893 | CLS Loss: 0.010477911680936813\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 3.6383283138275146 | KNN Loss: 3.6073408126831055 | CLS Loss: 0.030987421050667763\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 3.651340961456299 | KNN Loss: 3.608279228210449 | CLS Loss: 0.04306182637810707\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 3.6353919506073 | KNN Loss: 3.6197876930236816 | CLS Loss: 0.015604272484779358\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 3.6564064025878906 | KNN Loss: 3.6235547065734863 | CLS Loss: 0.03285177797079086\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 3.648425817489624 | KNN Loss: 3.640791416168213 | CLS Loss: 0.007634403184056282\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 3.672245740890503 | KNN Loss: 3.638486623764038 | CLS Loss: 0.0337592214345932\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 3.67085599899292 | KNN Loss: 3.6441497802734375 | CLS Loss: 0.026706119999289513\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 3.6346940994262695 | KNN Loss: 3.630293607711792 | CLS Loss: 0.004400517791509628\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 3.6436071395874023 | KNN Loss: 3.6038944721221924 | CLS Loss: 0.03971258923411369\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 3.6442630290985107 | KNN Loss: 3.6273512840270996 | CLS Loss: 0.016911718994379044\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 3.744241952896118 | KNN Loss: 3.7075562477111816 | CLS Loss: 0.03668561950325966\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 3.5920979976654053 | KNN Loss: 3.5769331455230713 | CLS Loss: 0.015164748765528202\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 3.6558947563171387 | KNN Loss: 3.650465488433838 | CLS Loss: 0.005429357755929232\n",
      "Epoch: 053, Loss: 3.6503, Train: 0.9936, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 3.6506900787353516 | KNN Loss: 3.608166456222534 | CLS Loss: 0.04252363741397858\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 3.66629695892334 | KNN Loss: 3.630934238433838 | CLS Loss: 0.035362739115953445\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 3.6879003047943115 | KNN Loss: 3.643795967102051 | CLS Loss: 0.04410434514284134\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 3.633125066757202 | KNN Loss: 3.5989139080047607 | CLS Loss: 0.03421126678586006\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 3.6231751441955566 | KNN Loss: 3.5988879203796387 | CLS Loss: 0.024287214502692223\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 3.6616735458374023 | KNN Loss: 3.6224496364593506 | CLS Loss: 0.03922394663095474\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 3.6356780529022217 | KNN Loss: 3.620479106903076 | CLS Loss: 0.015198839828372002\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 3.710343837738037 | KNN Loss: 3.686738967895508 | CLS Loss: 0.023604927584528923\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 3.652751922607422 | KNN Loss: 3.633277416229248 | CLS Loss: 0.019474590197205544\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 3.6314756870269775 | KNN Loss: 3.620445489883423 | CLS Loss: 0.011030237190425396\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 3.6980206966400146 | KNN Loss: 3.640869379043579 | CLS Loss: 0.05715130642056465\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 3.5930421352386475 | KNN Loss: 3.584552526473999 | CLS Loss: 0.0084895184263587\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 3.631260871887207 | KNN Loss: 3.599769353866577 | CLS Loss: 0.03149162977933884\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 3.672809362411499 | KNN Loss: 3.633336305618286 | CLS Loss: 0.03947305679321289\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 3.6572446823120117 | KNN Loss: 3.631335735321045 | CLS Loss: 0.02590884640812874\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 3.6882035732269287 | KNN Loss: 3.6690680980682373 | CLS Loss: 0.01913558319211006\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 3.6572213172912598 | KNN Loss: 3.614445924758911 | CLS Loss: 0.04277532547712326\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 3.626992702484131 | KNN Loss: 3.609309434890747 | CLS Loss: 0.017683347687125206\n",
      "Epoch: 054, Loss: 3.6471, Train: 0.9940, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 3.606182098388672 | KNN Loss: 3.5842411518096924 | CLS Loss: 0.021940981969237328\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 3.6261441707611084 | KNN Loss: 3.6118688583374023 | CLS Loss: 0.014275300316512585\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 3.66200852394104 | KNN Loss: 3.6433537006378174 | CLS Loss: 0.01865476928651333\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 3.6392548084259033 | KNN Loss: 3.609727621078491 | CLS Loss: 0.029527200385928154\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 3.6688551902770996 | KNN Loss: 3.636079788208008 | CLS Loss: 0.032775286585092545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 3.6613314151763916 | KNN Loss: 3.6292049884796143 | CLS Loss: 0.03212636336684227\n",
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 3.643455743789673 | KNN Loss: 3.606968641281128 | CLS Loss: 0.03648701310157776\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 3.6610770225524902 | KNN Loss: 3.632298231124878 | CLS Loss: 0.028778746724128723\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 3.6350581645965576 | KNN Loss: 3.5970938205718994 | CLS Loss: 0.03796426206827164\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 3.617839813232422 | KNN Loss: 3.6127371788024902 | CLS Loss: 0.005102622788399458\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 3.666402578353882 | KNN Loss: 3.642460584640503 | CLS Loss: 0.023941950872540474\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 3.65158748626709 | KNN Loss: 3.626426935195923 | CLS Loss: 0.025160498917102814\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 3.663989543914795 | KNN Loss: 3.6523149013519287 | CLS Loss: 0.011674649082124233\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 3.730393648147583 | KNN Loss: 3.6915624141693115 | CLS Loss: 0.038831278681755066\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 3.6278810501098633 | KNN Loss: 3.614072561264038 | CLS Loss: 0.013808608055114746\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 3.606755495071411 | KNN Loss: 3.5878658294677734 | CLS Loss: 0.01888967677950859\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 3.644813060760498 | KNN Loss: 3.6104984283447266 | CLS Loss: 0.0343145988881588\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 3.6119489669799805 | KNN Loss: 3.6057028770446777 | CLS Loss: 0.006246192846447229\n",
      "Epoch: 055, Loss: 3.6487, Train: 0.9952, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 3.661402940750122 | KNN Loss: 3.6420929431915283 | CLS Loss: 0.01931011490523815\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 3.66156268119812 | KNN Loss: 3.6255154609680176 | CLS Loss: 0.036047328263521194\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 3.6278820037841797 | KNN Loss: 3.6197597980499268 | CLS Loss: 0.008122223429381847\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 3.6744494438171387 | KNN Loss: 3.6594905853271484 | CLS Loss: 0.014958787709474564\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 3.633655071258545 | KNN Loss: 3.6018226146698 | CLS Loss: 0.03183255344629288\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 3.6361255645751953 | KNN Loss: 3.62137508392334 | CLS Loss: 0.014750583097338676\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 3.640752077102661 | KNN Loss: 3.6326780319213867 | CLS Loss: 0.008074047975242138\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 3.687586784362793 | KNN Loss: 3.6698074340820312 | CLS Loss: 0.017779309302568436\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 3.6356053352355957 | KNN Loss: 3.606144428253174 | CLS Loss: 0.029460789635777473\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 3.6444170475006104 | KNN Loss: 3.5893704891204834 | CLS Loss: 0.05504661053419113\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 3.6397335529327393 | KNN Loss: 3.622565507888794 | CLS Loss: 0.017167964950203896\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 3.6518990993499756 | KNN Loss: 3.6284852027893066 | CLS Loss: 0.023413943126797676\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 3.629859685897827 | KNN Loss: 3.624147415161133 | CLS Loss: 0.005712331738322973\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 3.6418564319610596 | KNN Loss: 3.6235110759735107 | CLS Loss: 0.018345413729548454\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 3.650890350341797 | KNN Loss: 3.6360652446746826 | CLS Loss: 0.014825101010501385\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 3.640249252319336 | KNN Loss: 3.6214308738708496 | CLS Loss: 0.018818343058228493\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 3.6463778018951416 | KNN Loss: 3.616384506225586 | CLS Loss: 0.02999340184032917\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 3.6228225231170654 | KNN Loss: 3.609259843826294 | CLS Loss: 0.013562780804932117\n",
      "Epoch: 056, Loss: 3.6449, Train: 0.9938, Valid: 0.9846, Best: 0.9873\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 3.641007900238037 | KNN Loss: 3.5985043048858643 | CLS Loss: 0.04250369593501091\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 3.6318399906158447 | KNN Loss: 3.6130425930023193 | CLS Loss: 0.0187973789870739\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 3.6284549236297607 | KNN Loss: 3.605221748352051 | CLS Loss: 0.02323317527770996\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 3.6112818717956543 | KNN Loss: 3.601412057876587 | CLS Loss: 0.009869725443422794\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 3.665309429168701 | KNN Loss: 3.641653299331665 | CLS Loss: 0.023656103760004044\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 3.6581614017486572 | KNN Loss: 3.6260464191436768 | CLS Loss: 0.03211500868201256\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 3.6094205379486084 | KNN Loss: 3.603027582168579 | CLS Loss: 0.006392979994416237\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 3.6534647941589355 | KNN Loss: 3.6393768787384033 | CLS Loss: 0.014087814837694168\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 3.650846242904663 | KNN Loss: 3.633805751800537 | CLS Loss: 0.017040515318512917\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 3.6491236686706543 | KNN Loss: 3.616788864135742 | CLS Loss: 0.03233477845788002\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 3.6640074253082275 | KNN Loss: 3.623610258102417 | CLS Loss: 0.04039708152413368\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 3.6708245277404785 | KNN Loss: 3.6459741592407227 | CLS Loss: 0.024850325658917427\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 3.6483216285705566 | KNN Loss: 3.6440069675445557 | CLS Loss: 0.004314725287258625\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 3.620377540588379 | KNN Loss: 3.5971813201904297 | CLS Loss: 0.023196140304207802\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 3.637481212615967 | KNN Loss: 3.5899808406829834 | CLS Loss: 0.0475003719329834\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 3.607795238494873 | KNN Loss: 3.59590220451355 | CLS Loss: 0.011893109418451786\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 3.628321886062622 | KNN Loss: 3.6162190437316895 | CLS Loss: 0.012102724984288216\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 3.6396918296813965 | KNN Loss: 3.6247944831848145 | CLS Loss: 0.014897424727678299\n",
      "Epoch: 057, Loss: 3.6419, Train: 0.9947, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 3.6684136390686035 | KNN Loss: 3.6346933841705322 | CLS Loss: 0.033720217645168304\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 3.6193056106567383 | KNN Loss: 3.5893349647521973 | CLS Loss: 0.02997073344886303\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 3.6280062198638916 | KNN Loss: 3.615705966949463 | CLS Loss: 0.012300215661525726\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 3.652539014816284 | KNN Loss: 3.6351304054260254 | CLS Loss: 0.017408674582839012\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 3.632209539413452 | KNN Loss: 3.6243250370025635 | CLS Loss: 0.00788451824337244\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 3.6645352840423584 | KNN Loss: 3.641488790512085 | CLS Loss: 0.023046543821692467\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 3.6519227027893066 | KNN Loss: 3.6439759731292725 | CLS Loss: 0.007946725934743881\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 3.708163022994995 | KNN Loss: 3.672484874725342 | CLS Loss: 0.03567824885249138\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 3.6552834510803223 | KNN Loss: 3.6186184883117676 | CLS Loss: 0.036664996296167374\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 3.5986483097076416 | KNN Loss: 3.5918381214141846 | CLS Loss: 0.006810270715504885\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 3.6400294303894043 | KNN Loss: 3.6043295860290527 | CLS Loss: 0.03569992259144783\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 3.6514079570770264 | KNN Loss: 3.6305439472198486 | CLS Loss: 0.020863937214016914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 3.7090811729431152 | KNN Loss: 3.650923252105713 | CLS Loss: 0.05815788730978966\n",
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 3.6430752277374268 | KNN Loss: 3.5913162231445312 | CLS Loss: 0.05175893008708954\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 3.683300733566284 | KNN Loss: 3.6716830730438232 | CLS Loss: 0.011617613025009632\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 3.622406244277954 | KNN Loss: 3.589998960494995 | CLS Loss: 0.0324072502553463\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 3.6579744815826416 | KNN Loss: 3.6300365924835205 | CLS Loss: 0.02793784812092781\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 3.6593587398529053 | KNN Loss: 3.62252140045166 | CLS Loss: 0.03683742508292198\n",
      "Epoch: 058, Loss: 3.6498, Train: 0.9943, Valid: 0.9853, Best: 0.9873\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 3.6590826511383057 | KNN Loss: 3.6548049449920654 | CLS Loss: 0.004277745261788368\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 3.622788429260254 | KNN Loss: 3.6109654903411865 | CLS Loss: 0.011822997592389584\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 3.627354145050049 | KNN Loss: 3.5947675704956055 | CLS Loss: 0.032586514949798584\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 3.6105191707611084 | KNN Loss: 3.6005699634552 | CLS Loss: 0.009949100203812122\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 3.6482677459716797 | KNN Loss: 3.6299383640289307 | CLS Loss: 0.018329327926039696\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 3.637869358062744 | KNN Loss: 3.565258026123047 | CLS Loss: 0.0726112574338913\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 3.6429591178894043 | KNN Loss: 3.631819248199463 | CLS Loss: 0.011139781214296818\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 3.617556571960449 | KNN Loss: 3.6000804901123047 | CLS Loss: 0.017476096749305725\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 3.6024773120880127 | KNN Loss: 3.587238311767578 | CLS Loss: 0.01523893978446722\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 3.60398006439209 | KNN Loss: 3.5987589359283447 | CLS Loss: 0.005221186671406031\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 3.636143922805786 | KNN Loss: 3.6108174324035645 | CLS Loss: 0.025326428934931755\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 3.6532199382781982 | KNN Loss: 3.6224303245544434 | CLS Loss: 0.03078971616923809\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 3.651627779006958 | KNN Loss: 3.609161376953125 | CLS Loss: 0.042466286569833755\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 3.639953374862671 | KNN Loss: 3.614041328430176 | CLS Loss: 0.02591194584965706\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 3.662383794784546 | KNN Loss: 3.6301844120025635 | CLS Loss: 0.03219946101307869\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 3.624452829360962 | KNN Loss: 3.5936102867126465 | CLS Loss: 0.030842449516057968\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 3.6229708194732666 | KNN Loss: 3.591850519180298 | CLS Loss: 0.031120283529162407\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 3.6371634006500244 | KNN Loss: 3.5979385375976562 | CLS Loss: 0.03922475874423981\n",
      "Epoch: 059, Loss: 3.6421, Train: 0.9909, Valid: 0.9815, Best: 0.9873\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 3.6640336513519287 | KNN Loss: 3.6396753787994385 | CLS Loss: 0.02435833401978016\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 3.6573615074157715 | KNN Loss: 3.635671615600586 | CLS Loss: 0.02168978750705719\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 3.6054933071136475 | KNN Loss: 3.585380792617798 | CLS Loss: 0.02011260949075222\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 3.6567020416259766 | KNN Loss: 3.612457752227783 | CLS Loss: 0.04424438998103142\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 3.6143269538879395 | KNN Loss: 3.6056723594665527 | CLS Loss: 0.008654521778225899\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 3.609592914581299 | KNN Loss: 3.5918235778808594 | CLS Loss: 0.01776929758489132\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 3.6127519607543945 | KNN Loss: 3.581636428833008 | CLS Loss: 0.031115643680095673\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 3.6739258766174316 | KNN Loss: 3.654989242553711 | CLS Loss: 0.018936607986688614\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 3.6095404624938965 | KNN Loss: 3.5963735580444336 | CLS Loss: 0.013166788965463638\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 3.643242835998535 | KNN Loss: 3.623922109603882 | CLS Loss: 0.019320644438266754\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 3.6468491554260254 | KNN Loss: 3.6353697776794434 | CLS Loss: 0.011479266919195652\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 3.5962107181549072 | KNN Loss: 3.5932421684265137 | CLS Loss: 0.002968493616208434\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 3.632570505142212 | KNN Loss: 3.60840106010437 | CLS Loss: 0.024169359356164932\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 3.635728597640991 | KNN Loss: 3.613131046295166 | CLS Loss: 0.022597474977374077\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 3.616992235183716 | KNN Loss: 3.5813708305358887 | CLS Loss: 0.035621508955955505\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 3.6340866088867188 | KNN Loss: 3.6005165576934814 | CLS Loss: 0.03357003629207611\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 3.6400163173675537 | KNN Loss: 3.6226425170898438 | CLS Loss: 0.017373913899064064\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 3.6090567111968994 | KNN Loss: 3.5880823135375977 | CLS Loss: 0.02097434364259243\n",
      "Epoch: 060, Loss: 3.6384, Train: 0.9955, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 3.6047232151031494 | KNN Loss: 3.5854787826538086 | CLS Loss: 0.01924453303217888\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 3.6048319339752197 | KNN Loss: 3.582540988922119 | CLS Loss: 0.022290831431746483\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 3.591414213180542 | KNN Loss: 3.587275266647339 | CLS Loss: 0.004138885997235775\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 3.6744749546051025 | KNN Loss: 3.6508655548095703 | CLS Loss: 0.023609362542629242\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 3.6307544708251953 | KNN Loss: 3.604870319366455 | CLS Loss: 0.025884205475449562\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 3.6900205612182617 | KNN Loss: 3.6580276489257812 | CLS Loss: 0.03199286386370659\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 3.6439661979675293 | KNN Loss: 3.6121373176574707 | CLS Loss: 0.03182888776063919\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 3.6457583904266357 | KNN Loss: 3.6297249794006348 | CLS Loss: 0.016033442690968513\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 3.650160312652588 | KNN Loss: 3.6333608627319336 | CLS Loss: 0.01679937355220318\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 3.6205432415008545 | KNN Loss: 3.613462448120117 | CLS Loss: 0.0070808990858495235\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 3.6544620990753174 | KNN Loss: 3.6464970111846924 | CLS Loss: 0.007965107448399067\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 3.641479730606079 | KNN Loss: 3.6201560497283936 | CLS Loss: 0.021323679015040398\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 3.630988359451294 | KNN Loss: 3.6076672077178955 | CLS Loss: 0.023321259766817093\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 3.636000156402588 | KNN Loss: 3.6193926334381104 | CLS Loss: 0.016607441008090973\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 3.643174648284912 | KNN Loss: 3.6207425594329834 | CLS Loss: 0.02243201620876789\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 3.6513843536376953 | KNN Loss: 3.6276421546936035 | CLS Loss: 0.02374216727912426\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 3.612380266189575 | KNN Loss: 3.589780807495117 | CLS Loss: 0.02259938046336174\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 3.6562235355377197 | KNN Loss: 3.61834454536438 | CLS Loss: 0.03787893429398537\n",
      "Epoch: 061, Loss: 3.6353, Train: 0.9947, Valid: 0.9864, Best: 0.9873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 3.6650583744049072 | KNN Loss: 3.6297364234924316 | CLS Loss: 0.03532198444008827\n",
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 3.6379528045654297 | KNN Loss: 3.6248228549957275 | CLS Loss: 0.01312994584441185\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 3.6866202354431152 | KNN Loss: 3.6764466762542725 | CLS Loss: 0.010173634625971317\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 3.6666083335876465 | KNN Loss: 3.6461474895477295 | CLS Loss: 0.020460914820432663\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 3.6463522911071777 | KNN Loss: 3.62431263923645 | CLS Loss: 0.022039690986275673\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 3.669015884399414 | KNN Loss: 3.642732620239258 | CLS Loss: 0.026283256709575653\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 3.653456926345825 | KNN Loss: 3.638542413711548 | CLS Loss: 0.014914433471858501\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 3.63602876663208 | KNN Loss: 3.6284823417663574 | CLS Loss: 0.0075463103130459785\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 3.6658012866973877 | KNN Loss: 3.655965805053711 | CLS Loss: 0.00983546394854784\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 3.7218854427337646 | KNN Loss: 3.7022695541381836 | CLS Loss: 0.019615912809967995\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 3.6346254348754883 | KNN Loss: 3.616363763809204 | CLS Loss: 0.01826166734099388\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 3.639227867126465 | KNN Loss: 3.6248738765716553 | CLS Loss: 0.01435387134552002\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 3.647020101547241 | KNN Loss: 3.6057372093200684 | CLS Loss: 0.0412827804684639\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 3.6002068519592285 | KNN Loss: 3.590250015258789 | CLS Loss: 0.009956737980246544\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 3.622687339782715 | KNN Loss: 3.6147141456604004 | CLS Loss: 0.007973256520926952\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 3.6658267974853516 | KNN Loss: 3.6575608253479004 | CLS Loss: 0.008265879936516285\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 3.6395232677459717 | KNN Loss: 3.622544527053833 | CLS Loss: 0.01697884127497673\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 3.6739187240600586 | KNN Loss: 3.664510488510132 | CLS Loss: 0.009408155456185341\n",
      "Epoch: 062, Loss: 3.6416, Train: 0.9936, Valid: 0.9846, Best: 0.9873\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 3.6391990184783936 | KNN Loss: 3.6237049102783203 | CLS Loss: 0.015494144521653652\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 3.5858960151672363 | KNN Loss: 3.581578254699707 | CLS Loss: 0.004317679442465305\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 3.631667375564575 | KNN Loss: 3.611314058303833 | CLS Loss: 0.020353266969323158\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 3.7060422897338867 | KNN Loss: 3.6947824954986572 | CLS Loss: 0.011259679682552814\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 3.6020519733428955 | KNN Loss: 3.586513042449951 | CLS Loss: 0.015539041720330715\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 3.619468927383423 | KNN Loss: 3.5895137786865234 | CLS Loss: 0.02995503507554531\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 3.657048225402832 | KNN Loss: 3.6467690467834473 | CLS Loss: 0.010279115289449692\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 3.696603775024414 | KNN Loss: 3.660282850265503 | CLS Loss: 0.036320850253105164\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 3.674670457839966 | KNN Loss: 3.6687915325164795 | CLS Loss: 0.0058788335882127285\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 3.6483657360076904 | KNN Loss: 3.6164634227752686 | CLS Loss: 0.03190220147371292\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 3.632483720779419 | KNN Loss: 3.5880544185638428 | CLS Loss: 0.04442938044667244\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 3.6961236000061035 | KNN Loss: 3.653322458267212 | CLS Loss: 0.042801033705472946\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 3.6344876289367676 | KNN Loss: 3.6171274185180664 | CLS Loss: 0.017360279336571693\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 3.627458095550537 | KNN Loss: 3.6069631576538086 | CLS Loss: 0.020494915544986725\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 3.6367387771606445 | KNN Loss: 3.609821081161499 | CLS Loss: 0.026917656883597374\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 3.619075059890747 | KNN Loss: 3.611640214920044 | CLS Loss: 0.007434954401105642\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 3.6363744735717773 | KNN Loss: 3.6165013313293457 | CLS Loss: 0.01987319625914097\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 3.6169819831848145 | KNN Loss: 3.585667610168457 | CLS Loss: 0.03131425380706787\n",
      "Epoch: 063, Loss: 3.6408, Train: 0.9949, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 3.637916088104248 | KNN Loss: 3.60530424118042 | CLS Loss: 0.032611966133117676\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 3.603809356689453 | KNN Loss: 3.596694231033325 | CLS Loss: 0.00711518619209528\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 3.641275405883789 | KNN Loss: 3.6300649642944336 | CLS Loss: 0.011210434138774872\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 3.650667428970337 | KNN Loss: 3.6038429737091064 | CLS Loss: 0.04682443290948868\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 3.637726068496704 | KNN Loss: 3.6248130798339844 | CLS Loss: 0.012912878766655922\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 3.606271505355835 | KNN Loss: 3.588808059692383 | CLS Loss: 0.017463557422161102\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 3.634248733520508 | KNN Loss: 3.610133647918701 | CLS Loss: 0.024114983156323433\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 3.6600265502929688 | KNN Loss: 3.624513864517212 | CLS Loss: 0.035512641072273254\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 3.676553964614868 | KNN Loss: 3.6523847579956055 | CLS Loss: 0.024169130250811577\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 3.628666877746582 | KNN Loss: 3.6112613677978516 | CLS Loss: 0.017405500635504723\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 3.6546707153320312 | KNN Loss: 3.6374428272247314 | CLS Loss: 0.01722797565162182\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 3.6140573024749756 | KNN Loss: 3.6090290546417236 | CLS Loss: 0.00502823106944561\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 3.657573938369751 | KNN Loss: 3.6460442543029785 | CLS Loss: 0.011529575102031231\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 3.637453556060791 | KNN Loss: 3.612252950668335 | CLS Loss: 0.025200510397553444\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 3.649235725402832 | KNN Loss: 3.632098436355591 | CLS Loss: 0.01713724434375763\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 3.6049351692199707 | KNN Loss: 3.5970821380615234 | CLS Loss: 0.007852936163544655\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 3.653120994567871 | KNN Loss: 3.6304476261138916 | CLS Loss: 0.022673368453979492\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 3.6532115936279297 | KNN Loss: 3.634333372116089 | CLS Loss: 0.018878329545259476\n",
      "Epoch: 064, Loss: 3.6402, Train: 0.9952, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 3.62465238571167 | KNN Loss: 3.6171560287475586 | CLS Loss: 0.007496441714465618\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 3.6454596519470215 | KNN Loss: 3.6223301887512207 | CLS Loss: 0.023129437118768692\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 3.6300301551818848 | KNN Loss: 3.61737322807312 | CLS Loss: 0.012656914070248604\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 3.63228702545166 | KNN Loss: 3.620610237121582 | CLS Loss: 0.011676877737045288\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 3.588043689727783 | KNN Loss: 3.571481704711914 | CLS Loss: 0.016562040895223618\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 3.617197036743164 | KNN Loss: 3.580626964569092 | CLS Loss: 0.036570098251104355\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 3.626666784286499 | KNN Loss: 3.6137444972991943 | CLS Loss: 0.012922287918627262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 3.659623384475708 | KNN Loss: 3.622908353805542 | CLS Loss: 0.036715004593133926\n",
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 3.6287477016448975 | KNN Loss: 3.62618350982666 | CLS Loss: 0.0025640816893428564\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 3.6369149684906006 | KNN Loss: 3.6267123222351074 | CLS Loss: 0.010202603414654732\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 3.682544469833374 | KNN Loss: 3.6554970741271973 | CLS Loss: 0.027047472074627876\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 3.6456539630889893 | KNN Loss: 3.6307246685028076 | CLS Loss: 0.014929354190826416\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 3.612827777862549 | KNN Loss: 3.5889060497283936 | CLS Loss: 0.023921679705381393\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 3.6711368560791016 | KNN Loss: 3.6494579315185547 | CLS Loss: 0.02167890965938568\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 3.622426748275757 | KNN Loss: 3.6148147583007812 | CLS Loss: 0.007611928042024374\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 3.677096366882324 | KNN Loss: 3.64406681060791 | CLS Loss: 0.033029619604349136\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 3.636387825012207 | KNN Loss: 3.6173839569091797 | CLS Loss: 0.019003836438059807\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 3.6011641025543213 | KNN Loss: 3.594114303588867 | CLS Loss: 0.007049866486340761\n",
      "Epoch: 065, Loss: 3.6412, Train: 0.9956, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 3.667628049850464 | KNN Loss: 3.643286943435669 | CLS Loss: 0.0243411622941494\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 3.652001142501831 | KNN Loss: 3.6237730979919434 | CLS Loss: 0.028228094801306725\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 3.6937661170959473 | KNN Loss: 3.6774790287017822 | CLS Loss: 0.016287092119455338\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 3.6185338497161865 | KNN Loss: 3.608833074569702 | CLS Loss: 0.009700731374323368\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 3.61928391456604 | KNN Loss: 3.599133014678955 | CLS Loss: 0.020150979980826378\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 3.6700854301452637 | KNN Loss: 3.6535613536834717 | CLS Loss: 0.01652403362095356\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 3.628847360610962 | KNN Loss: 3.6003127098083496 | CLS Loss: 0.028534745797514915\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 3.642455577850342 | KNN Loss: 3.6262993812561035 | CLS Loss: 0.016156140714883804\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 3.6857688426971436 | KNN Loss: 3.666536569595337 | CLS Loss: 0.019232304766774178\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 3.617006540298462 | KNN Loss: 3.608772039413452 | CLS Loss: 0.008234604261815548\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 3.6214120388031006 | KNN Loss: 3.6145217418670654 | CLS Loss: 0.006890272255986929\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 3.615546464920044 | KNN Loss: 3.6135544776916504 | CLS Loss: 0.0019919555634260178\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 3.6313865184783936 | KNN Loss: 3.6168007850646973 | CLS Loss: 0.01458571944385767\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 3.6409246921539307 | KNN Loss: 3.626666784286499 | CLS Loss: 0.014257937669754028\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 3.664660930633545 | KNN Loss: 3.6478099822998047 | CLS Loss: 0.016850842162966728\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 3.6470959186553955 | KNN Loss: 3.636413097381592 | CLS Loss: 0.010682832449674606\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 3.676891565322876 | KNN Loss: 3.6200342178344727 | CLS Loss: 0.0568573921918869\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 3.6139895915985107 | KNN Loss: 3.60013484954834 | CLS Loss: 0.013854802586138248\n",
      "Epoch: 066, Loss: 3.6411, Train: 0.9949, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 3.67037296295166 | KNN Loss: 3.6620638370513916 | CLS Loss: 0.008309095166623592\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 3.614018201828003 | KNN Loss: 3.5984156131744385 | CLS Loss: 0.01560248527675867\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 3.65572190284729 | KNN Loss: 3.632974863052368 | CLS Loss: 0.022746946662664413\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 3.6203596591949463 | KNN Loss: 3.6107943058013916 | CLS Loss: 0.009565342217683792\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 3.647122621536255 | KNN Loss: 3.6289007663726807 | CLS Loss: 0.018221745267510414\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 3.6125168800354004 | KNN Loss: 3.6043431758880615 | CLS Loss: 0.008173641748726368\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 3.6396193504333496 | KNN Loss: 3.6235811710357666 | CLS Loss: 0.016038183122873306\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 3.653764486312866 | KNN Loss: 3.6451921463012695 | CLS Loss: 0.008572257123887539\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 3.733053684234619 | KNN Loss: 3.701547145843506 | CLS Loss: 0.03150646761059761\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 3.642939567565918 | KNN Loss: 3.6260128021240234 | CLS Loss: 0.016926709562540054\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 3.721076726913452 | KNN Loss: 3.698859453201294 | CLS Loss: 0.022217389196157455\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 3.628674268722534 | KNN Loss: 3.6115612983703613 | CLS Loss: 0.01711289770901203\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 3.63142466545105 | KNN Loss: 3.6125881671905518 | CLS Loss: 0.018836408853530884\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 3.6225690841674805 | KNN Loss: 3.61177921295166 | CLS Loss: 0.01078997366130352\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 3.617396354675293 | KNN Loss: 3.6094167232513428 | CLS Loss: 0.00797953549772501\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 3.6424856185913086 | KNN Loss: 3.613734006881714 | CLS Loss: 0.028751563280820847\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 3.61303448677063 | KNN Loss: 3.596355438232422 | CLS Loss: 0.01667901873588562\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 3.630765914916992 | KNN Loss: 3.6084940433502197 | CLS Loss: 0.022271765395998955\n",
      "Epoch: 067, Loss: 3.6406, Train: 0.9954, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 3.59014892578125 | KNN Loss: 3.5706968307495117 | CLS Loss: 0.01945207640528679\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 3.616820812225342 | KNN Loss: 3.6009206771850586 | CLS Loss: 0.015900112688541412\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 3.640333890914917 | KNN Loss: 3.6270084381103516 | CLS Loss: 0.013325562700629234\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 3.6286673545837402 | KNN Loss: 3.6109282970428467 | CLS Loss: 0.017739076167345047\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 3.646853446960449 | KNN Loss: 3.6200926303863525 | CLS Loss: 0.026760920882225037\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 3.6421852111816406 | KNN Loss: 3.6221439838409424 | CLS Loss: 0.020041167736053467\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 3.6370904445648193 | KNN Loss: 3.583827495574951 | CLS Loss: 0.05326296389102936\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 3.6305527687072754 | KNN Loss: 3.6087088584899902 | CLS Loss: 0.021844003349542618\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 3.6072444915771484 | KNN Loss: 3.6042637825012207 | CLS Loss: 0.0029807379469275475\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 3.6250197887420654 | KNN Loss: 3.5977060794830322 | CLS Loss: 0.02731362171471119\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 3.6233255863189697 | KNN Loss: 3.606046676635742 | CLS Loss: 0.017278920859098434\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 3.6243488788604736 | KNN Loss: 3.6123828887939453 | CLS Loss: 0.011966075748205185\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 3.628673791885376 | KNN Loss: 3.6248996257781982 | CLS Loss: 0.0037741533014923334\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 3.6694960594177246 | KNN Loss: 3.6388375759124756 | CLS Loss: 0.030658572912216187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 3.6116585731506348 | KNN Loss: 3.601923942565918 | CLS Loss: 0.009734644554555416\n",
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 3.6132140159606934 | KNN Loss: 3.599552631378174 | CLS Loss: 0.013661324977874756\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 3.650015115737915 | KNN Loss: 3.6417548656463623 | CLS Loss: 0.00826026126742363\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 3.627016067504883 | KNN Loss: 3.5881052017211914 | CLS Loss: 0.038910817354917526\n",
      "Epoch: 068, Loss: 3.6334, Train: 0.9952, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 3.6023855209350586 | KNN Loss: 3.5903031826019287 | CLS Loss: 0.01208241656422615\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 3.6404638290405273 | KNN Loss: 3.6167640686035156 | CLS Loss: 0.023699862882494926\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 3.6384425163269043 | KNN Loss: 3.619255781173706 | CLS Loss: 0.01918662153184414\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 3.630556344985962 | KNN Loss: 3.627148151397705 | CLS Loss: 0.0034080841578543186\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 3.652872323989868 | KNN Loss: 3.6253511905670166 | CLS Loss: 0.027521148324012756\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 3.619231939315796 | KNN Loss: 3.5837419033050537 | CLS Loss: 0.03548998013138771\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 3.6390395164489746 | KNN Loss: 3.607701301574707 | CLS Loss: 0.03133822977542877\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 3.705482244491577 | KNN Loss: 3.6619441509246826 | CLS Loss: 0.04353811591863632\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 3.726754665374756 | KNN Loss: 3.6899828910827637 | CLS Loss: 0.0367717519402504\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 3.6799707412719727 | KNN Loss: 3.6258223056793213 | CLS Loss: 0.054148443043231964\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 3.6516218185424805 | KNN Loss: 3.6272077560424805 | CLS Loss: 0.024414019659161568\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 3.6579737663269043 | KNN Loss: 3.631824493408203 | CLS Loss: 0.026149241253733635\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 3.6322481632232666 | KNN Loss: 3.6192679405212402 | CLS Loss: 0.012980248779058456\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 3.608372926712036 | KNN Loss: 3.593100070953369 | CLS Loss: 0.015272878110408783\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 3.6555802822113037 | KNN Loss: 3.6187779903411865 | CLS Loss: 0.03680240735411644\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 3.6232213973999023 | KNN Loss: 3.596831798553467 | CLS Loss: 0.026389695703983307\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 3.670862913131714 | KNN Loss: 3.6493077278137207 | CLS Loss: 0.021555298939347267\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 3.6097264289855957 | KNN Loss: 3.5980658531188965 | CLS Loss: 0.011660539545118809\n",
      "Epoch: 069, Loss: 3.6445, Train: 0.9942, Valid: 0.9853, Best: 0.9873\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 3.6424765586853027 | KNN Loss: 3.631481409072876 | CLS Loss: 0.010995130985975266\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 3.617371082305908 | KNN Loss: 3.6107735633850098 | CLS Loss: 0.006597529165446758\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 3.632054328918457 | KNN Loss: 3.6069507598876953 | CLS Loss: 0.025103459134697914\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 3.6828198432922363 | KNN Loss: 3.6581923961639404 | CLS Loss: 0.024627527222037315\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 3.6395726203918457 | KNN Loss: 3.632352352142334 | CLS Loss: 0.007220267318189144\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 3.6306049823760986 | KNN Loss: 3.6139931678771973 | CLS Loss: 0.016611861065030098\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 3.6590585708618164 | KNN Loss: 3.6361029148101807 | CLS Loss: 0.022955553606152534\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 3.602024793624878 | KNN Loss: 3.592291831970215 | CLS Loss: 0.009733032435178757\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 3.6952831745147705 | KNN Loss: 3.6731181144714355 | CLS Loss: 0.022165004163980484\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 3.645174980163574 | KNN Loss: 3.638556957244873 | CLS Loss: 0.006618095561861992\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 3.6224746704101562 | KNN Loss: 3.593750238418579 | CLS Loss: 0.028724541887640953\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 3.6035892963409424 | KNN Loss: 3.591596841812134 | CLS Loss: 0.011992445215582848\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 3.685285806655884 | KNN Loss: 3.6635138988494873 | CLS Loss: 0.021771859377622604\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 3.5834789276123047 | KNN Loss: 3.55659818649292 | CLS Loss: 0.026880839839577675\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 3.6144943237304688 | KNN Loss: 3.601393222808838 | CLS Loss: 0.013101133517920971\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 3.6317920684814453 | KNN Loss: 3.6110925674438477 | CLS Loss: 0.020699547603726387\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 3.642429828643799 | KNN Loss: 3.634416341781616 | CLS Loss: 0.008013416081666946\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 3.619070529937744 | KNN Loss: 3.6136999130249023 | CLS Loss: 0.0053706117905676365\n",
      "Epoch: 070, Loss: 3.6359, Train: 0.9957, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 3.6177873611450195 | KNN Loss: 3.611605167388916 | CLS Loss: 0.006182188168168068\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 3.6024010181427 | KNN Loss: 3.579338788986206 | CLS Loss: 0.023062342777848244\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 3.6437268257141113 | KNN Loss: 3.6330342292785645 | CLS Loss: 0.010692535899579525\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 3.6121320724487305 | KNN Loss: 3.6011900901794434 | CLS Loss: 0.010942013002932072\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 3.6501288414001465 | KNN Loss: 3.638490676879883 | CLS Loss: 0.011638280004262924\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 3.6155714988708496 | KNN Loss: 3.5936357975006104 | CLS Loss: 0.021935734897851944\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 3.6574032306671143 | KNN Loss: 3.6373090744018555 | CLS Loss: 0.02009418047964573\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 3.6205286979675293 | KNN Loss: 3.609163761138916 | CLS Loss: 0.011364862322807312\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 3.631891965866089 | KNN Loss: 3.610605239868164 | CLS Loss: 0.02128680609166622\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 3.645665168762207 | KNN Loss: 3.6187074184417725 | CLS Loss: 0.026957714930176735\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 3.623436212539673 | KNN Loss: 3.6154699325561523 | CLS Loss: 0.007966226898133755\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 3.6148931980133057 | KNN Loss: 3.5986571311950684 | CLS Loss: 0.016236145049333572\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 3.6494646072387695 | KNN Loss: 3.6395483016967773 | CLS Loss: 0.009916246868669987\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 3.6397159099578857 | KNN Loss: 3.626981258392334 | CLS Loss: 0.012734660878777504\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 3.639819622039795 | KNN Loss: 3.61893367767334 | CLS Loss: 0.020885955542325974\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 3.6057069301605225 | KNN Loss: 3.5934512615203857 | CLS Loss: 0.012255786918103695\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 3.6187474727630615 | KNN Loss: 3.598226547241211 | CLS Loss: 0.020520877093076706\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 3.633880615234375 | KNN Loss: 3.625814914703369 | CLS Loss: 0.008065816946327686\n",
      "Epoch: 071, Loss: 3.6348, Train: 0.9963, Valid: 0.9872, Best: 0.9873\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 3.658440589904785 | KNN Loss: 3.617434024810791 | CLS Loss: 0.041006650775671005\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 3.636169672012329 | KNN Loss: 3.617096424102783 | CLS Loss: 0.01907329261302948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 3.6078531742095947 | KNN Loss: 3.6015708446502686 | CLS Loss: 0.006282305344939232\n",
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 3.6265857219696045 | KNN Loss: 3.605905294418335 | CLS Loss: 0.020680485293269157\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 3.612851142883301 | KNN Loss: 3.6102089881896973 | CLS Loss: 0.002642161911353469\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 3.6367785930633545 | KNN Loss: 3.6213433742523193 | CLS Loss: 0.015435220673680305\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 3.6311161518096924 | KNN Loss: 3.6260986328125 | CLS Loss: 0.005017537157982588\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 3.6116833686828613 | KNN Loss: 3.606553792953491 | CLS Loss: 0.0051295701414346695\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 3.637434959411621 | KNN Loss: 3.6163313388824463 | CLS Loss: 0.02110353298485279\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 3.705763816833496 | KNN Loss: 3.667851209640503 | CLS Loss: 0.03791259229183197\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 3.6129512786865234 | KNN Loss: 3.604161024093628 | CLS Loss: 0.008790172636508942\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 3.6149933338165283 | KNN Loss: 3.5924761295318604 | CLS Loss: 0.022517221048474312\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 3.684248447418213 | KNN Loss: 3.6703131198883057 | CLS Loss: 0.013935327529907227\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 3.606283664703369 | KNN Loss: 3.601771593093872 | CLS Loss: 0.004512098617851734\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 3.622913360595703 | KNN Loss: 3.6062347888946533 | CLS Loss: 0.016678573563694954\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 3.622746706008911 | KNN Loss: 3.6150381565093994 | CLS Loss: 0.0077085718512535095\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 3.633415699005127 | KNN Loss: 3.5973451137542725 | CLS Loss: 0.03607053682208061\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 3.6122748851776123 | KNN Loss: 3.6018197536468506 | CLS Loss: 0.010455033741891384\n",
      "Epoch: 072, Loss: 3.6323, Train: 0.9959, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 3.6186983585357666 | KNN Loss: 3.602125406265259 | CLS Loss: 0.01657295599579811\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 3.628779411315918 | KNN Loss: 3.6235172748565674 | CLS Loss: 0.00526212714612484\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 3.6089563369750977 | KNN Loss: 3.604203224182129 | CLS Loss: 0.0047530862502753735\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 3.6444222927093506 | KNN Loss: 3.622722864151001 | CLS Loss: 0.021699419245123863\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 3.668785572052002 | KNN Loss: 3.6396405696868896 | CLS Loss: 0.029145078733563423\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 3.6173858642578125 | KNN Loss: 3.6131064891815186 | CLS Loss: 0.0042794630862772465\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 3.664435625076294 | KNN Loss: 3.650937080383301 | CLS Loss: 0.013498491607606411\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 3.651824474334717 | KNN Loss: 3.637483596801758 | CLS Loss: 0.014340808615088463\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 3.662450075149536 | KNN Loss: 3.6564862728118896 | CLS Loss: 0.005963789764791727\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 3.665815591812134 | KNN Loss: 3.641141653060913 | CLS Loss: 0.0246739462018013\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 3.624879837036133 | KNN Loss: 3.6188998222351074 | CLS Loss: 0.005979900248348713\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 3.6243033409118652 | KNN Loss: 3.6120972633361816 | CLS Loss: 0.012206165120005608\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 3.6109344959259033 | KNN Loss: 3.6076300144195557 | CLS Loss: 0.003304465673863888\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 3.657820224761963 | KNN Loss: 3.63791823387146 | CLS Loss: 0.019902054220438004\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 3.707049608230591 | KNN Loss: 3.651866912841797 | CLS Loss: 0.05518257990479469\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 3.6648242473602295 | KNN Loss: 3.6369106769561768 | CLS Loss: 0.027913527563214302\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 3.6772477626800537 | KNN Loss: 3.6311254501342773 | CLS Loss: 0.04612232372164726\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 3.7200396060943604 | KNN Loss: 3.6781835556030273 | CLS Loss: 0.041856031864881516\n",
      "Epoch: 073, Loss: 3.6307, Train: 0.9947, Valid: 0.9842, Best: 0.9873\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 3.655895948410034 | KNN Loss: 3.6446244716644287 | CLS Loss: 0.011271554045379162\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 3.6703476905822754 | KNN Loss: 3.6542370319366455 | CLS Loss: 0.016110757365822792\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 3.6400654315948486 | KNN Loss: 3.628220558166504 | CLS Loss: 0.011844774708151817\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 3.6765642166137695 | KNN Loss: 3.665961265563965 | CLS Loss: 0.010602874681353569\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 3.6605207920074463 | KNN Loss: 3.649778366088867 | CLS Loss: 0.010742389596998692\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 3.6233246326446533 | KNN Loss: 3.6015446186065674 | CLS Loss: 0.021779915317893028\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 3.6089048385620117 | KNN Loss: 3.5939981937408447 | CLS Loss: 0.01490657590329647\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 3.6315271854400635 | KNN Loss: 3.6250014305114746 | CLS Loss: 0.006525710225105286\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 3.5954928398132324 | KNN Loss: 3.5769102573394775 | CLS Loss: 0.018582550808787346\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 3.6464271545410156 | KNN Loss: 3.606616258621216 | CLS Loss: 0.03981088846921921\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 3.5993998050689697 | KNN Loss: 3.588747501373291 | CLS Loss: 0.0106522710993886\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 3.612344264984131 | KNN Loss: 3.6100471019744873 | CLS Loss: 0.0022971048019826412\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 3.62139892578125 | KNN Loss: 3.600666046142578 | CLS Loss: 0.020732872188091278\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 3.616270065307617 | KNN Loss: 3.602487802505493 | CLS Loss: 0.013782311230897903\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 3.5992090702056885 | KNN Loss: 3.5845274925231934 | CLS Loss: 0.014681672677397728\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 3.6262013912200928 | KNN Loss: 3.5898802280426025 | CLS Loss: 0.03632105514407158\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 3.633366584777832 | KNN Loss: 3.627241373062134 | CLS Loss: 0.006125097628682852\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 3.694275140762329 | KNN Loss: 3.6694962978363037 | CLS Loss: 0.02477891556918621\n",
      "Epoch: 074, Loss: 3.6311, Train: 0.9952, Valid: 0.9871, Best: 0.9873\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 3.6380491256713867 | KNN Loss: 3.6224539279937744 | CLS Loss: 0.015595205128192902\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 3.6164355278015137 | KNN Loss: 3.605121612548828 | CLS Loss: 0.011313796043395996\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 3.599310874938965 | KNN Loss: 3.597010612487793 | CLS Loss: 0.002300361404195428\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 3.589003086090088 | KNN Loss: 3.578408718109131 | CLS Loss: 0.010594449937343597\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 3.6184818744659424 | KNN Loss: 3.6096959114074707 | CLS Loss: 0.008785946294665337\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 3.5995001792907715 | KNN Loss: 3.592824697494507 | CLS Loss: 0.006675570271909237\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 3.6343142986297607 | KNN Loss: 3.6067512035369873 | CLS Loss: 0.027563199400901794\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 3.6410932540893555 | KNN Loss: 3.6343700885772705 | CLS Loss: 0.006723183207213879\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 3.606638193130493 | KNN Loss: 3.5959701538085938 | CLS Loss: 0.010667924769222736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 3.6432509422302246 | KNN Loss: 3.623993158340454 | CLS Loss: 0.019257858395576477\n",
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 3.6497132778167725 | KNN Loss: 3.6173081398010254 | CLS Loss: 0.03240522742271423\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 3.657618284225464 | KNN Loss: 3.643691301345825 | CLS Loss: 0.01392704900354147\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 3.587270498275757 | KNN Loss: 3.5662460327148438 | CLS Loss: 0.021024387329816818\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 3.6258833408355713 | KNN Loss: 3.609583616256714 | CLS Loss: 0.016299722716212273\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 3.6030611991882324 | KNN Loss: 3.591930389404297 | CLS Loss: 0.01113081257790327\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 3.6527023315429688 | KNN Loss: 3.6281728744506836 | CLS Loss: 0.024529486894607544\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 3.6275405883789062 | KNN Loss: 3.6003541946411133 | CLS Loss: 0.027186311781406403\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 3.62100887298584 | KNN Loss: 3.6006410121917725 | CLS Loss: 0.020367883145809174\n",
      "Epoch: 075, Loss: 3.6297, Train: 0.9957, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 3.6279053688049316 | KNN Loss: 3.618252992630005 | CLS Loss: 0.009652403183281422\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 3.632388114929199 | KNN Loss: 3.6230239868164062 | CLS Loss: 0.009364169090986252\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 3.6102757453918457 | KNN Loss: 3.573617696762085 | CLS Loss: 0.036657996475696564\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 3.631718158721924 | KNN Loss: 3.6225779056549072 | CLS Loss: 0.00914018414914608\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 3.6423397064208984 | KNN Loss: 3.6350340843200684 | CLS Loss: 0.00730561837553978\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 3.6577789783477783 | KNN Loss: 3.635528326034546 | CLS Loss: 0.0222507081925869\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 3.6632678508758545 | KNN Loss: 3.6533877849578857 | CLS Loss: 0.00988005381077528\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 3.6015422344207764 | KNN Loss: 3.589259386062622 | CLS Loss: 0.012282910756766796\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 3.698735237121582 | KNN Loss: 3.6833271980285645 | CLS Loss: 0.015407942235469818\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 3.6200740337371826 | KNN Loss: 3.597210645675659 | CLS Loss: 0.022863350808620453\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 3.624181032180786 | KNN Loss: 3.615682601928711 | CLS Loss: 0.008498395793139935\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 3.5993947982788086 | KNN Loss: 3.5832624435424805 | CLS Loss: 0.01613243669271469\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 3.60066819190979 | KNN Loss: 3.5985097885131836 | CLS Loss: 0.0021582928020507097\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 3.622580051422119 | KNN Loss: 3.6115102767944336 | CLS Loss: 0.011069683358073235\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 3.6395938396453857 | KNN Loss: 3.622687578201294 | CLS Loss: 0.01690635085105896\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 3.6063363552093506 | KNN Loss: 3.6004881858825684 | CLS Loss: 0.005848143249750137\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 3.6570632457733154 | KNN Loss: 3.6348812580108643 | CLS Loss: 0.022181877866387367\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 3.6098005771636963 | KNN Loss: 3.604377031326294 | CLS Loss: 0.00542359659448266\n",
      "Epoch: 076, Loss: 3.6339, Train: 0.9959, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 3.629763603210449 | KNN Loss: 3.592031955718994 | CLS Loss: 0.03773169592022896\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 3.5978615283966064 | KNN Loss: 3.5950024127960205 | CLS Loss: 0.0028590289875864983\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 3.6198501586914062 | KNN Loss: 3.6104543209075928 | CLS Loss: 0.009395886212587357\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 3.6544528007507324 | KNN Loss: 3.6441211700439453 | CLS Loss: 0.010331609286367893\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 3.6025068759918213 | KNN Loss: 3.5860955715179443 | CLS Loss: 0.016411371529102325\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 3.600368022918701 | KNN Loss: 3.597986936569214 | CLS Loss: 0.002381180180236697\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 3.6580286026000977 | KNN Loss: 3.629805326461792 | CLS Loss: 0.028223372995853424\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 3.6073834896087646 | KNN Loss: 3.592115640640259 | CLS Loss: 0.015267804265022278\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 3.618936538696289 | KNN Loss: 3.6083712577819824 | CLS Loss: 0.010565346106886864\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 3.63161563873291 | KNN Loss: 3.6197752952575684 | CLS Loss: 0.01184031181037426\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 3.6169700622558594 | KNN Loss: 3.584916114807129 | CLS Loss: 0.03205399215221405\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 3.637444257736206 | KNN Loss: 3.6278069019317627 | CLS Loss: 0.009637361392378807\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 3.5891401767730713 | KNN Loss: 3.576558828353882 | CLS Loss: 0.012581435963511467\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 3.6241490840911865 | KNN Loss: 3.6133501529693604 | CLS Loss: 0.01079888641834259\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 3.6411077976226807 | KNN Loss: 3.620131731033325 | CLS Loss: 0.020976098254323006\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 3.585282802581787 | KNN Loss: 3.5689120292663574 | CLS Loss: 0.016370724886655807\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 3.6079177856445312 | KNN Loss: 3.605156421661377 | CLS Loss: 0.002761407755315304\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 3.6444878578186035 | KNN Loss: 3.629701614379883 | CLS Loss: 0.01478626485913992\n",
      "Epoch: 077, Loss: 3.6268, Train: 0.9965, Valid: 0.9881, Best: 0.9881\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 3.6378889083862305 | KNN Loss: 3.633584499359131 | CLS Loss: 0.004304443020373583\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 3.6184256076812744 | KNN Loss: 3.6063358783721924 | CLS Loss: 0.012089652940630913\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 3.6054458618164062 | KNN Loss: 3.5919101238250732 | CLS Loss: 0.013535686768591404\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 3.6237006187438965 | KNN Loss: 3.6161341667175293 | CLS Loss: 0.007566407322883606\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 3.6237568855285645 | KNN Loss: 3.610126256942749 | CLS Loss: 0.013630627654492855\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 3.651176929473877 | KNN Loss: 3.6288719177246094 | CLS Loss: 0.022304929792881012\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 3.6665658950805664 | KNN Loss: 3.6524665355682373 | CLS Loss: 0.014099475927650928\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 3.612924814224243 | KNN Loss: 3.578620433807373 | CLS Loss: 0.0343044176697731\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 3.633876085281372 | KNN Loss: 3.622227668762207 | CLS Loss: 0.011648470535874367\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 3.6615850925445557 | KNN Loss: 3.643514633178711 | CLS Loss: 0.018070384860038757\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 3.6439244747161865 | KNN Loss: 3.610870838165283 | CLS Loss: 0.033053670078516006\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 3.6655027866363525 | KNN Loss: 3.644991159439087 | CLS Loss: 0.020511694252490997\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 3.625922918319702 | KNN Loss: 3.617953300476074 | CLS Loss: 0.007969611324369907\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 3.6356568336486816 | KNN Loss: 3.6183793544769287 | CLS Loss: 0.017277467995882034\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 3.6004464626312256 | KNN Loss: 3.5829944610595703 | CLS Loss: 0.017451902851462364\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 3.626925468444824 | KNN Loss: 3.6184957027435303 | CLS Loss: 0.008429781533777714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 3.608360767364502 | KNN Loss: 3.592115640640259 | CLS Loss: 0.016245054081082344\n",
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 3.591012954711914 | KNN Loss: 3.579185962677002 | CLS Loss: 0.011826964095234871\n",
      "Epoch: 078, Loss: 3.6246, Train: 0.9960, Valid: 0.9869, Best: 0.9881\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 3.603792190551758 | KNN Loss: 3.5797924995422363 | CLS Loss: 0.023999638855457306\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 3.6212425231933594 | KNN Loss: 3.6008007526397705 | CLS Loss: 0.020441750064492226\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 3.6015663146972656 | KNN Loss: 3.5890729427337646 | CLS Loss: 0.012493393383920193\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 3.623159885406494 | KNN Loss: 3.614776611328125 | CLS Loss: 0.008383376523852348\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 3.6364541053771973 | KNN Loss: 3.616581678390503 | CLS Loss: 0.019872449338436127\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 3.5809926986694336 | KNN Loss: 3.576770782470703 | CLS Loss: 0.004222020041197538\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 3.6286635398864746 | KNN Loss: 3.6073389053344727 | CLS Loss: 0.021324649453163147\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 3.6358237266540527 | KNN Loss: 3.621708631515503 | CLS Loss: 0.014115190133452415\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 3.659708261489868 | KNN Loss: 3.6208553314208984 | CLS Loss: 0.038852836936712265\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 3.630127429962158 | KNN Loss: 3.625171184539795 | CLS Loss: 0.004956293385475874\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 3.7089030742645264 | KNN Loss: 3.6690878868103027 | CLS Loss: 0.03981512039899826\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 3.6354541778564453 | KNN Loss: 3.6142618656158447 | CLS Loss: 0.021192234009504318\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 3.6497750282287598 | KNN Loss: 3.6307194232940674 | CLS Loss: 0.019055519253015518\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 3.6033103466033936 | KNN Loss: 3.59344482421875 | CLS Loss: 0.00986557174474001\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 3.6147146224975586 | KNN Loss: 3.611475706100464 | CLS Loss: 0.0032387995161116123\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 3.6072871685028076 | KNN Loss: 3.5992588996887207 | CLS Loss: 0.008028383366763592\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 3.638015031814575 | KNN Loss: 3.629087448120117 | CLS Loss: 0.008927648887038231\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 3.5982930660247803 | KNN Loss: 3.583317279815674 | CLS Loss: 0.014975874684751034\n",
      "Epoch: 079, Loss: 3.6292, Train: 0.9956, Valid: 0.9868, Best: 0.9881\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 3.6008529663085938 | KNN Loss: 3.5882363319396973 | CLS Loss: 0.012616750784218311\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 3.589918613433838 | KNN Loss: 3.575704574584961 | CLS Loss: 0.014214102178812027\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 3.5981616973876953 | KNN Loss: 3.592198371887207 | CLS Loss: 0.005963354371488094\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 3.6101977825164795 | KNN Loss: 3.606144905090332 | CLS Loss: 0.004052994307130575\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 3.6208579540252686 | KNN Loss: 3.6140732765197754 | CLS Loss: 0.006784720346331596\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 3.6048483848571777 | KNN Loss: 3.587667226791382 | CLS Loss: 0.01718108355998993\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 3.644397497177124 | KNN Loss: 3.6185927391052246 | CLS Loss: 0.025804653763771057\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 3.674792766571045 | KNN Loss: 3.66739821434021 | CLS Loss: 0.007394443731755018\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 3.670753240585327 | KNN Loss: 3.647676467895508 | CLS Loss: 0.023076828569173813\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 3.6057937145233154 | KNN Loss: 3.5860557556152344 | CLS Loss: 0.01973804086446762\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 3.6315953731536865 | KNN Loss: 3.623211145401001 | CLS Loss: 0.008384167216718197\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 3.659475088119507 | KNN Loss: 3.6313741207122803 | CLS Loss: 0.0281008742749691\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 3.626204013824463 | KNN Loss: 3.5892529487609863 | CLS Loss: 0.036951035261154175\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 3.5932364463806152 | KNN Loss: 3.588728666305542 | CLS Loss: 0.004507702309638262\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 3.5826053619384766 | KNN Loss: 3.5732882022857666 | CLS Loss: 0.009317179210484028\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 3.6162455081939697 | KNN Loss: 3.6058530807495117 | CLS Loss: 0.010392390191555023\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 3.5954434871673584 | KNN Loss: 3.5851471424102783 | CLS Loss: 0.01029634103178978\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 3.614108085632324 | KNN Loss: 3.598487377166748 | CLS Loss: 0.01562059111893177\n",
      "Epoch: 080, Loss: 3.6309, Train: 0.9956, Valid: 0.9859, Best: 0.9881\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 3.606752634048462 | KNN Loss: 3.596416711807251 | CLS Loss: 0.010335806757211685\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 3.5970702171325684 | KNN Loss: 3.584435224533081 | CLS Loss: 0.012635022401809692\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 3.6305136680603027 | KNN Loss: 3.6030569076538086 | CLS Loss: 0.027456775307655334\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 3.6086809635162354 | KNN Loss: 3.5912983417510986 | CLS Loss: 0.017382515594363213\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 3.603396415710449 | KNN Loss: 3.585437059402466 | CLS Loss: 0.01795945316553116\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 3.610321044921875 | KNN Loss: 3.5986335277557373 | CLS Loss: 0.011687485501170158\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 3.599714517593384 | KNN Loss: 3.586503744125366 | CLS Loss: 0.013210700824856758\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 3.63492751121521 | KNN Loss: 3.6236226558685303 | CLS Loss: 0.011304754763841629\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 3.61039662361145 | KNN Loss: 3.5991897583007812 | CLS Loss: 0.011206782422959805\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 3.656883716583252 | KNN Loss: 3.6451120376586914 | CLS Loss: 0.011771679855883121\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 3.602280378341675 | KNN Loss: 3.594268798828125 | CLS Loss: 0.00801150407642126\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 3.6396524906158447 | KNN Loss: 3.597756862640381 | CLS Loss: 0.04189566150307655\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 3.5896155834198 | KNN Loss: 3.5820302963256836 | CLS Loss: 0.007585170213133097\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 3.6230697631835938 | KNN Loss: 3.606736183166504 | CLS Loss: 0.016333678737282753\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 3.605820417404175 | KNN Loss: 3.6008760929107666 | CLS Loss: 0.004944376647472382\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 3.6352012157440186 | KNN Loss: 3.5977327823638916 | CLS Loss: 0.03746838867664337\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 3.613157033920288 | KNN Loss: 3.6005771160125732 | CLS Loss: 0.012579995207488537\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 3.610801935195923 | KNN Loss: 3.5839180946350098 | CLS Loss: 0.02688376046717167\n",
      "Epoch: 081, Loss: 3.6240, Train: 0.9962, Valid: 0.9861, Best: 0.9881\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 3.6305432319641113 | KNN Loss: 3.621079921722412 | CLS Loss: 0.009463313966989517\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 3.60400652885437 | KNN Loss: 3.5958034992218018 | CLS Loss: 0.008203040808439255\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 3.5944316387176514 | KNN Loss: 3.5720314979553223 | CLS Loss: 0.02240011654794216\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 3.6338465213775635 | KNN Loss: 3.623035430908203 | CLS Loss: 0.010811186395585537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 3.590385675430298 | KNN Loss: 3.5843987464904785 | CLS Loss: 0.005986956879496574\n",
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 3.60817813873291 | KNN Loss: 3.6028826236724854 | CLS Loss: 0.005295445676892996\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 3.6131114959716797 | KNN Loss: 3.598600149154663 | CLS Loss: 0.014511308632791042\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 3.6079277992248535 | KNN Loss: 3.59498929977417 | CLS Loss: 0.012938479892909527\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 3.6848158836364746 | KNN Loss: 3.6809210777282715 | CLS Loss: 0.0038948534056544304\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 3.598494529724121 | KNN Loss: 3.5889899730682373 | CLS Loss: 0.00950460322201252\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 3.628730058670044 | KNN Loss: 3.612852096557617 | CLS Loss: 0.01587800495326519\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 3.6119167804718018 | KNN Loss: 3.6044905185699463 | CLS Loss: 0.007426278665661812\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 3.6224026679992676 | KNN Loss: 3.6007156372070312 | CLS Loss: 0.02168697863817215\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 3.611984968185425 | KNN Loss: 3.60349702835083 | CLS Loss: 0.008487993851304054\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 3.64062762260437 | KNN Loss: 3.6124348640441895 | CLS Loss: 0.028192667290568352\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 3.649887800216675 | KNN Loss: 3.615405797958374 | CLS Loss: 0.03448200225830078\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 3.6240596771240234 | KNN Loss: 3.6072580814361572 | CLS Loss: 0.016801703721284866\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 3.6020395755767822 | KNN Loss: 3.585477113723755 | CLS Loss: 0.01656254008412361\n",
      "Epoch: 082, Loss: 3.6225, Train: 0.9965, Valid: 0.9866, Best: 0.9881\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 3.618661880493164 | KNN Loss: 3.612420082092285 | CLS Loss: 0.006241845432668924\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 3.6090612411499023 | KNN Loss: 3.602177143096924 | CLS Loss: 0.0068841357715427876\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 3.6138505935668945 | KNN Loss: 3.596959352493286 | CLS Loss: 0.01689114235341549\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 3.624711513519287 | KNN Loss: 3.6015396118164062 | CLS Loss: 0.023171784356236458\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 3.6170806884765625 | KNN Loss: 3.602236032485962 | CLS Loss: 0.01484466902911663\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 3.5952723026275635 | KNN Loss: 3.577686309814453 | CLS Loss: 0.01758597232401371\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 3.607052803039551 | KNN Loss: 3.6027517318725586 | CLS Loss: 0.004301021806895733\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 3.642848253250122 | KNN Loss: 3.622572183609009 | CLS Loss: 0.020276160910725594\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 3.6113858222961426 | KNN Loss: 3.6025664806365967 | CLS Loss: 0.008819459937512875\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 3.6406540870666504 | KNN Loss: 3.623687744140625 | CLS Loss: 0.016966328024864197\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 3.667963743209839 | KNN Loss: 3.656644582748413 | CLS Loss: 0.011319237761199474\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 3.612884759902954 | KNN Loss: 3.608470916748047 | CLS Loss: 0.004413803573697805\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 3.641112804412842 | KNN Loss: 3.631633996963501 | CLS Loss: 0.00947889219969511\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 3.6229772567749023 | KNN Loss: 3.595128059387207 | CLS Loss: 0.02784907817840576\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 3.62845778465271 | KNN Loss: 3.609132766723633 | CLS Loss: 0.019324924796819687\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 3.615403175354004 | KNN Loss: 3.6039822101593018 | CLS Loss: 0.01142094936221838\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 3.592618465423584 | KNN Loss: 3.576511859893799 | CLS Loss: 0.016106531023979187\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 3.6316020488739014 | KNN Loss: 3.617145299911499 | CLS Loss: 0.014456680044531822\n",
      "Epoch: 083, Loss: 3.6278, Train: 0.9952, Valid: 0.9839, Best: 0.9881\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 3.612565279006958 | KNN Loss: 3.6017110347747803 | CLS Loss: 0.010854143649339676\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 3.6189510822296143 | KNN Loss: 3.6113815307617188 | CLS Loss: 0.007569627836346626\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 3.644822120666504 | KNN Loss: 3.635939836502075 | CLS Loss: 0.008882268331944942\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 3.61025333404541 | KNN Loss: 3.598109006881714 | CLS Loss: 0.012144424021244049\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 3.640969753265381 | KNN Loss: 3.6190366744995117 | CLS Loss: 0.021933026611804962\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 3.615527629852295 | KNN Loss: 3.5892348289489746 | CLS Loss: 0.026292875409126282\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 3.6926753520965576 | KNN Loss: 3.6832756996154785 | CLS Loss: 0.009399604052305222\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 3.6239168643951416 | KNN Loss: 3.616349697113037 | CLS Loss: 0.007567276246845722\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 3.6104650497436523 | KNN Loss: 3.5890414714813232 | CLS Loss: 0.021423479542136192\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 3.6476376056671143 | KNN Loss: 3.635568380355835 | CLS Loss: 0.01206926442682743\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 3.628493547439575 | KNN Loss: 3.6187944412231445 | CLS Loss: 0.009699005633592606\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 3.60191011428833 | KNN Loss: 3.5861616134643555 | CLS Loss: 0.015748444944620132\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 3.6584744453430176 | KNN Loss: 3.629408836364746 | CLS Loss: 0.029065527021884918\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 3.5871543884277344 | KNN Loss: 3.5794215202331543 | CLS Loss: 0.007732918951660395\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 3.683664560317993 | KNN Loss: 3.6685233116149902 | CLS Loss: 0.015141352079808712\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 3.6642203330993652 | KNN Loss: 3.64579701423645 | CLS Loss: 0.018423235043883324\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 3.702216148376465 | KNN Loss: 3.6702351570129395 | CLS Loss: 0.03198089823126793\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 3.6179521083831787 | KNN Loss: 3.60703182220459 | CLS Loss: 0.010920282453298569\n",
      "Epoch: 084, Loss: 3.6333, Train: 0.9962, Valid: 0.9861, Best: 0.9881\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 3.632404327392578 | KNN Loss: 3.6066930294036865 | CLS Loss: 0.025711383670568466\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 3.6190388202667236 | KNN Loss: 3.6124460697174072 | CLS Loss: 0.006592826917767525\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 3.574368476867676 | KNN Loss: 3.5678486824035645 | CLS Loss: 0.006519697140902281\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 3.627004623413086 | KNN Loss: 3.5929720401763916 | CLS Loss: 0.034032486379146576\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 3.5834858417510986 | KNN Loss: 3.578590154647827 | CLS Loss: 0.004895578138530254\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 3.612677812576294 | KNN Loss: 3.5971503257751465 | CLS Loss: 0.015527439303696156\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 3.608350992202759 | KNN Loss: 3.579770088195801 | CLS Loss: 0.028580931946635246\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 3.59159255027771 | KNN Loss: 3.5812902450561523 | CLS Loss: 0.010302330367267132\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 3.6279938220977783 | KNN Loss: 3.605161666870117 | CLS Loss: 0.02283221110701561\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 3.6425576210021973 | KNN Loss: 3.6301698684692383 | CLS Loss: 0.012387663125991821\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 3.5968945026397705 | KNN Loss: 3.588980197906494 | CLS Loss: 0.007914237678050995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 3.6526379585266113 | KNN Loss: 3.6186540126800537 | CLS Loss: 0.03398396819829941\n",
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 3.6158230304718018 | KNN Loss: 3.605956554412842 | CLS Loss: 0.009866478852927685\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 3.6284825801849365 | KNN Loss: 3.599581003189087 | CLS Loss: 0.028901543468236923\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 3.6334500312805176 | KNN Loss: 3.626453161239624 | CLS Loss: 0.006996871437877417\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 3.5954108238220215 | KNN Loss: 3.577103614807129 | CLS Loss: 0.018307199701666832\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 3.5969326496124268 | KNN Loss: 3.5808956623077393 | CLS Loss: 0.01603698544204235\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 3.618598461151123 | KNN Loss: 3.611574411392212 | CLS Loss: 0.007024068851023912\n",
      "Epoch: 085, Loss: 3.6276, Train: 0.9963, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 3.642717123031616 | KNN Loss: 3.6295571327209473 | CLS Loss: 0.013159898109734058\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 3.637535810470581 | KNN Loss: 3.61244535446167 | CLS Loss: 0.025090539827942848\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 3.6117961406707764 | KNN Loss: 3.5946669578552246 | CLS Loss: 0.01712925359606743\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 3.6146693229675293 | KNN Loss: 3.5960946083068848 | CLS Loss: 0.018574802204966545\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 3.6129403114318848 | KNN Loss: 3.600396156311035 | CLS Loss: 0.012544238939881325\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 3.646369695663452 | KNN Loss: 3.6332881450653076 | CLS Loss: 0.013081437908113003\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 3.6322381496429443 | KNN Loss: 3.6244795322418213 | CLS Loss: 0.007758524734526873\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 3.573173999786377 | KNN Loss: 3.568554639816284 | CLS Loss: 0.004619367886334658\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 3.6180062294006348 | KNN Loss: 3.595155715942383 | CLS Loss: 0.022850485518574715\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 3.601590156555176 | KNN Loss: 3.5797224044799805 | CLS Loss: 0.021867671981453896\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 3.6171000003814697 | KNN Loss: 3.6018126010894775 | CLS Loss: 0.015287434682250023\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 3.6060943603515625 | KNN Loss: 3.5988481044769287 | CLS Loss: 0.007246191613376141\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 3.6061716079711914 | KNN Loss: 3.598816156387329 | CLS Loss: 0.007355338893830776\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 3.659416913986206 | KNN Loss: 3.6270155906677246 | CLS Loss: 0.032401423901319504\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 3.627601385116577 | KNN Loss: 3.6026556491851807 | CLS Loss: 0.02494576945900917\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 3.6208691596984863 | KNN Loss: 3.586339235305786 | CLS Loss: 0.03452993929386139\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 3.6427626609802246 | KNN Loss: 3.605464220046997 | CLS Loss: 0.03729837015271187\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 3.6419503688812256 | KNN Loss: 3.6266415119171143 | CLS Loss: 0.015308757312595844\n",
      "Epoch: 086, Loss: 3.6259, Train: 0.9938, Valid: 0.9856, Best: 0.9881\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 3.598707675933838 | KNN Loss: 3.594095230102539 | CLS Loss: 0.00461242813616991\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 3.601635456085205 | KNN Loss: 3.5993754863739014 | CLS Loss: 0.0022600230295211077\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 3.6270482540130615 | KNN Loss: 3.6097519397735596 | CLS Loss: 0.017296355217695236\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 3.6553564071655273 | KNN Loss: 3.6143059730529785 | CLS Loss: 0.04105043411254883\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 3.6495003700256348 | KNN Loss: 3.6333179473876953 | CLS Loss: 0.016182364895939827\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 3.6200714111328125 | KNN Loss: 3.5990922451019287 | CLS Loss: 0.02097914181649685\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 3.6161763668060303 | KNN Loss: 3.6038429737091064 | CLS Loss: 0.01233329251408577\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 3.613320827484131 | KNN Loss: 3.606741189956665 | CLS Loss: 0.0065796650014817715\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 3.619678258895874 | KNN Loss: 3.5833306312561035 | CLS Loss: 0.03634754940867424\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 3.6261067390441895 | KNN Loss: 3.5970895290374756 | CLS Loss: 0.029017223045229912\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 3.6087098121643066 | KNN Loss: 3.5985543727874756 | CLS Loss: 0.010155401192605495\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 3.633275032043457 | KNN Loss: 3.61617374420166 | CLS Loss: 0.01710137538611889\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 3.6140613555908203 | KNN Loss: 3.5954554080963135 | CLS Loss: 0.018606049939990044\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 3.64178204536438 | KNN Loss: 3.621868371963501 | CLS Loss: 0.01991378702223301\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 3.631101131439209 | KNN Loss: 3.6238040924072266 | CLS Loss: 0.007296964526176453\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 3.599273443222046 | KNN Loss: 3.5798418521881104 | CLS Loss: 0.019431553781032562\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 3.637902021408081 | KNN Loss: 3.623769760131836 | CLS Loss: 0.014132359996438026\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 3.6299898624420166 | KNN Loss: 3.6177432537078857 | CLS Loss: 0.012246714904904366\n",
      "Epoch: 087, Loss: 3.6302, Train: 0.9957, Valid: 0.9858, Best: 0.9881\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 3.6175143718719482 | KNN Loss: 3.5996551513671875 | CLS Loss: 0.017859259620308876\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 3.6904876232147217 | KNN Loss: 3.676643133163452 | CLS Loss: 0.013844447210431099\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 3.6343472003936768 | KNN Loss: 3.610560894012451 | CLS Loss: 0.023786352947354317\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 3.6181187629699707 | KNN Loss: 3.6036288738250732 | CLS Loss: 0.01448989287018776\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 3.6143038272857666 | KNN Loss: 3.598489999771118 | CLS Loss: 0.015813833102583885\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 3.597017765045166 | KNN Loss: 3.5824878215789795 | CLS Loss: 0.014529959298670292\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 3.645480155944824 | KNN Loss: 3.62473726272583 | CLS Loss: 0.02074279449880123\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 3.578038454055786 | KNN Loss: 3.575269937515259 | CLS Loss: 0.002768623875454068\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 3.610276460647583 | KNN Loss: 3.603471279144287 | CLS Loss: 0.006805093493312597\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 3.60931658744812 | KNN Loss: 3.587975025177002 | CLS Loss: 0.02134159952402115\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 3.644491195678711 | KNN Loss: 3.61401629447937 | CLS Loss: 0.030474839732050896\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 3.6421260833740234 | KNN Loss: 3.6358864307403564 | CLS Loss: 0.006239769514650106\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 3.60809588432312 | KNN Loss: 3.5962376594543457 | CLS Loss: 0.011858326382935047\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 3.6475930213928223 | KNN Loss: 3.6149673461914062 | CLS Loss: 0.032625794410705566\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 3.6180591583251953 | KNN Loss: 3.589015007019043 | CLS Loss: 0.02904408797621727\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 3.616051435470581 | KNN Loss: 3.5980379581451416 | CLS Loss: 0.0180133655667305\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 3.6700680255889893 | KNN Loss: 3.650411367416382 | CLS Loss: 0.019656570628285408\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 3.610097646713257 | KNN Loss: 3.5988330841064453 | CLS Loss: 0.01126448530703783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 088, Loss: 3.6282, Train: 0.9950, Valid: 0.9861, Best: 0.9881\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 3.6097090244293213 | KNN Loss: 3.5991828441619873 | CLS Loss: 0.01052629854530096\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 3.61694073677063 | KNN Loss: 3.6133177280426025 | CLS Loss: 0.0036229512188583612\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 3.6056883335113525 | KNN Loss: 3.5985605716705322 | CLS Loss: 0.00712782796472311\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 3.646388530731201 | KNN Loss: 3.6406948566436768 | CLS Loss: 0.0056937141343951225\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 3.5958356857299805 | KNN Loss: 3.5877678394317627 | CLS Loss: 0.008067801594734192\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 3.6543004512786865 | KNN Loss: 3.641294240951538 | CLS Loss: 0.013006219640374184\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 3.637173652648926 | KNN Loss: 3.615574359893799 | CLS Loss: 0.02159930393099785\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 3.6169798374176025 | KNN Loss: 3.6063036918640137 | CLS Loss: 0.010676093399524689\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 3.6075854301452637 | KNN Loss: 3.591348648071289 | CLS Loss: 0.016236860305070877\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 3.5824527740478516 | KNN Loss: 3.577927827835083 | CLS Loss: 0.004525036551058292\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 3.6276445388793945 | KNN Loss: 3.6142373085021973 | CLS Loss: 0.013407178223133087\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 3.612719774246216 | KNN Loss: 3.588820219039917 | CLS Loss: 0.023899445310235023\n",
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 3.6653482913970947 | KNN Loss: 3.628080129623413 | CLS Loss: 0.03726818412542343\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 3.6079883575439453 | KNN Loss: 3.6025288105010986 | CLS Loss: 0.005459576845169067\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 3.574955940246582 | KNN Loss: 3.5668258666992188 | CLS Loss: 0.008130090311169624\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 3.6269352436065674 | KNN Loss: 3.616763114929199 | CLS Loss: 0.010172095149755478\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 3.681147336959839 | KNN Loss: 3.643824577331543 | CLS Loss: 0.037322670221328735\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 3.6141183376312256 | KNN Loss: 3.5900111198425293 | CLS Loss: 0.024107277393341064\n",
      "Epoch: 089, Loss: 3.6258, Train: 0.9948, Valid: 0.9850, Best: 0.9881\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 3.6235740184783936 | KNN Loss: 3.61303448677063 | CLS Loss: 0.010539497248828411\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 3.6303606033325195 | KNN Loss: 3.603767156600952 | CLS Loss: 0.026593461632728577\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 3.6533145904541016 | KNN Loss: 3.616772413253784 | CLS Loss: 0.036542125046253204\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 3.596052885055542 | KNN Loss: 3.583864450454712 | CLS Loss: 0.012188432738184929\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 3.589581251144409 | KNN Loss: 3.577765703201294 | CLS Loss: 0.011815544217824936\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 3.6436009407043457 | KNN Loss: 3.596592426300049 | CLS Loss: 0.047008439898490906\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 3.6045708656311035 | KNN Loss: 3.599212646484375 | CLS Loss: 0.005358230788260698\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 3.6290981769561768 | KNN Loss: 3.621180772781372 | CLS Loss: 0.007917474955320358\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 3.619077205657959 | KNN Loss: 3.603055953979492 | CLS Loss: 0.01602129451930523\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 3.643374443054199 | KNN Loss: 3.626990556716919 | CLS Loss: 0.016383862122893333\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 3.678196430206299 | KNN Loss: 3.6562325954437256 | CLS Loss: 0.02196379005908966\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 3.61053466796875 | KNN Loss: 3.593379497528076 | CLS Loss: 0.017155058681964874\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 3.618499517440796 | KNN Loss: 3.5928304195404053 | CLS Loss: 0.025669123977422714\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 3.6429431438446045 | KNN Loss: 3.6245222091674805 | CLS Loss: 0.018420999869704247\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 3.6332321166992188 | KNN Loss: 3.6214005947113037 | CLS Loss: 0.011831473559141159\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 3.6307671070098877 | KNN Loss: 3.619145154953003 | CLS Loss: 0.011621889658272266\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 3.613715410232544 | KNN Loss: 3.604092597961426 | CLS Loss: 0.009622892364859581\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 3.6538994312286377 | KNN Loss: 3.642296075820923 | CLS Loss: 0.011603257618844509\n",
      "Epoch: 090, Loss: 3.6251, Train: 0.9960, Valid: 0.9873, Best: 0.9881\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 3.6041228771209717 | KNN Loss: 3.5819482803344727 | CLS Loss: 0.022174546495079994\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 3.6486079692840576 | KNN Loss: 3.637746810913086 | CLS Loss: 0.010861126706004143\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 3.659268379211426 | KNN Loss: 3.632148265838623 | CLS Loss: 0.027120156213641167\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 3.6117100715637207 | KNN Loss: 3.598172187805176 | CLS Loss: 0.013537930324673653\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 3.6168289184570312 | KNN Loss: 3.611515998840332 | CLS Loss: 0.005312839522957802\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 3.6545474529266357 | KNN Loss: 3.6478257179260254 | CLS Loss: 0.006721821613609791\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 3.5964555740356445 | KNN Loss: 3.59303879737854 | CLS Loss: 0.0034168357960879803\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 3.6125333309173584 | KNN Loss: 3.5880696773529053 | CLS Loss: 0.024463698267936707\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 3.5980777740478516 | KNN Loss: 3.582625389099121 | CLS Loss: 0.015452451072633266\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 3.6294212341308594 | KNN Loss: 3.6180920600891113 | CLS Loss: 0.011329232715070248\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 3.608473777770996 | KNN Loss: 3.5925118923187256 | CLS Loss: 0.015961909666657448\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 3.6351981163024902 | KNN Loss: 3.6246695518493652 | CLS Loss: 0.010528557002544403\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 3.606926918029785 | KNN Loss: 3.5919861793518066 | CLS Loss: 0.014940829947590828\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 3.6066737174987793 | KNN Loss: 3.602855920791626 | CLS Loss: 0.0038178369868546724\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 3.598738670349121 | KNN Loss: 3.5943429470062256 | CLS Loss: 0.004395656753331423\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 3.5976505279541016 | KNN Loss: 3.592257499694824 | CLS Loss: 0.005393114406615496\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 3.629817485809326 | KNN Loss: 3.6007673740386963 | CLS Loss: 0.02905009314417839\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 3.5907981395721436 | KNN Loss: 3.586827278137207 | CLS Loss: 0.003970904741436243\n",
      "Epoch: 091, Loss: 3.6271, Train: 0.9960, Valid: 0.9868, Best: 0.9881\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 3.595879077911377 | KNN Loss: 3.5867276191711426 | CLS Loss: 0.009151474572718143\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 3.621222496032715 | KNN Loss: 3.605175733566284 | CLS Loss: 0.016046738252043724\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 3.6542153358459473 | KNN Loss: 3.6411547660827637 | CLS Loss: 0.013060471042990685\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 3.633667469024658 | KNN Loss: 3.612844705581665 | CLS Loss: 0.020822707563638687\n",
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 3.614164352416992 | KNN Loss: 3.5819907188415527 | CLS Loss: 0.03217364102602005\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 3.611384630203247 | KNN Loss: 3.6041407585144043 | CLS Loss: 0.007243753876537085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 3.6299216747283936 | KNN Loss: 3.6202521324157715 | CLS Loss: 0.009669617749750614\n",
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 3.604034900665283 | KNN Loss: 3.5838005542755127 | CLS Loss: 0.020234448835253716\n",
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 3.6052756309509277 | KNN Loss: 3.6022756099700928 | CLS Loss: 0.002999914577230811\n",
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 3.6048531532287598 | KNN Loss: 3.6022427082061768 | CLS Loss: 0.0026104506105184555\n",
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 3.6874210834503174 | KNN Loss: 3.6572487354278564 | CLS Loss: 0.03017231449484825\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 3.616624355316162 | KNN Loss: 3.601573944091797 | CLS Loss: 0.015050292015075684\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 3.612304449081421 | KNN Loss: 3.5936269760131836 | CLS Loss: 0.01867748610675335\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 3.6032867431640625 | KNN Loss: 3.5819337368011475 | CLS Loss: 0.02135312557220459\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 3.6083028316497803 | KNN Loss: 3.5809223651885986 | CLS Loss: 0.027380427345633507\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 3.6085376739501953 | KNN Loss: 3.595311403274536 | CLS Loss: 0.013226295821368694\n",
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 3.6104512214660645 | KNN Loss: 3.5844621658325195 | CLS Loss: 0.025988975539803505\n",
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 3.601726531982422 | KNN Loss: 3.5808708667755127 | CLS Loss: 0.02085558883845806\n",
      "Epoch: 092, Loss: 3.6209, Train: 0.9964, Valid: 0.9865, Best: 0.9881\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 3.591381788253784 | KNN Loss: 3.579340934753418 | CLS Loss: 0.01204084511846304\n",
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 3.6479451656341553 | KNN Loss: 3.6123695373535156 | CLS Loss: 0.03557562083005905\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 3.609696865081787 | KNN Loss: 3.6016159057617188 | CLS Loss: 0.008081013336777687\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 3.615452527999878 | KNN Loss: 3.60443115234375 | CLS Loss: 0.011021302081644535\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 3.6396844387054443 | KNN Loss: 3.619997978210449 | CLS Loss: 0.019686492159962654\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 3.5815370082855225 | KNN Loss: 3.574636697769165 | CLS Loss: 0.006900395732372999\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 3.6107163429260254 | KNN Loss: 3.5989553928375244 | CLS Loss: 0.011760838329792023\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 3.6216163635253906 | KNN Loss: 3.607328414916992 | CLS Loss: 0.014287867583334446\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 3.607034921646118 | KNN Loss: 3.5945115089416504 | CLS Loss: 0.01252333726733923\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 3.615004539489746 | KNN Loss: 3.593167543411255 | CLS Loss: 0.02183694578707218\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 3.6088716983795166 | KNN Loss: 3.5956029891967773 | CLS Loss: 0.013268635608255863\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 3.63560152053833 | KNN Loss: 3.6261234283447266 | CLS Loss: 0.009478204883635044\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 3.635016441345215 | KNN Loss: 3.6057684421539307 | CLS Loss: 0.029248103499412537\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 3.6076393127441406 | KNN Loss: 3.5971643924713135 | CLS Loss: 0.010475014336407185\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 3.581373929977417 | KNN Loss: 3.5638694763183594 | CLS Loss: 0.01750451698899269\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 3.647616147994995 | KNN Loss: 3.644056558609009 | CLS Loss: 0.0035596319939941168\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 3.665005922317505 | KNN Loss: 3.6547887325286865 | CLS Loss: 0.01021720189601183\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 3.6379971504211426 | KNN Loss: 3.6185648441314697 | CLS Loss: 0.01943226531147957\n",
      "Epoch: 093, Loss: 3.6237, Train: 0.9958, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 3.646921396255493 | KNN Loss: 3.6312079429626465 | CLS Loss: 0.015713443979620934\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 3.64009165763855 | KNN Loss: 3.627101421356201 | CLS Loss: 0.012990124523639679\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 3.6254985332489014 | KNN Loss: 3.6122078895568848 | CLS Loss: 0.01329069770872593\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 3.60721492767334 | KNN Loss: 3.6022956371307373 | CLS Loss: 0.0049191853031516075\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 3.6542792320251465 | KNN Loss: 3.6259045600891113 | CLS Loss: 0.028374604880809784\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 3.60894775390625 | KNN Loss: 3.598795175552368 | CLS Loss: 0.010152474977076054\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 3.608668804168701 | KNN Loss: 3.5945818424224854 | CLS Loss: 0.014086900278925896\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 3.6492760181427 | KNN Loss: 3.6403913497924805 | CLS Loss: 0.00888470746576786\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 3.6900641918182373 | KNN Loss: 3.6749255657196045 | CLS Loss: 0.015138540416955948\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 3.6022086143493652 | KNN Loss: 3.5958070755004883 | CLS Loss: 0.006401621736586094\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 3.6148343086242676 | KNN Loss: 3.6076555252075195 | CLS Loss: 0.007178833708167076\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 3.594693899154663 | KNN Loss: 3.5696184635162354 | CLS Loss: 0.025075513869524002\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 3.653917074203491 | KNN Loss: 3.644479751586914 | CLS Loss: 0.009437265805900097\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 3.6015100479125977 | KNN Loss: 3.5935795307159424 | CLS Loss: 0.007930588908493519\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 3.6035358905792236 | KNN Loss: 3.584228038787842 | CLS Loss: 0.019307846203446388\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 3.605571746826172 | KNN Loss: 3.5941250324249268 | CLS Loss: 0.011446795426309109\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 3.614647626876831 | KNN Loss: 3.5920913219451904 | CLS Loss: 0.022556381300091743\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 3.613492250442505 | KNN Loss: 3.592632293701172 | CLS Loss: 0.020860016345977783\n",
      "Epoch: 094, Loss: 3.6299, Train: 0.9965, Valid: 0.9862, Best: 0.9881\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 3.6682369709014893 | KNN Loss: 3.6637253761291504 | CLS Loss: 0.004511690232902765\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 3.711202621459961 | KNN Loss: 3.705437421798706 | CLS Loss: 0.0057651507668197155\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 3.6496779918670654 | KNN Loss: 3.639143705368042 | CLS Loss: 0.010534171015024185\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 3.602436065673828 | KNN Loss: 3.577749490737915 | CLS Loss: 0.0246865414083004\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 3.59342885017395 | KNN Loss: 3.5894999504089355 | CLS Loss: 0.00392901711165905\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 3.6165030002593994 | KNN Loss: 3.607452392578125 | CLS Loss: 0.009050714783370495\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 3.6783673763275146 | KNN Loss: 3.652409791946411 | CLS Loss: 0.025957519188523293\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 3.6791183948516846 | KNN Loss: 3.6689040660858154 | CLS Loss: 0.010214446112513542\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 3.592437744140625 | KNN Loss: 3.588315725326538 | CLS Loss: 0.0041221086867153645\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 3.643108606338501 | KNN Loss: 3.6333465576171875 | CLS Loss: 0.009762035682797432\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 3.6036481857299805 | KNN Loss: 3.5980911254882812 | CLS Loss: 0.005557169206440449\n",
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 3.6310606002807617 | KNN Loss: 3.6248056888580322 | CLS Loss: 0.006254885345697403\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 3.6206531524658203 | KNN Loss: 3.6118414402008057 | CLS Loss: 0.008811596781015396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 3.6031577587127686 | KNN Loss: 3.5908613204956055 | CLS Loss: 0.012296427972614765\n",
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 3.6065027713775635 | KNN Loss: 3.599504232406616 | CLS Loss: 0.006998507771641016\n",
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 3.6330788135528564 | KNN Loss: 3.6258912086486816 | CLS Loss: 0.007187516428530216\n",
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 3.60300874710083 | KNN Loss: 3.5895142555236816 | CLS Loss: 0.013494417071342468\n",
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 3.6084210872650146 | KNN Loss: 3.607045888900757 | CLS Loss: 0.0013751289807260036\n",
      "Epoch: 095, Loss: 3.6249, Train: 0.9965, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 3.626405715942383 | KNN Loss: 3.6208367347717285 | CLS Loss: 0.005568910855799913\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 3.7036592960357666 | KNN Loss: 3.6880064010620117 | CLS Loss: 0.015652917325496674\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 3.620191812515259 | KNN Loss: 3.6157946586608887 | CLS Loss: 0.004397050477564335\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 3.6090598106384277 | KNN Loss: 3.5979299545288086 | CLS Loss: 0.011129893362522125\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 3.638115167617798 | KNN Loss: 3.632237434387207 | CLS Loss: 0.005877739284187555\n",
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 3.6033308506011963 | KNN Loss: 3.5995450019836426 | CLS Loss: 0.0037858278956264257\n",
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 3.635014295578003 | KNN Loss: 3.625180721282959 | CLS Loss: 0.009833525866270065\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 3.5846176147460938 | KNN Loss: 3.5797650814056396 | CLS Loss: 0.004852602258324623\n",
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 3.658503293991089 | KNN Loss: 3.6122043132781982 | CLS Loss: 0.046299006789922714\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 3.587393283843994 | KNN Loss: 3.579047918319702 | CLS Loss: 0.008345476351678371\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 3.612534523010254 | KNN Loss: 3.5769901275634766 | CLS Loss: 0.035544395446777344\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 3.6101772785186768 | KNN Loss: 3.603642225265503 | CLS Loss: 0.006535031832754612\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 3.6230599880218506 | KNN Loss: 3.6120645999908447 | CLS Loss: 0.010995419695973396\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 3.6004750728607178 | KNN Loss: 3.592259645462036 | CLS Loss: 0.008215525187551975\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 3.6116325855255127 | KNN Loss: 3.600677967071533 | CLS Loss: 0.01095470879226923\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 3.6115167140960693 | KNN Loss: 3.6031014919281006 | CLS Loss: 0.008415233343839645\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 3.718764543533325 | KNN Loss: 3.684913396835327 | CLS Loss: 0.03385120630264282\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 3.6133906841278076 | KNN Loss: 3.5957350730895996 | CLS Loss: 0.01765552908182144\n",
      "Epoch: 096, Loss: 3.6260, Train: 0.9968, Valid: 0.9877, Best: 0.9881\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 3.6387462615966797 | KNN Loss: 3.625871181488037 | CLS Loss: 0.012875096872448921\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 3.648879051208496 | KNN Loss: 3.6282031536102295 | CLS Loss: 0.02067588083446026\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 3.6275370121002197 | KNN Loss: 3.622983455657959 | CLS Loss: 0.00455363979563117\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 3.5931990146636963 | KNN Loss: 3.5821402072906494 | CLS Loss: 0.011058785021305084\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 3.6773324012756348 | KNN Loss: 3.6548025608062744 | CLS Loss: 0.022529909387230873\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 3.610726833343506 | KNN Loss: 3.590711832046509 | CLS Loss: 0.020014937967061996\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 3.6191279888153076 | KNN Loss: 3.598351240158081 | CLS Loss: 0.020776810124516487\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 3.6435351371765137 | KNN Loss: 3.6393392086029053 | CLS Loss: 0.004195816814899445\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 3.625688314437866 | KNN Loss: 3.601515769958496 | CLS Loss: 0.024172546342015266\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 3.624457836151123 | KNN Loss: 3.614774703979492 | CLS Loss: 0.009683084674179554\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 3.6399450302124023 | KNN Loss: 3.6077682971954346 | CLS Loss: 0.032176680862903595\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 3.604097366333008 | KNN Loss: 3.5920891761779785 | CLS Loss: 0.012008307501673698\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 3.6446924209594727 | KNN Loss: 3.62091064453125 | CLS Loss: 0.023781798779964447\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 3.6205978393554688 | KNN Loss: 3.615726947784424 | CLS Loss: 0.004870912525802851\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 3.609236240386963 | KNN Loss: 3.5956478118896484 | CLS Loss: 0.013588378205895424\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 3.707653522491455 | KNN Loss: 3.6852424144744873 | CLS Loss: 0.022411007434129715\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 3.617542266845703 | KNN Loss: 3.592238187789917 | CLS Loss: 0.02530408278107643\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 3.6405417919158936 | KNN Loss: 3.6227974891662598 | CLS Loss: 0.017744235694408417\n",
      "Epoch: 097, Loss: 3.6313, Train: 0.9952, Valid: 0.9863, Best: 0.9881\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 3.599297285079956 | KNN Loss: 3.592522621154785 | CLS Loss: 0.006774664390832186\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 3.6427998542785645 | KNN Loss: 3.627647876739502 | CLS Loss: 0.01515206042677164\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 3.618755340576172 | KNN Loss: 3.6138739585876465 | CLS Loss: 0.004881456959992647\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 3.593367576599121 | KNN Loss: 3.5752670764923096 | CLS Loss: 0.018100472167134285\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 3.6022915840148926 | KNN Loss: 3.600645065307617 | CLS Loss: 0.0016465717926621437\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 3.637012004852295 | KNN Loss: 3.6064231395721436 | CLS Loss: 0.03058883175253868\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 3.6070713996887207 | KNN Loss: 3.60485577583313 | CLS Loss: 0.0022156494669616222\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 3.6199097633361816 | KNN Loss: 3.611518383026123 | CLS Loss: 0.008391357958316803\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 3.613025426864624 | KNN Loss: 3.5997822284698486 | CLS Loss: 0.013243155553936958\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 3.641456127166748 | KNN Loss: 3.6268022060394287 | CLS Loss: 0.01465398445725441\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 3.6409566402435303 | KNN Loss: 3.6293935775756836 | CLS Loss: 0.011563017964363098\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 3.593801975250244 | KNN Loss: 3.5900814533233643 | CLS Loss: 0.003720485372468829\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 3.597028970718384 | KNN Loss: 3.5928287506103516 | CLS Loss: 0.00420032674446702\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 3.6880548000335693 | KNN Loss: 3.672849655151367 | CLS Loss: 0.015205157920718193\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 3.686894416809082 | KNN Loss: 3.684885025024414 | CLS Loss: 0.002009456278756261\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 3.609121561050415 | KNN Loss: 3.5916340351104736 | CLS Loss: 0.017487427219748497\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 3.597057580947876 | KNN Loss: 3.5782995223999023 | CLS Loss: 0.018758030608296394\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 3.6222262382507324 | KNN Loss: 3.614931344985962 | CLS Loss: 0.007294954266399145\n",
      "Epoch: 098, Loss: 3.6256, Train: 0.9972, Valid: 0.9868, Best: 0.9881\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 3.5909883975982666 | KNN Loss: 3.573366641998291 | CLS Loss: 0.017621777951717377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 3.607104778289795 | KNN Loss: 3.604343891143799 | CLS Loss: 0.0027609674725681543\n",
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 3.593759536743164 | KNN Loss: 3.586265802383423 | CLS Loss: 0.00749370688572526\n",
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 3.6244349479675293 | KNN Loss: 3.6207594871520996 | CLS Loss: 0.0036754265893250704\n",
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 3.600209951400757 | KNN Loss: 3.5927391052246094 | CLS Loss: 0.007470823358744383\n",
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 3.6026833057403564 | KNN Loss: 3.5829503536224365 | CLS Loss: 0.01973291113972664\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 3.58573842048645 | KNN Loss: 3.5762736797332764 | CLS Loss: 0.00946483388543129\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 3.565946340560913 | KNN Loss: 3.5513689517974854 | CLS Loss: 0.014577271416783333\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 3.622305393218994 | KNN Loss: 3.5953266620635986 | CLS Loss: 0.02697879634797573\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 3.606576919555664 | KNN Loss: 3.596297025680542 | CLS Loss: 0.010279995389282703\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 3.661902666091919 | KNN Loss: 3.6149938106536865 | CLS Loss: 0.046908970922231674\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 3.5881245136260986 | KNN Loss: 3.5797808170318604 | CLS Loss: 0.008343610912561417\n",
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 3.606123208999634 | KNN Loss: 3.600153923034668 | CLS Loss: 0.005969255696982145\n",
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 3.592684030532837 | KNN Loss: 3.589459180831909 | CLS Loss: 0.0032247700728476048\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 3.6372101306915283 | KNN Loss: 3.636157512664795 | CLS Loss: 0.001052514766342938\n",
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 3.6481592655181885 | KNN Loss: 3.6262247562408447 | CLS Loss: 0.02193455584347248\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 3.579782247543335 | KNN Loss: 3.572216510772705 | CLS Loss: 0.0075656878761947155\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 3.619713068008423 | KNN Loss: 3.6064834594726562 | CLS Loss: 0.013229628093540668\n",
      "Epoch: 099, Loss: 3.6183, Train: 0.9970, Valid: 0.9865, Best: 0.9881\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 3.664947748184204 | KNN Loss: 3.6516623497009277 | CLS Loss: 0.013285461813211441\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 3.5873217582702637 | KNN Loss: 3.5822503566741943 | CLS Loss: 0.005071359220892191\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 3.58150315284729 | KNN Loss: 3.566284656524658 | CLS Loss: 0.015218392945826054\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 3.636669635772705 | KNN Loss: 3.624803304672241 | CLS Loss: 0.011866351589560509\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 3.656083345413208 | KNN Loss: 3.6255998611450195 | CLS Loss: 0.030483581125736237\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 3.616886615753174 | KNN Loss: 3.5995819568634033 | CLS Loss: 0.017304588109254837\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 3.6150734424591064 | KNN Loss: 3.6033501625061035 | CLS Loss: 0.011723222211003304\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 3.678802967071533 | KNN Loss: 3.647665500640869 | CLS Loss: 0.031137356534600258\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 3.616227626800537 | KNN Loss: 3.60455060005188 | CLS Loss: 0.011677004396915436\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 3.5828115940093994 | KNN Loss: 3.579768180847168 | CLS Loss: 0.0030432995408773422\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 3.595238208770752 | KNN Loss: 3.5922508239746094 | CLS Loss: 0.002987376879900694\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 3.6022424697875977 | KNN Loss: 3.5838232040405273 | CLS Loss: 0.018419168889522552\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 3.582916736602783 | KNN Loss: 3.5754880905151367 | CLS Loss: 0.007428575307130814\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 3.5810816287994385 | KNN Loss: 3.5789618492126465 | CLS Loss: 0.002119780983775854\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 3.601022243499756 | KNN Loss: 3.5940191745758057 | CLS Loss: 0.007003020029515028\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 3.6064276695251465 | KNN Loss: 3.5984556674957275 | CLS Loss: 0.007971999235451221\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 3.665188789367676 | KNN Loss: 3.614875555038452 | CLS Loss: 0.05031333863735199\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 3.621462345123291 | KNN Loss: 3.606219530105591 | CLS Loss: 0.015242718160152435\n",
      "Epoch: 100, Loss: 3.6196, Train: 0.9954, Valid: 0.9861, Best: 0.9881\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 3.6794357299804688 | KNN Loss: 3.6725335121154785 | CLS Loss: 0.006902290973812342\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 3.615920066833496 | KNN Loss: 3.5956690311431885 | CLS Loss: 0.020250923931598663\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 3.6421420574188232 | KNN Loss: 3.6060147285461426 | CLS Loss: 0.036127347499132156\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 3.6497974395751953 | KNN Loss: 3.644252300262451 | CLS Loss: 0.00554507365450263\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 3.6186678409576416 | KNN Loss: 3.6128060817718506 | CLS Loss: 0.005861661862581968\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 3.6028056144714355 | KNN Loss: 3.5843558311462402 | CLS Loss: 0.018449755385518074\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 3.6295015811920166 | KNN Loss: 3.623297691345215 | CLS Loss: 0.006203820463269949\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 3.598581075668335 | KNN Loss: 3.5638530254364014 | CLS Loss: 0.03472812846302986\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 3.585618734359741 | KNN Loss: 3.582972764968872 | CLS Loss: 0.0026460476219654083\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 3.6301703453063965 | KNN Loss: 3.617518901824951 | CLS Loss: 0.012651530094444752\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 3.669318199157715 | KNN Loss: 3.653242826461792 | CLS Loss: 0.01607547700405121\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 3.608323097229004 | KNN Loss: 3.6010398864746094 | CLS Loss: 0.007283294107764959\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 3.6316230297088623 | KNN Loss: 3.6223676204681396 | CLS Loss: 0.0092554846778512\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 3.660670757293701 | KNN Loss: 3.6576778888702393 | CLS Loss: 0.0029929368756711483\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 3.676144599914551 | KNN Loss: 3.6529362201690674 | CLS Loss: 0.023208312690258026\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 3.6302406787872314 | KNN Loss: 3.621187210083008 | CLS Loss: 0.009053494781255722\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 3.596545457839966 | KNN Loss: 3.5841522216796875 | CLS Loss: 0.012393327429890633\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 3.6455085277557373 | KNN Loss: 3.6314191818237305 | CLS Loss: 0.014089402742683887\n",
      "Epoch: 101, Loss: 3.6195, Train: 0.9970, Valid: 0.9873, Best: 0.9881\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 3.6183996200561523 | KNN Loss: 3.595890522003174 | CLS Loss: 0.022509077563881874\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 3.645805597305298 | KNN Loss: 3.6373887062072754 | CLS Loss: 0.008416849188506603\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 3.582185745239258 | KNN Loss: 3.5804662704467773 | CLS Loss: 0.001719496794976294\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 3.5990750789642334 | KNN Loss: 3.5884852409362793 | CLS Loss: 0.010589768178761005\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 3.614558696746826 | KNN Loss: 3.6131720542907715 | CLS Loss: 0.0013867552625015378\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 3.6194260120391846 | KNN Loss: 3.6019232273101807 | CLS Loss: 0.017502667382359505\n",
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 3.5963377952575684 | KNN Loss: 3.594440221786499 | CLS Loss: 0.0018975298153236508\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 3.6019418239593506 | KNN Loss: 3.599071741104126 | CLS Loss: 0.0028700532857328653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 3.6054251194000244 | KNN Loss: 3.601679801940918 | CLS Loss: 0.0037453973200172186\n",
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 3.6136953830718994 | KNN Loss: 3.6123852729797363 | CLS Loss: 0.0013101596850901842\n",
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 3.6126914024353027 | KNN Loss: 3.5850138664245605 | CLS Loss: 0.027677452191710472\n",
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 3.6270532608032227 | KNN Loss: 3.6112849712371826 | CLS Loss: 0.015768174082040787\n",
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 3.595400094985962 | KNN Loss: 3.5868515968322754 | CLS Loss: 0.008548563346266747\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 3.588284730911255 | KNN Loss: 3.5782132148742676 | CLS Loss: 0.010071457363665104\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 3.601775646209717 | KNN Loss: 3.5766208171844482 | CLS Loss: 0.025154942646622658\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 3.620424270629883 | KNN Loss: 3.6071207523345947 | CLS Loss: 0.013303480111062527\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 3.6519007682800293 | KNN Loss: 3.6364030838012695 | CLS Loss: 0.015497616492211819\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 3.6636734008789062 | KNN Loss: 3.6589574813842773 | CLS Loss: 0.004715839866548777\n",
      "Epoch: 102, Loss: 3.6173, Train: 0.9973, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 3.580368757247925 | KNN Loss: 3.5769548416137695 | CLS Loss: 0.003414020175114274\n",
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 3.610914945602417 | KNN Loss: 3.5986990928649902 | CLS Loss: 0.012215962633490562\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 3.6021840572357178 | KNN Loss: 3.597043991088867 | CLS Loss: 0.005139957647770643\n",
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 3.6449363231658936 | KNN Loss: 3.638181209564209 | CLS Loss: 0.006755199749022722\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 3.5869922637939453 | KNN Loss: 3.5837390422821045 | CLS Loss: 0.003253244562074542\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 3.585460901260376 | KNN Loss: 3.567460060119629 | CLS Loss: 0.018000854179263115\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 3.608299493789673 | KNN Loss: 3.5947563648223877 | CLS Loss: 0.013543217442929745\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 3.5671026706695557 | KNN Loss: 3.565546989440918 | CLS Loss: 0.0015556769212707877\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 3.6541879177093506 | KNN Loss: 3.6492743492126465 | CLS Loss: 0.0049134972505271435\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 3.6279547214508057 | KNN Loss: 3.619992256164551 | CLS Loss: 0.007962530478835106\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 3.611542224884033 | KNN Loss: 3.6013174057006836 | CLS Loss: 0.010224700905382633\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 3.7356951236724854 | KNN Loss: 3.6987547874450684 | CLS Loss: 0.036940280348062515\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 3.6655519008636475 | KNN Loss: 3.640408515930176 | CLS Loss: 0.025143373757600784\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 3.607468605041504 | KNN Loss: 3.591758966445923 | CLS Loss: 0.015709519386291504\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 3.6690292358398438 | KNN Loss: 3.6507346630096436 | CLS Loss: 0.018294602632522583\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 3.648928165435791 | KNN Loss: 3.633943557739258 | CLS Loss: 0.01498454064130783\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 3.646488904953003 | KNN Loss: 3.6231629848480225 | CLS Loss: 0.0233258418738842\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 3.6056981086730957 | KNN Loss: 3.5997097492218018 | CLS Loss: 0.0059883189387619495\n",
      "Epoch: 103, Loss: 3.6216, Train: 0.9961, Valid: 0.9861, Best: 0.9881\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 3.7068631649017334 | KNN Loss: 3.695918560028076 | CLS Loss: 0.010944698005914688\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 3.626581907272339 | KNN Loss: 3.610361099243164 | CLS Loss: 0.016220878809690475\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 3.62778902053833 | KNN Loss: 3.6207692623138428 | CLS Loss: 0.007019797805696726\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 3.6734402179718018 | KNN Loss: 3.665067434310913 | CLS Loss: 0.008372673764824867\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 3.610142230987549 | KNN Loss: 3.601332664489746 | CLS Loss: 0.008809656836092472\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 3.6332452297210693 | KNN Loss: 3.6115381717681885 | CLS Loss: 0.021707110106945038\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 3.6201517581939697 | KNN Loss: 3.5969431400299072 | CLS Loss: 0.02320852503180504\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 3.6068811416625977 | KNN Loss: 3.6008822917938232 | CLS Loss: 0.005998953245580196\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 3.6218056678771973 | KNN Loss: 3.6090760231018066 | CLS Loss: 0.01272953674197197\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 3.6010804176330566 | KNN Loss: 3.594834327697754 | CLS Loss: 0.00624605780467391\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 3.6009252071380615 | KNN Loss: 3.5865650177001953 | CLS Loss: 0.014360196888446808\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 3.5661888122558594 | KNN Loss: 3.560830593109131 | CLS Loss: 0.0053582098335027695\n",
      "Epoch 104 / 200 | iteration 120 / 171 | Total Loss: 3.607588291168213 | KNN Loss: 3.604895830154419 | CLS Loss: 0.002692516427487135\n",
      "Epoch 104 / 200 | iteration 130 / 171 | Total Loss: 3.6728997230529785 | KNN Loss: 3.6493566036224365 | CLS Loss: 0.02354307286441326\n",
      "Epoch 104 / 200 | iteration 140 / 171 | Total Loss: 3.6130285263061523 | KNN Loss: 3.6006081104278564 | CLS Loss: 0.012420322746038437\n",
      "Epoch 104 / 200 | iteration 150 / 171 | Total Loss: 3.630279541015625 | KNN Loss: 3.6091606616973877 | CLS Loss: 0.021118776872754097\n",
      "Epoch 104 / 200 | iteration 160 / 171 | Total Loss: 3.648860454559326 | KNN Loss: 3.6138529777526855 | CLS Loss: 0.03500746190547943\n",
      "Epoch 104 / 200 | iteration 170 / 171 | Total Loss: 3.599579095840454 | KNN Loss: 3.5918807983398438 | CLS Loss: 0.0076983035542070866\n",
      "Epoch: 104, Loss: 3.6230, Train: 0.9958, Valid: 0.9858, Best: 0.9881\n",
      "Epoch 105 / 200 | iteration 0 / 171 | Total Loss: 3.6027681827545166 | KNN Loss: 3.600269317626953 | CLS Loss: 0.002498897025361657\n",
      "Epoch 105 / 200 | iteration 10 / 171 | Total Loss: 3.6201610565185547 | KNN Loss: 3.6186375617980957 | CLS Loss: 0.0015235505998134613\n",
      "Epoch 105 / 200 | iteration 20 / 171 | Total Loss: 3.6109297275543213 | KNN Loss: 3.601431369781494 | CLS Loss: 0.009498247876763344\n",
      "Epoch 105 / 200 | iteration 30 / 171 | Total Loss: 3.5879950523376465 | KNN Loss: 3.5845656394958496 | CLS Loss: 0.0034295222721993923\n",
      "Epoch 105 / 200 | iteration 40 / 171 | Total Loss: 3.633591890335083 | KNN Loss: 3.6209657192230225 | CLS Loss: 0.01262610498815775\n",
      "Epoch 105 / 200 | iteration 50 / 171 | Total Loss: 3.5999770164489746 | KNN Loss: 3.595799684524536 | CLS Loss: 0.004177391994744539\n",
      "Epoch 105 / 200 | iteration 60 / 171 | Total Loss: 3.6328365802764893 | KNN Loss: 3.597186803817749 | CLS Loss: 0.0356498546898365\n",
      "Epoch 105 / 200 | iteration 70 / 171 | Total Loss: 3.5916833877563477 | KNN Loss: 3.584970712661743 | CLS Loss: 0.006712585221976042\n",
      "Epoch 105 / 200 | iteration 80 / 171 | Total Loss: 3.638685941696167 | KNN Loss: 3.6248250007629395 | CLS Loss: 0.013860962353646755\n",
      "Epoch 105 / 200 | iteration 90 / 171 | Total Loss: 3.608388662338257 | KNN Loss: 3.577873468399048 | CLS Loss: 0.030515311285853386\n",
      "Epoch 105 / 200 | iteration 100 / 171 | Total Loss: 3.6595048904418945 | KNN Loss: 3.6580803394317627 | CLS Loss: 0.001424630987457931\n",
      "Epoch 105 / 200 | iteration 110 / 171 | Total Loss: 3.6328318119049072 | KNN Loss: 3.630934476852417 | CLS Loss: 0.0018973019905388355\n",
      "Epoch 105 / 200 | iteration 120 / 171 | Total Loss: 3.6266098022460938 | KNN Loss: 3.6154820919036865 | CLS Loss: 0.011127729900181293\n",
      "Epoch 105 / 200 | iteration 130 / 171 | Total Loss: 3.5992484092712402 | KNN Loss: 3.5930521488189697 | CLS Loss: 0.006196248810738325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 / 200 | iteration 140 / 171 | Total Loss: 3.621258497238159 | KNN Loss: 3.595087766647339 | CLS Loss: 0.0261706430464983\n",
      "Epoch 105 / 200 | iteration 150 / 171 | Total Loss: 3.57934308052063 | KNN Loss: 3.578195810317993 | CLS Loss: 0.0011473491322249174\n",
      "Epoch 105 / 200 | iteration 160 / 171 | Total Loss: 3.6048479080200195 | KNN Loss: 3.5728423595428467 | CLS Loss: 0.03200559318065643\n",
      "Epoch 105 / 200 | iteration 170 / 171 | Total Loss: 3.5945873260498047 | KNN Loss: 3.5807077884674072 | CLS Loss: 0.01387965027242899\n",
      "Epoch: 105, Loss: 3.6159, Train: 0.9963, Valid: 0.9868, Best: 0.9881\n",
      "Epoch 106 / 200 | iteration 0 / 171 | Total Loss: 3.6360819339752197 | KNN Loss: 3.6221022605895996 | CLS Loss: 0.013979783281683922\n",
      "Epoch 106 / 200 | iteration 10 / 171 | Total Loss: 3.5761168003082275 | KNN Loss: 3.5731942653656006 | CLS Loss: 0.0029225219041109085\n",
      "Epoch 106 / 200 | iteration 20 / 171 | Total Loss: 3.6563286781311035 | KNN Loss: 3.642249345779419 | CLS Loss: 0.014079291373491287\n",
      "Epoch 106 / 200 | iteration 30 / 171 | Total Loss: 3.604771852493286 | KNN Loss: 3.594538927078247 | CLS Loss: 0.010232971981167793\n",
      "Epoch 106 / 200 | iteration 40 / 171 | Total Loss: 3.6393487453460693 | KNN Loss: 3.6340324878692627 | CLS Loss: 0.0053162286058068275\n",
      "Epoch 106 / 200 | iteration 50 / 171 | Total Loss: 3.6229820251464844 | KNN Loss: 3.61185359954834 | CLS Loss: 0.011128534562885761\n",
      "Epoch 106 / 200 | iteration 60 / 171 | Total Loss: 3.6059887409210205 | KNN Loss: 3.5986456871032715 | CLS Loss: 0.0073430356569588184\n",
      "Epoch 106 / 200 | iteration 70 / 171 | Total Loss: 3.650949239730835 | KNN Loss: 3.628655433654785 | CLS Loss: 0.022293701767921448\n",
      "Epoch 106 / 200 | iteration 80 / 171 | Total Loss: 3.5754966735839844 | KNN Loss: 3.5694892406463623 | CLS Loss: 0.0060073575004935265\n",
      "Epoch 106 / 200 | iteration 90 / 171 | Total Loss: 3.6193015575408936 | KNN Loss: 3.61417555809021 | CLS Loss: 0.005125952418893576\n",
      "Epoch 106 / 200 | iteration 100 / 171 | Total Loss: 3.588963508605957 | KNN Loss: 3.576242208480835 | CLS Loss: 0.012721401639282703\n",
      "Epoch 106 / 200 | iteration 110 / 171 | Total Loss: 3.6488606929779053 | KNN Loss: 3.64273738861084 | CLS Loss: 0.006123346742242575\n",
      "Epoch 106 / 200 | iteration 120 / 171 | Total Loss: 3.635416030883789 | KNN Loss: 3.6216940879821777 | CLS Loss: 0.013721914030611515\n",
      "Epoch 106 / 200 | iteration 130 / 171 | Total Loss: 3.629145622253418 | KNN Loss: 3.608959674835205 | CLS Loss: 0.02018602192401886\n",
      "Epoch 106 / 200 | iteration 140 / 171 | Total Loss: 3.594872236251831 | KNN Loss: 3.5704236030578613 | CLS Loss: 0.024448581039905548\n",
      "Epoch 106 / 200 | iteration 150 / 171 | Total Loss: 3.6441376209259033 | KNN Loss: 3.633586883544922 | CLS Loss: 0.010550704784691334\n",
      "Epoch 106 / 200 | iteration 160 / 171 | Total Loss: 3.597306966781616 | KNN Loss: 3.5873003005981445 | CLS Loss: 0.010006638243794441\n",
      "Epoch 106 / 200 | iteration 170 / 171 | Total Loss: 3.583902359008789 | KNN Loss: 3.581918954849243 | CLS Loss: 0.0019833731930702925\n",
      "Epoch: 106, Loss: 3.6204, Train: 0.9965, Valid: 0.9859, Best: 0.9881\n",
      "Epoch 107 / 200 | iteration 0 / 171 | Total Loss: 3.5886168479919434 | KNN Loss: 3.584477424621582 | CLS Loss: 0.004139526281505823\n",
      "Epoch 107 / 200 | iteration 10 / 171 | Total Loss: 3.5907697677612305 | KNN Loss: 3.5789990425109863 | CLS Loss: 0.011770716868340969\n",
      "Epoch 107 / 200 | iteration 20 / 171 | Total Loss: 3.586824893951416 | KNN Loss: 3.5780510902404785 | CLS Loss: 0.008773826994001865\n",
      "Epoch 107 / 200 | iteration 30 / 171 | Total Loss: 3.6119844913482666 | KNN Loss: 3.599756956100464 | CLS Loss: 0.012227443978190422\n",
      "Epoch 107 / 200 | iteration 40 / 171 | Total Loss: 3.634315013885498 | KNN Loss: 3.6192328929901123 | CLS Loss: 0.015082213096320629\n",
      "Epoch 107 / 200 | iteration 50 / 171 | Total Loss: 3.679464817047119 | KNN Loss: 3.66530179977417 | CLS Loss: 0.014162901788949966\n",
      "Epoch 107 / 200 | iteration 60 / 171 | Total Loss: 3.599337577819824 | KNN Loss: 3.5947139263153076 | CLS Loss: 0.004623549059033394\n",
      "Epoch 107 / 200 | iteration 70 / 171 | Total Loss: 3.601464033126831 | KNN Loss: 3.589693069458008 | CLS Loss: 0.011770974844694138\n",
      "Epoch 107 / 200 | iteration 80 / 171 | Total Loss: 3.6545820236206055 | KNN Loss: 3.651672601699829 | CLS Loss: 0.0029093839693814516\n",
      "Epoch 107 / 200 | iteration 90 / 171 | Total Loss: 3.6613285541534424 | KNN Loss: 3.648698091506958 | CLS Loss: 0.012630575336515903\n",
      "Epoch 107 / 200 | iteration 100 / 171 | Total Loss: 3.606844425201416 | KNN Loss: 3.597944498062134 | CLS Loss: 0.008900035172700882\n",
      "Epoch 107 / 200 | iteration 110 / 171 | Total Loss: 3.6279890537261963 | KNN Loss: 3.5942952632904053 | CLS Loss: 0.03369377553462982\n",
      "Epoch 107 / 200 | iteration 120 / 171 | Total Loss: 3.6097986698150635 | KNN Loss: 3.6023366451263428 | CLS Loss: 0.007462045177817345\n",
      "Epoch 107 / 200 | iteration 130 / 171 | Total Loss: 3.6118862628936768 | KNN Loss: 3.6018197536468506 | CLS Loss: 0.010066533461213112\n",
      "Epoch 107 / 200 | iteration 140 / 171 | Total Loss: 3.6061086654663086 | KNN Loss: 3.597853899002075 | CLS Loss: 0.00825467612594366\n",
      "Epoch 107 / 200 | iteration 150 / 171 | Total Loss: 3.6697046756744385 | KNN Loss: 3.6557681560516357 | CLS Loss: 0.013936544768512249\n",
      "Epoch 107 / 200 | iteration 160 / 171 | Total Loss: 3.6036760807037354 | KNN Loss: 3.593830108642578 | CLS Loss: 0.009846067056059837\n",
      "Epoch 107 / 200 | iteration 170 / 171 | Total Loss: 3.590543746948242 | KNN Loss: 3.5876119136810303 | CLS Loss: 0.0029318388551473618\n",
      "Epoch: 107, Loss: 3.6221, Train: 0.9967, Valid: 0.9866, Best: 0.9881\n",
      "Epoch 108 / 200 | iteration 0 / 171 | Total Loss: 3.603184223175049 | KNN Loss: 3.5906450748443604 | CLS Loss: 0.01253922376781702\n",
      "Epoch 108 / 200 | iteration 10 / 171 | Total Loss: 3.6283061504364014 | KNN Loss: 3.615521192550659 | CLS Loss: 0.012784933671355247\n",
      "Epoch 108 / 200 | iteration 20 / 171 | Total Loss: 3.6004364490509033 | KNN Loss: 3.592616081237793 | CLS Loss: 0.007820283994078636\n",
      "Epoch 108 / 200 | iteration 30 / 171 | Total Loss: 3.713879108428955 | KNN Loss: 3.7030270099639893 | CLS Loss: 0.010852116160094738\n",
      "Epoch 108 / 200 | iteration 40 / 171 | Total Loss: 3.600116491317749 | KNN Loss: 3.596029281616211 | CLS Loss: 0.00408723670989275\n",
      "Epoch 108 / 200 | iteration 50 / 171 | Total Loss: 3.610858201980591 | KNN Loss: 3.6019177436828613 | CLS Loss: 0.008940397761762142\n",
      "Epoch 108 / 200 | iteration 60 / 171 | Total Loss: 3.6278767585754395 | KNN Loss: 3.619523763656616 | CLS Loss: 0.008352939039468765\n",
      "Epoch 108 / 200 | iteration 70 / 171 | Total Loss: 3.613236427307129 | KNN Loss: 3.604463577270508 | CLS Loss: 0.008772899396717548\n",
      "Epoch 108 / 200 | iteration 80 / 171 | Total Loss: 3.6640939712524414 | KNN Loss: 3.651487350463867 | CLS Loss: 0.012606575153768063\n",
      "Epoch 108 / 200 | iteration 90 / 171 | Total Loss: 3.609147071838379 | KNN Loss: 3.589125871658325 | CLS Loss: 0.020021099597215652\n",
      "Epoch 108 / 200 | iteration 100 / 171 | Total Loss: 3.6002492904663086 | KNN Loss: 3.5774080753326416 | CLS Loss: 0.022841254249215126\n",
      "Epoch 108 / 200 | iteration 110 / 171 | Total Loss: 3.6265292167663574 | KNN Loss: 3.6233019828796387 | CLS Loss: 0.0032272054813802242\n",
      "Epoch 108 / 200 | iteration 120 / 171 | Total Loss: 3.6346435546875 | KNN Loss: 3.628978729248047 | CLS Loss: 0.005664784926921129\n",
      "Epoch 108 / 200 | iteration 130 / 171 | Total Loss: 3.5876479148864746 | KNN Loss: 3.5720345973968506 | CLS Loss: 0.015613286755979061\n",
      "Epoch 108 / 200 | iteration 140 / 171 | Total Loss: 3.621448278427124 | KNN Loss: 3.6076321601867676 | CLS Loss: 0.013816113583743572\n",
      "Epoch 108 / 200 | iteration 150 / 171 | Total Loss: 3.6525769233703613 | KNN Loss: 3.6501240730285645 | CLS Loss: 0.002452931832522154\n",
      "Epoch 108 / 200 | iteration 160 / 171 | Total Loss: 3.6228480339050293 | KNN Loss: 3.61238169670105 | CLS Loss: 0.010466438718140125\n",
      "Epoch 108 / 200 | iteration 170 / 171 | Total Loss: 3.61588191986084 | KNN Loss: 3.597766399383545 | CLS Loss: 0.018115440383553505\n",
      "Epoch: 108, Loss: 3.6199, Train: 0.9970, Valid: 0.9864, Best: 0.9881\n",
      "Epoch 109 / 200 | iteration 0 / 171 | Total Loss: 3.587583065032959 | KNN Loss: 3.5737905502319336 | CLS Loss: 0.013792506419122219\n",
      "Epoch 109 / 200 | iteration 10 / 171 | Total Loss: 3.6301958560943604 | KNN Loss: 3.6026248931884766 | CLS Loss: 0.027570858597755432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 / 200 | iteration 20 / 171 | Total Loss: 3.6155145168304443 | KNN Loss: 3.591719627380371 | CLS Loss: 0.02379487454891205\n",
      "Epoch 109 / 200 | iteration 30 / 171 | Total Loss: 3.654296875 | KNN Loss: 3.631864309310913 | CLS Loss: 0.022432496771216393\n",
      "Epoch 109 / 200 | iteration 40 / 171 | Total Loss: 3.644212007522583 | KNN Loss: 3.6005733013153076 | CLS Loss: 0.04363860934972763\n",
      "Epoch 109 / 200 | iteration 50 / 171 | Total Loss: 3.605515956878662 | KNN Loss: 3.590158462524414 | CLS Loss: 0.015357498079538345\n",
      "Epoch 109 / 200 | iteration 60 / 171 | Total Loss: 3.6847920417785645 | KNN Loss: 3.6636672019958496 | CLS Loss: 0.021124867722392082\n",
      "Epoch 109 / 200 | iteration 70 / 171 | Total Loss: 3.7126827239990234 | KNN Loss: 3.6932153701782227 | CLS Loss: 0.01946740597486496\n",
      "Epoch 109 / 200 | iteration 80 / 171 | Total Loss: 3.6285064220428467 | KNN Loss: 3.6124963760375977 | CLS Loss: 0.016010086983442307\n",
      "Epoch 109 / 200 | iteration 90 / 171 | Total Loss: 3.601691484451294 | KNN Loss: 3.5935299396514893 | CLS Loss: 0.008161497302353382\n",
      "Epoch 109 / 200 | iteration 100 / 171 | Total Loss: 3.5950896739959717 | KNN Loss: 3.586268901824951 | CLS Loss: 0.008820679038763046\n",
      "Epoch 109 / 200 | iteration 110 / 171 | Total Loss: 3.6367123126983643 | KNN Loss: 3.631237506866455 | CLS Loss: 0.005474796053022146\n",
      "Epoch 109 / 200 | iteration 120 / 171 | Total Loss: 3.625351667404175 | KNN Loss: 3.6091737747192383 | CLS Loss: 0.01617792807519436\n",
      "Epoch 109 / 200 | iteration 130 / 171 | Total Loss: 3.6106295585632324 | KNN Loss: 3.5994887351989746 | CLS Loss: 0.011140934191644192\n",
      "Epoch 109 / 200 | iteration 140 / 171 | Total Loss: 3.5974233150482178 | KNN Loss: 3.578618288040161 | CLS Loss: 0.01880509965121746\n",
      "Epoch 109 / 200 | iteration 150 / 171 | Total Loss: 3.6096928119659424 | KNN Loss: 3.602423906326294 | CLS Loss: 0.007268952205777168\n",
      "Epoch 109 / 200 | iteration 160 / 171 | Total Loss: 3.6067795753479004 | KNN Loss: 3.596855878829956 | CLS Loss: 0.009923619218170643\n",
      "Epoch 109 / 200 | iteration 170 / 171 | Total Loss: 3.650259017944336 | KNN Loss: 3.6085333824157715 | CLS Loss: 0.04172561317682266\n",
      "Epoch: 109, Loss: 3.6154, Train: 0.9971, Valid: 0.9863, Best: 0.9881\n",
      "Epoch 110 / 200 | iteration 0 / 171 | Total Loss: 3.6207351684570312 | KNN Loss: 3.6156420707702637 | CLS Loss: 0.005093216896057129\n",
      "Epoch 110 / 200 | iteration 10 / 171 | Total Loss: 3.5864241123199463 | KNN Loss: 3.5822575092315674 | CLS Loss: 0.004166521597653627\n",
      "Epoch 110 / 200 | iteration 20 / 171 | Total Loss: 3.6068546772003174 | KNN Loss: 3.57473087310791 | CLS Loss: 0.032123710960149765\n",
      "Epoch 110 / 200 | iteration 30 / 171 | Total Loss: 3.5984790325164795 | KNN Loss: 3.596520185470581 | CLS Loss: 0.001958860084414482\n",
      "Epoch 110 / 200 | iteration 40 / 171 | Total Loss: 3.6102471351623535 | KNN Loss: 3.5899837017059326 | CLS Loss: 0.02026338502764702\n",
      "Epoch 110 / 200 | iteration 50 / 171 | Total Loss: 3.5957534313201904 | KNN Loss: 3.5889813899993896 | CLS Loss: 0.006771988235414028\n",
      "Epoch 110 / 200 | iteration 60 / 171 | Total Loss: 3.6267409324645996 | KNN Loss: 3.601285934448242 | CLS Loss: 0.025454938411712646\n",
      "Epoch 110 / 200 | iteration 70 / 171 | Total Loss: 3.615474224090576 | KNN Loss: 3.604717493057251 | CLS Loss: 0.010756789706647396\n",
      "Epoch 110 / 200 | iteration 80 / 171 | Total Loss: 3.644460916519165 | KNN Loss: 3.626671552658081 | CLS Loss: 0.01778934709727764\n",
      "Epoch 110 / 200 | iteration 90 / 171 | Total Loss: 3.6089141368865967 | KNN Loss: 3.59879207611084 | CLS Loss: 0.010122036561369896\n",
      "Epoch 110 / 200 | iteration 100 / 171 | Total Loss: 3.633715867996216 | KNN Loss: 3.630002498626709 | CLS Loss: 0.0037133004516363144\n",
      "Epoch 110 / 200 | iteration 110 / 171 | Total Loss: 3.6191587448120117 | KNN Loss: 3.617607831954956 | CLS Loss: 0.0015508197247982025\n",
      "Epoch 110 / 200 | iteration 120 / 171 | Total Loss: 3.588615655899048 | KNN Loss: 3.5798850059509277 | CLS Loss: 0.008730732835829258\n",
      "Epoch 110 / 200 | iteration 130 / 171 | Total Loss: 3.5957448482513428 | KNN Loss: 3.5924808979034424 | CLS Loss: 0.0032638765405863523\n",
      "Epoch 110 / 200 | iteration 140 / 171 | Total Loss: 3.6038239002227783 | KNN Loss: 3.585561513900757 | CLS Loss: 0.018262343481183052\n",
      "Epoch 110 / 200 | iteration 150 / 171 | Total Loss: 3.6219077110290527 | KNN Loss: 3.6133217811584473 | CLS Loss: 0.008585868403315544\n",
      "Epoch 110 / 200 | iteration 160 / 171 | Total Loss: 3.601431131362915 | KNN Loss: 3.576056718826294 | CLS Loss: 0.025374332442879677\n",
      "Epoch 110 / 200 | iteration 170 / 171 | Total Loss: 3.652305841445923 | KNN Loss: 3.63672137260437 | CLS Loss: 0.015584578737616539\n",
      "Epoch: 110, Loss: 3.6153, Train: 0.9958, Valid: 0.9869, Best: 0.9881\n",
      "Epoch 111 / 200 | iteration 0 / 171 | Total Loss: 3.5839993953704834 | KNN Loss: 3.57458758354187 | CLS Loss: 0.009411817416548729\n",
      "Epoch 111 / 200 | iteration 10 / 171 | Total Loss: 3.6096723079681396 | KNN Loss: 3.5998518466949463 | CLS Loss: 0.009820492938160896\n",
      "Epoch 111 / 200 | iteration 20 / 171 | Total Loss: 3.658935070037842 | KNN Loss: 3.651353120803833 | CLS Loss: 0.00758204935118556\n",
      "Epoch 111 / 200 | iteration 30 / 171 | Total Loss: 3.6317598819732666 | KNN Loss: 3.616774082183838 | CLS Loss: 0.014985845424234867\n",
      "Epoch 111 / 200 | iteration 40 / 171 | Total Loss: 3.6037864685058594 | KNN Loss: 3.6011078357696533 | CLS Loss: 0.0026787477545440197\n",
      "Epoch 111 / 200 | iteration 50 / 171 | Total Loss: 3.611886978149414 | KNN Loss: 3.60351824760437 | CLS Loss: 0.008368832059204578\n",
      "Epoch 111 / 200 | iteration 60 / 171 | Total Loss: 3.6310031414031982 | KNN Loss: 3.6248486042022705 | CLS Loss: 0.0061546191573143005\n",
      "Epoch 111 / 200 | iteration 70 / 171 | Total Loss: 3.609952211380005 | KNN Loss: 3.598656415939331 | CLS Loss: 0.011295744217932224\n",
      "Epoch 111 / 200 | iteration 80 / 171 | Total Loss: 3.571528434753418 | KNN Loss: 3.5598549842834473 | CLS Loss: 0.011673401109874249\n",
      "Epoch 111 / 200 | iteration 90 / 171 | Total Loss: 3.593254327774048 | KNN Loss: 3.5909957885742188 | CLS Loss: 0.002258503809571266\n",
      "Epoch 111 / 200 | iteration 100 / 171 | Total Loss: 3.5994200706481934 | KNN Loss: 3.5794196128845215 | CLS Loss: 0.020000489428639412\n",
      "Epoch 111 / 200 | iteration 110 / 171 | Total Loss: 3.5901622772216797 | KNN Loss: 3.5738656520843506 | CLS Loss: 0.016296610236167908\n",
      "Epoch 111 / 200 | iteration 120 / 171 | Total Loss: 3.603748321533203 | KNN Loss: 3.592419147491455 | CLS Loss: 0.01132923923432827\n",
      "Epoch 111 / 200 | iteration 130 / 171 | Total Loss: 3.6610610485076904 | KNN Loss: 3.6532046794891357 | CLS Loss: 0.007856342010200024\n",
      "Epoch 111 / 200 | iteration 140 / 171 | Total Loss: 3.6265132427215576 | KNN Loss: 3.614532232284546 | CLS Loss: 0.011980901472270489\n",
      "Epoch 111 / 200 | iteration 150 / 171 | Total Loss: 3.6580049991607666 | KNN Loss: 3.6385841369628906 | CLS Loss: 0.019420916214585304\n",
      "Epoch 111 / 200 | iteration 160 / 171 | Total Loss: 3.5946404933929443 | KNN Loss: 3.5553009510040283 | CLS Loss: 0.03933955356478691\n",
      "Epoch 111 / 200 | iteration 170 / 171 | Total Loss: 3.6273696422576904 | KNN Loss: 3.6156861782073975 | CLS Loss: 0.011683552525937557\n",
      "Epoch: 111, Loss: 3.6176, Train: 0.9964, Valid: 0.9876, Best: 0.9881\n",
      "Epoch 112 / 200 | iteration 0 / 171 | Total Loss: 3.6262714862823486 | KNN Loss: 3.6115827560424805 | CLS Loss: 0.014688676223158836\n",
      "Epoch 112 / 200 | iteration 10 / 171 | Total Loss: 3.6206812858581543 | KNN Loss: 3.6189658641815186 | CLS Loss: 0.0017153300577774644\n",
      "Epoch 112 / 200 | iteration 20 / 171 | Total Loss: 3.5924551486968994 | KNN Loss: 3.582300901412964 | CLS Loss: 0.01015416905283928\n",
      "Epoch 112 / 200 | iteration 30 / 171 | Total Loss: 3.699532985687256 | KNN Loss: 3.672795057296753 | CLS Loss: 0.02673804573714733\n",
      "Epoch 112 / 200 | iteration 40 / 171 | Total Loss: 3.607464551925659 | KNN Loss: 3.5970892906188965 | CLS Loss: 0.010375145822763443\n",
      "Epoch 112 / 200 | iteration 50 / 171 | Total Loss: 3.6219584941864014 | KNN Loss: 3.617840051651001 | CLS Loss: 0.004118360113352537\n",
      "Epoch 112 / 200 | iteration 60 / 171 | Total Loss: 3.6215462684631348 | KNN Loss: 3.613527774810791 | CLS Loss: 0.008018394000828266\n",
      "Epoch 112 / 200 | iteration 70 / 171 | Total Loss: 3.59466814994812 | KNN Loss: 3.5868794918060303 | CLS Loss: 0.007788776885718107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 / 200 | iteration 80 / 171 | Total Loss: 3.6035053730010986 | KNN Loss: 3.5965304374694824 | CLS Loss: 0.006974935065954924\n",
      "Epoch 112 / 200 | iteration 90 / 171 | Total Loss: 3.6135776042938232 | KNN Loss: 3.587245225906372 | CLS Loss: 0.02633245661854744\n",
      "Epoch 112 / 200 | iteration 100 / 171 | Total Loss: 3.6555404663085938 | KNN Loss: 3.630105972290039 | CLS Loss: 0.02543458715081215\n",
      "Epoch 112 / 200 | iteration 110 / 171 | Total Loss: 3.645601272583008 | KNN Loss: 3.632251262664795 | CLS Loss: 0.013349977321922779\n",
      "Epoch 112 / 200 | iteration 120 / 171 | Total Loss: 3.5855722427368164 | KNN Loss: 3.571620464324951 | CLS Loss: 0.013951738364994526\n",
      "Epoch 112 / 200 | iteration 130 / 171 | Total Loss: 3.6021888256073 | KNN Loss: 3.5948171615600586 | CLS Loss: 0.0073716104961931705\n",
      "Epoch 112 / 200 | iteration 140 / 171 | Total Loss: 3.590501546859741 | KNN Loss: 3.584798812866211 | CLS Loss: 0.005702849477529526\n",
      "Epoch 112 / 200 | iteration 150 / 171 | Total Loss: 3.608586072921753 | KNN Loss: 3.5969412326812744 | CLS Loss: 0.011644777841866016\n",
      "Epoch 112 / 200 | iteration 160 / 171 | Total Loss: 3.6494550704956055 | KNN Loss: 3.634660243988037 | CLS Loss: 0.014794713817536831\n",
      "Epoch 112 / 200 | iteration 170 / 171 | Total Loss: 3.6369659900665283 | KNN Loss: 3.6087985038757324 | CLS Loss: 0.028167424723505974\n",
      "Epoch: 112, Loss: 3.6200, Train: 0.9950, Valid: 0.9852, Best: 0.9881\n",
      "Epoch 113 / 200 | iteration 0 / 171 | Total Loss: 3.663106918334961 | KNN Loss: 3.641446590423584 | CLS Loss: 0.021660422906279564\n",
      "Epoch 113 / 200 | iteration 10 / 171 | Total Loss: 3.5860724449157715 | KNN Loss: 3.5775604248046875 | CLS Loss: 0.008511904627084732\n",
      "Epoch 113 / 200 | iteration 20 / 171 | Total Loss: 3.614745616912842 | KNN Loss: 3.6057941913604736 | CLS Loss: 0.008951505646109581\n",
      "Epoch 113 / 200 | iteration 30 / 171 | Total Loss: 3.6124579906463623 | KNN Loss: 3.587859630584717 | CLS Loss: 0.024598365649580956\n",
      "Epoch 113 / 200 | iteration 40 / 171 | Total Loss: 3.634984016418457 | KNN Loss: 3.626007556915283 | CLS Loss: 0.008976353332400322\n",
      "Epoch 113 / 200 | iteration 50 / 171 | Total Loss: 3.680635690689087 | KNN Loss: 3.6760058403015137 | CLS Loss: 0.004629860166460276\n",
      "Epoch 113 / 200 | iteration 60 / 171 | Total Loss: 3.6041791439056396 | KNN Loss: 3.595505952835083 | CLS Loss: 0.008673099800944328\n",
      "Epoch 113 / 200 | iteration 70 / 171 | Total Loss: 3.589571714401245 | KNN Loss: 3.58209228515625 | CLS Loss: 0.007479488383978605\n",
      "Epoch 113 / 200 | iteration 80 / 171 | Total Loss: 3.6262524127960205 | KNN Loss: 3.6247308254241943 | CLS Loss: 0.001521637779660523\n",
      "Epoch 113 / 200 | iteration 90 / 171 | Total Loss: 3.614812135696411 | KNN Loss: 3.611152172088623 | CLS Loss: 0.0036598583683371544\n",
      "Epoch 113 / 200 | iteration 100 / 171 | Total Loss: 3.608494520187378 | KNN Loss: 3.602753162384033 | CLS Loss: 0.005741368513554335\n",
      "Epoch 113 / 200 | iteration 110 / 171 | Total Loss: 3.679659843444824 | KNN Loss: 3.6412267684936523 | CLS Loss: 0.03843319043517113\n",
      "Epoch 113 / 200 | iteration 120 / 171 | Total Loss: 3.614070415496826 | KNN Loss: 3.611402750015259 | CLS Loss: 0.002667565830051899\n",
      "Epoch 113 / 200 | iteration 130 / 171 | Total Loss: 3.62092661857605 | KNN Loss: 3.6155831813812256 | CLS Loss: 0.0053433445282280445\n",
      "Epoch 113 / 200 | iteration 140 / 171 | Total Loss: 3.595858097076416 | KNN Loss: 3.5803024768829346 | CLS Loss: 0.015555701218545437\n",
      "Epoch 113 / 200 | iteration 150 / 171 | Total Loss: 3.6151843070983887 | KNN Loss: 3.6085193157196045 | CLS Loss: 0.006664912216365337\n",
      "Epoch 113 / 200 | iteration 160 / 171 | Total Loss: 3.6304080486297607 | KNN Loss: 3.613929271697998 | CLS Loss: 0.01647874154150486\n",
      "Epoch 113 / 200 | iteration 170 / 171 | Total Loss: 3.5797030925750732 | KNN Loss: 3.5701897144317627 | CLS Loss: 0.009513381868600845\n",
      "Epoch: 113, Loss: 3.6204, Train: 0.9967, Valid: 0.9864, Best: 0.9881\n",
      "Epoch 114 / 200 | iteration 0 / 171 | Total Loss: 3.615398406982422 | KNN Loss: 3.600384473800659 | CLS Loss: 0.015014037489891052\n",
      "Epoch 114 / 200 | iteration 10 / 171 | Total Loss: 3.6077985763549805 | KNN Loss: 3.591646909713745 | CLS Loss: 0.016151703894138336\n",
      "Epoch 114 / 200 | iteration 20 / 171 | Total Loss: 3.5821030139923096 | KNN Loss: 3.5640671253204346 | CLS Loss: 0.01803586259484291\n",
      "Epoch 114 / 200 | iteration 30 / 171 | Total Loss: 3.5897653102874756 | KNN Loss: 3.5663681030273438 | CLS Loss: 0.023397207260131836\n",
      "Epoch 114 / 200 | iteration 40 / 171 | Total Loss: 3.628070592880249 | KNN Loss: 3.593630313873291 | CLS Loss: 0.034440360963344574\n",
      "Epoch 114 / 200 | iteration 50 / 171 | Total Loss: 3.5967001914978027 | KNN Loss: 3.582514762878418 | CLS Loss: 0.014185392297804356\n",
      "Epoch 114 / 200 | iteration 60 / 171 | Total Loss: 3.638897657394409 | KNN Loss: 3.6240575313568115 | CLS Loss: 0.014840067364275455\n",
      "Epoch 114 / 200 | iteration 70 / 171 | Total Loss: 3.6296348571777344 | KNN Loss: 3.6109979152679443 | CLS Loss: 0.018637042492628098\n",
      "Epoch 114 / 200 | iteration 80 / 171 | Total Loss: 3.6301543712615967 | KNN Loss: 3.614633798599243 | CLS Loss: 0.015520520508289337\n",
      "Epoch 114 / 200 | iteration 90 / 171 | Total Loss: 3.5815649032592773 | KNN Loss: 3.5781683921813965 | CLS Loss: 0.0033965595066547394\n",
      "Epoch 114 / 200 | iteration 100 / 171 | Total Loss: 3.6489336490631104 | KNN Loss: 3.6314821243286133 | CLS Loss: 0.017451610416173935\n",
      "Epoch 114 / 200 | iteration 110 / 171 | Total Loss: 3.639188289642334 | KNN Loss: 3.616619110107422 | CLS Loss: 0.022569263353943825\n",
      "Epoch 114 / 200 | iteration 120 / 171 | Total Loss: 3.641927719116211 | KNN Loss: 3.628337860107422 | CLS Loss: 0.013589846901595592\n",
      "Epoch 114 / 200 | iteration 130 / 171 | Total Loss: 3.6362061500549316 | KNN Loss: 3.6281728744506836 | CLS Loss: 0.008033387362957\n",
      "Epoch 114 / 200 | iteration 140 / 171 | Total Loss: 3.5936760902404785 | KNN Loss: 3.588095188140869 | CLS Loss: 0.005580894649028778\n",
      "Epoch 114 / 200 | iteration 150 / 171 | Total Loss: 3.6077771186828613 | KNN Loss: 3.584291934967041 | CLS Loss: 0.02348526567220688\n",
      "Epoch 114 / 200 | iteration 160 / 171 | Total Loss: 3.632981300354004 | KNN Loss: 3.6041414737701416 | CLS Loss: 0.0288397166877985\n",
      "Epoch 114 / 200 | iteration 170 / 171 | Total Loss: 3.5908191204071045 | KNN Loss: 3.5806055068969727 | CLS Loss: 0.010213719680905342\n",
      "Epoch: 114, Loss: 3.6167, Train: 0.9958, Valid: 0.9861, Best: 0.9881\n",
      "Epoch 115 / 200 | iteration 0 / 171 | Total Loss: 3.633423328399658 | KNN Loss: 3.6137149333953857 | CLS Loss: 0.019708458334207535\n",
      "Epoch 115 / 200 | iteration 10 / 171 | Total Loss: 3.611052989959717 | KNN Loss: 3.600152015686035 | CLS Loss: 0.010901080444455147\n",
      "Epoch 115 / 200 | iteration 20 / 171 | Total Loss: 3.61808180809021 | KNN Loss: 3.6105005741119385 | CLS Loss: 0.0075812432914972305\n",
      "Epoch 115 / 200 | iteration 30 / 171 | Total Loss: 3.6277315616607666 | KNN Loss: 3.6192381381988525 | CLS Loss: 0.008493517525494099\n",
      "Epoch 115 / 200 | iteration 40 / 171 | Total Loss: 3.683933973312378 | KNN Loss: 3.6633219718933105 | CLS Loss: 0.020612040534615517\n",
      "Epoch 115 / 200 | iteration 50 / 171 | Total Loss: 3.6635992527008057 | KNN Loss: 3.6418209075927734 | CLS Loss: 0.021778441965579987\n",
      "Epoch 115 / 200 | iteration 60 / 171 | Total Loss: 3.6145753860473633 | KNN Loss: 3.6014623641967773 | CLS Loss: 0.013112984597682953\n",
      "Epoch 115 / 200 | iteration 70 / 171 | Total Loss: 3.6110920906066895 | KNN Loss: 3.6006295680999756 | CLS Loss: 0.010462595149874687\n",
      "Epoch 115 / 200 | iteration 80 / 171 | Total Loss: 3.6394450664520264 | KNN Loss: 3.6280007362365723 | CLS Loss: 0.011444272473454475\n",
      "Epoch 115 / 200 | iteration 90 / 171 | Total Loss: 3.598928928375244 | KNN Loss: 3.582474708557129 | CLS Loss: 0.016454152762889862\n",
      "Epoch 115 / 200 | iteration 100 / 171 | Total Loss: 3.6573190689086914 | KNN Loss: 3.635648012161255 | CLS Loss: 0.021671149879693985\n",
      "Epoch 115 / 200 | iteration 110 / 171 | Total Loss: 3.709416627883911 | KNN Loss: 3.687586784362793 | CLS Loss: 0.021829748526215553\n",
      "Epoch 115 / 200 | iteration 120 / 171 | Total Loss: 3.6233108043670654 | KNN Loss: 3.614784002304077 | CLS Loss: 0.008526780642569065\n",
      "Epoch 115 / 200 | iteration 130 / 171 | Total Loss: 3.6830050945281982 | KNN Loss: 3.673750400543213 | CLS Loss: 0.009254708886146545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 / 200 | iteration 140 / 171 | Total Loss: 3.6236655712127686 | KNN Loss: 3.6154463291168213 | CLS Loss: 0.008219242095947266\n",
      "Epoch 115 / 200 | iteration 150 / 171 | Total Loss: 3.6411449909210205 | KNN Loss: 3.6250200271606445 | CLS Loss: 0.016124870628118515\n",
      "Epoch 115 / 200 | iteration 160 / 171 | Total Loss: 3.60744309425354 | KNN Loss: 3.5959525108337402 | CLS Loss: 0.01149052381515503\n",
      "Epoch 115 / 200 | iteration 170 / 171 | Total Loss: 3.6377522945404053 | KNN Loss: 3.63360333442688 | CLS Loss: 0.0041489670984447\n",
      "Epoch: 115, Loss: 3.6178, Train: 0.9975, Valid: 0.9877, Best: 0.9881\n",
      "Epoch 116 / 200 | iteration 0 / 171 | Total Loss: 3.6135458946228027 | KNN Loss: 3.6086859703063965 | CLS Loss: 0.00485984468832612\n",
      "Epoch 116 / 200 | iteration 10 / 171 | Total Loss: 3.6337218284606934 | KNN Loss: 3.6279385089874268 | CLS Loss: 0.005783253349363804\n",
      "Epoch 116 / 200 | iteration 20 / 171 | Total Loss: 3.583249568939209 | KNN Loss: 3.580674409866333 | CLS Loss: 0.0025752221699804068\n",
      "Epoch 116 / 200 | iteration 30 / 171 | Total Loss: 3.6102678775787354 | KNN Loss: 3.6079747676849365 | CLS Loss: 0.0022930095437914133\n",
      "Epoch 116 / 200 | iteration 40 / 171 | Total Loss: 3.60514497756958 | KNN Loss: 3.5836644172668457 | CLS Loss: 0.02148064598441124\n",
      "Epoch 116 / 200 | iteration 50 / 171 | Total Loss: 3.6839044094085693 | KNN Loss: 3.6652512550354004 | CLS Loss: 0.018653105944395065\n",
      "Epoch 116 / 200 | iteration 60 / 171 | Total Loss: 3.601686716079712 | KNN Loss: 3.5931825637817383 | CLS Loss: 0.008504124358296394\n",
      "Epoch 116 / 200 | iteration 70 / 171 | Total Loss: 3.602776050567627 | KNN Loss: 3.596959114074707 | CLS Loss: 0.005816858261823654\n",
      "Epoch 116 / 200 | iteration 80 / 171 | Total Loss: 3.60907244682312 | KNN Loss: 3.5994455814361572 | CLS Loss: 0.009626781567931175\n",
      "Epoch 116 / 200 | iteration 90 / 171 | Total Loss: 3.583805799484253 | KNN Loss: 3.5812644958496094 | CLS Loss: 0.002541404915973544\n",
      "Epoch 116 / 200 | iteration 100 / 171 | Total Loss: 3.636087417602539 | KNN Loss: 3.6260573863983154 | CLS Loss: 0.010030066594481468\n",
      "Epoch 116 / 200 | iteration 110 / 171 | Total Loss: 3.5973947048187256 | KNN Loss: 3.586270332336426 | CLS Loss: 0.011124319396913052\n",
      "Epoch 116 / 200 | iteration 120 / 171 | Total Loss: 3.6061134338378906 | KNN Loss: 3.5986340045928955 | CLS Loss: 0.0074793556705117226\n",
      "Epoch 116 / 200 | iteration 130 / 171 | Total Loss: 3.6166610717773438 | KNN Loss: 3.5985300540924072 | CLS Loss: 0.018131135031580925\n",
      "Epoch 116 / 200 | iteration 140 / 171 | Total Loss: 3.5947506427764893 | KNN Loss: 3.5862863063812256 | CLS Loss: 0.008464288897812366\n",
      "Epoch 116 / 200 | iteration 150 / 171 | Total Loss: 3.598264694213867 | KNN Loss: 3.59580135345459 | CLS Loss: 0.0024634262081235647\n",
      "Epoch 116 / 200 | iteration 160 / 171 | Total Loss: 3.5975663661956787 | KNN Loss: 3.589653968811035 | CLS Loss: 0.007912391796708107\n",
      "Epoch 116 / 200 | iteration 170 / 171 | Total Loss: 3.603300094604492 | KNN Loss: 3.5992941856384277 | CLS Loss: 0.004005795810371637\n",
      "Epoch: 116, Loss: 3.6167, Train: 0.9967, Valid: 0.9868, Best: 0.9881\n",
      "Epoch 117 / 200 | iteration 0 / 171 | Total Loss: 3.5801048278808594 | KNN Loss: 3.5764718055725098 | CLS Loss: 0.003633026033639908\n",
      "Epoch 117 / 200 | iteration 10 / 171 | Total Loss: 3.602529764175415 | KNN Loss: 3.5998048782348633 | CLS Loss: 0.002724988153204322\n",
      "Epoch 117 / 200 | iteration 20 / 171 | Total Loss: 3.6158294677734375 | KNN Loss: 3.610755681991577 | CLS Loss: 0.005073849111795425\n",
      "Epoch 117 / 200 | iteration 30 / 171 | Total Loss: 3.5963237285614014 | KNN Loss: 3.5823307037353516 | CLS Loss: 0.013992986641824245\n",
      "Epoch 117 / 200 | iteration 40 / 171 | Total Loss: 3.6194984912872314 | KNN Loss: 3.611768960952759 | CLS Loss: 0.007729590870440006\n",
      "Epoch 117 / 200 | iteration 50 / 171 | Total Loss: 3.6452627182006836 | KNN Loss: 3.642767906188965 | CLS Loss: 0.002494734013453126\n",
      "Epoch 117 / 200 | iteration 60 / 171 | Total Loss: 3.6307291984558105 | KNN Loss: 3.619497537612915 | CLS Loss: 0.011231646873056889\n",
      "Epoch 117 / 200 | iteration 70 / 171 | Total Loss: 3.626213312149048 | KNN Loss: 3.6181423664093018 | CLS Loss: 0.008070853538811207\n",
      "Epoch 117 / 200 | iteration 80 / 171 | Total Loss: 3.6016314029693604 | KNN Loss: 3.599078893661499 | CLS Loss: 0.002552469726651907\n",
      "Epoch 117 / 200 | iteration 90 / 171 | Total Loss: 3.6196060180664062 | KNN Loss: 3.5996310710906982 | CLS Loss: 0.019974827766418457\n",
      "Epoch 117 / 200 | iteration 100 / 171 | Total Loss: 3.577613592147827 | KNN Loss: 3.573065757751465 | CLS Loss: 0.004547923803329468\n",
      "Epoch 117 / 200 | iteration 110 / 171 | Total Loss: 3.6350181102752686 | KNN Loss: 3.6000635623931885 | CLS Loss: 0.03495447337627411\n",
      "Epoch 117 / 200 | iteration 120 / 171 | Total Loss: 3.6366846561431885 | KNN Loss: 3.6158554553985596 | CLS Loss: 0.020829278975725174\n",
      "Epoch 117 / 200 | iteration 130 / 171 | Total Loss: 3.640629291534424 | KNN Loss: 3.609895706176758 | CLS Loss: 0.03073362447321415\n",
      "Epoch 117 / 200 | iteration 140 / 171 | Total Loss: 3.63632869720459 | KNN Loss: 3.6083314418792725 | CLS Loss: 0.027997201308608055\n",
      "Epoch 117 / 200 | iteration 150 / 171 | Total Loss: 3.5823347568511963 | KNN Loss: 3.579819440841675 | CLS Loss: 0.002515412401407957\n",
      "Epoch 117 / 200 | iteration 160 / 171 | Total Loss: 3.629754066467285 | KNN Loss: 3.613173007965088 | CLS Loss: 0.01658107340335846\n",
      "Epoch 117 / 200 | iteration 170 / 171 | Total Loss: 3.5839457511901855 | KNN Loss: 3.5762548446655273 | CLS Loss: 0.007690806407481432\n",
      "Epoch: 117, Loss: 3.6122, Train: 0.9970, Valid: 0.9863, Best: 0.9881\n",
      "Epoch 118 / 200 | iteration 0 / 171 | Total Loss: 3.5812630653381348 | KNN Loss: 3.575756788253784 | CLS Loss: 0.005506311077624559\n",
      "Epoch 118 / 200 | iteration 10 / 171 | Total Loss: 3.583162546157837 | KNN Loss: 3.575381278991699 | CLS Loss: 0.007781327702105045\n",
      "Epoch 118 / 200 | iteration 20 / 171 | Total Loss: 3.702787160873413 | KNN Loss: 3.6941545009613037 | CLS Loss: 0.008632735349237919\n",
      "Epoch 118 / 200 | iteration 30 / 171 | Total Loss: 3.694058656692505 | KNN Loss: 3.6704535484313965 | CLS Loss: 0.023605113849043846\n",
      "Epoch 118 / 200 | iteration 40 / 171 | Total Loss: 3.623309850692749 | KNN Loss: 3.616260051727295 | CLS Loss: 0.007049888372421265\n",
      "Epoch 118 / 200 | iteration 50 / 171 | Total Loss: 3.5983328819274902 | KNN Loss: 3.5927295684814453 | CLS Loss: 0.005603353958576918\n",
      "Epoch 118 / 200 | iteration 60 / 171 | Total Loss: 3.6557395458221436 | KNN Loss: 3.6203887462615967 | CLS Loss: 0.03535090759396553\n",
      "Epoch 118 / 200 | iteration 70 / 171 | Total Loss: 3.654480457305908 | KNN Loss: 3.625530242919922 | CLS Loss: 0.028950225561857224\n",
      "Epoch 118 / 200 | iteration 80 / 171 | Total Loss: 3.6004068851470947 | KNN Loss: 3.5895750522613525 | CLS Loss: 0.010831777937710285\n",
      "Epoch 118 / 200 | iteration 90 / 171 | Total Loss: 3.6327197551727295 | KNN Loss: 3.603681802749634 | CLS Loss: 0.029037993401288986\n",
      "Epoch 118 / 200 | iteration 100 / 171 | Total Loss: 3.6525418758392334 | KNN Loss: 3.6415061950683594 | CLS Loss: 0.011035571806132793\n",
      "Epoch 118 / 200 | iteration 110 / 171 | Total Loss: 3.5843424797058105 | KNN Loss: 3.5786654949188232 | CLS Loss: 0.0056769344955682755\n",
      "Epoch 118 / 200 | iteration 120 / 171 | Total Loss: 3.5887436866760254 | KNN Loss: 3.5733323097229004 | CLS Loss: 0.01541126612573862\n",
      "Epoch 118 / 200 | iteration 130 / 171 | Total Loss: 3.637471914291382 | KNN Loss: 3.601167678833008 | CLS Loss: 0.03630430996417999\n",
      "Epoch 118 / 200 | iteration 140 / 171 | Total Loss: 3.636863946914673 | KNN Loss: 3.627439260482788 | CLS Loss: 0.009424651972949505\n",
      "Epoch 118 / 200 | iteration 150 / 171 | Total Loss: 3.609370708465576 | KNN Loss: 3.569016218185425 | CLS Loss: 0.040354423224925995\n",
      "Epoch 118 / 200 | iteration 160 / 171 | Total Loss: 3.6025586128234863 | KNN Loss: 3.5866527557373047 | CLS Loss: 0.01590576581656933\n",
      "Epoch 118 / 200 | iteration 170 / 171 | Total Loss: 3.608233690261841 | KNN Loss: 3.603553056716919 | CLS Loss: 0.00468071736395359\n",
      "Epoch: 118, Loss: 3.6192, Train: 0.9973, Valid: 0.9877, Best: 0.9881\n",
      "Epoch 119 / 200 | iteration 0 / 171 | Total Loss: 3.6001861095428467 | KNN Loss: 3.592461109161377 | CLS Loss: 0.007725054863840342\n",
      "Epoch 119 / 200 | iteration 10 / 171 | Total Loss: 3.5769550800323486 | KNN Loss: 3.5722484588623047 | CLS Loss: 0.004706725012511015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 / 200 | iteration 20 / 171 | Total Loss: 3.6071670055389404 | KNN Loss: 3.5991220474243164 | CLS Loss: 0.008044973015785217\n",
      "Epoch 119 / 200 | iteration 30 / 171 | Total Loss: 3.612978219985962 | KNN Loss: 3.6033852100372314 | CLS Loss: 0.00959306862205267\n",
      "Epoch 119 / 200 | iteration 40 / 171 | Total Loss: 3.606078624725342 | KNN Loss: 3.5992918014526367 | CLS Loss: 0.006786815822124481\n",
      "Epoch 119 / 200 | iteration 50 / 171 | Total Loss: 3.6129939556121826 | KNN Loss: 3.6075706481933594 | CLS Loss: 0.005423199385404587\n",
      "Epoch 119 / 200 | iteration 60 / 171 | Total Loss: 3.6527276039123535 | KNN Loss: 3.638612747192383 | CLS Loss: 0.01411491073668003\n",
      "Epoch 119 / 200 | iteration 70 / 171 | Total Loss: 3.604142665863037 | KNN Loss: 3.5883240699768066 | CLS Loss: 0.015818608924746513\n",
      "Epoch 119 / 200 | iteration 80 / 171 | Total Loss: 3.5924365520477295 | KNN Loss: 3.5850725173950195 | CLS Loss: 0.007364145014435053\n",
      "Epoch 119 / 200 | iteration 90 / 171 | Total Loss: 3.6795766353607178 | KNN Loss: 3.6646652221679688 | CLS Loss: 0.0149114690721035\n",
      "Epoch 119 / 200 | iteration 100 / 171 | Total Loss: 3.648437023162842 | KNN Loss: 3.6201369762420654 | CLS Loss: 0.028300147503614426\n",
      "Epoch 119 / 200 | iteration 110 / 171 | Total Loss: 3.6825897693634033 | KNN Loss: 3.651196002960205 | CLS Loss: 0.031393855810165405\n",
      "Epoch 119 / 200 | iteration 120 / 171 | Total Loss: 3.5921497344970703 | KNN Loss: 3.5899667739868164 | CLS Loss: 0.0021829858887940645\n",
      "Epoch 119 / 200 | iteration 130 / 171 | Total Loss: 3.6671783924102783 | KNN Loss: 3.6422038078308105 | CLS Loss: 0.024974578991532326\n",
      "Epoch 119 / 200 | iteration 140 / 171 | Total Loss: 3.6370322704315186 | KNN Loss: 3.6220736503601074 | CLS Loss: 0.014958587475121021\n",
      "Epoch 119 / 200 | iteration 150 / 171 | Total Loss: 3.5832712650299072 | KNN Loss: 3.5809764862060547 | CLS Loss: 0.002294782316312194\n",
      "Epoch 119 / 200 | iteration 160 / 171 | Total Loss: 3.6194393634796143 | KNN Loss: 3.5956950187683105 | CLS Loss: 0.02374434843659401\n",
      "Epoch 119 / 200 | iteration 170 / 171 | Total Loss: 3.6036930084228516 | KNN Loss: 3.5922434329986572 | CLS Loss: 0.0114495400339365\n",
      "Epoch: 119, Loss: 3.6186, Train: 0.9961, Valid: 0.9868, Best: 0.9881\n",
      "Epoch 120 / 200 | iteration 0 / 171 | Total Loss: 3.647449254989624 | KNN Loss: 3.628086566925049 | CLS Loss: 0.01936270110309124\n",
      "Epoch 120 / 200 | iteration 10 / 171 | Total Loss: 3.597341299057007 | KNN Loss: 3.5923197269439697 | CLS Loss: 0.005021560937166214\n",
      "Epoch 120 / 200 | iteration 20 / 171 | Total Loss: 3.692779302597046 | KNN Loss: 3.6717443466186523 | CLS Loss: 0.02103501744568348\n",
      "Epoch 120 / 200 | iteration 30 / 171 | Total Loss: 3.6175925731658936 | KNN Loss: 3.605823040008545 | CLS Loss: 0.011769590899348259\n",
      "Epoch 120 / 200 | iteration 40 / 171 | Total Loss: 3.6567893028259277 | KNN Loss: 3.6508188247680664 | CLS Loss: 0.005970469210296869\n",
      "Epoch 120 / 200 | iteration 50 / 171 | Total Loss: 3.5843138694763184 | KNN Loss: 3.56998348236084 | CLS Loss: 0.014330461621284485\n",
      "Epoch 120 / 200 | iteration 60 / 171 | Total Loss: 3.624966621398926 | KNN Loss: 3.617785930633545 | CLS Loss: 0.0071807787753641605\n",
      "Epoch 120 / 200 | iteration 70 / 171 | Total Loss: 3.5706472396850586 | KNN Loss: 3.5607595443725586 | CLS Loss: 0.009887797757983208\n",
      "Epoch 120 / 200 | iteration 80 / 171 | Total Loss: 3.645815134048462 | KNN Loss: 3.636413097381592 | CLS Loss: 0.009401967748999596\n",
      "Epoch 120 / 200 | iteration 90 / 171 | Total Loss: 3.649240732192993 | KNN Loss: 3.6194334030151367 | CLS Loss: 0.029807444661855698\n",
      "Epoch 120 / 200 | iteration 100 / 171 | Total Loss: 3.612375259399414 | KNN Loss: 3.6057353019714355 | CLS Loss: 0.00663998955860734\n",
      "Epoch 120 / 200 | iteration 110 / 171 | Total Loss: 3.632800817489624 | KNN Loss: 3.609978199005127 | CLS Loss: 0.022822575643658638\n",
      "Epoch 120 / 200 | iteration 120 / 171 | Total Loss: 3.6180994510650635 | KNN Loss: 3.6052184104919434 | CLS Loss: 0.01288099680095911\n",
      "Epoch 120 / 200 | iteration 130 / 171 | Total Loss: 3.604724884033203 | KNN Loss: 3.5924441814422607 | CLS Loss: 0.012280654162168503\n",
      "Epoch 120 / 200 | iteration 140 / 171 | Total Loss: 3.6195056438446045 | KNN Loss: 3.5951266288757324 | CLS Loss: 0.024379048496484756\n",
      "Epoch 120 / 200 | iteration 150 / 171 | Total Loss: 3.593190908432007 | KNN Loss: 3.5891213417053223 | CLS Loss: 0.004069606773555279\n",
      "Epoch 120 / 200 | iteration 160 / 171 | Total Loss: 3.617398262023926 | KNN Loss: 3.600184917449951 | CLS Loss: 0.017213305458426476\n",
      "Epoch 120 / 200 | iteration 170 / 171 | Total Loss: 3.592768430709839 | KNN Loss: 3.5749239921569824 | CLS Loss: 0.01784447766840458\n",
      "Epoch: 120, Loss: 3.6199, Train: 0.9970, Valid: 0.9864, Best: 0.9881\n",
      "Epoch 121 / 200 | iteration 0 / 171 | Total Loss: 3.6154046058654785 | KNN Loss: 3.6126410961151123 | CLS Loss: 0.0027634368743747473\n",
      "Epoch 121 / 200 | iteration 10 / 171 | Total Loss: 3.57236647605896 | KNN Loss: 3.568586587905884 | CLS Loss: 0.0037797759287059307\n",
      "Epoch 121 / 200 | iteration 20 / 171 | Total Loss: 3.6332266330718994 | KNN Loss: 3.623248815536499 | CLS Loss: 0.009977727197110653\n",
      "Epoch 121 / 200 | iteration 30 / 171 | Total Loss: 3.5751235485076904 | KNN Loss: 3.569958209991455 | CLS Loss: 0.0051652295514941216\n",
      "Epoch 121 / 200 | iteration 40 / 171 | Total Loss: 3.631434440612793 | KNN Loss: 3.6157069206237793 | CLS Loss: 0.015727564692497253\n",
      "Epoch 121 / 200 | iteration 50 / 171 | Total Loss: 3.60305118560791 | KNN Loss: 3.5987961292266846 | CLS Loss: 0.00425502797588706\n",
      "Epoch 121 / 200 | iteration 60 / 171 | Total Loss: 3.5760152339935303 | KNN Loss: 3.574892997741699 | CLS Loss: 0.001122329500503838\n",
      "Epoch 121 / 200 | iteration 70 / 171 | Total Loss: 3.6056602001190186 | KNN Loss: 3.5852134227752686 | CLS Loss: 0.020446838811039925\n",
      "Epoch 121 / 200 | iteration 80 / 171 | Total Loss: 3.635179042816162 | KNN Loss: 3.6178905963897705 | CLS Loss: 0.017288468778133392\n",
      "Epoch 121 / 200 | iteration 90 / 171 | Total Loss: 3.61944580078125 | KNN Loss: 3.5874223709106445 | CLS Loss: 0.03202332183718681\n",
      "Epoch 121 / 200 | iteration 100 / 171 | Total Loss: 3.6131591796875 | KNN Loss: 3.603752613067627 | CLS Loss: 0.009406491182744503\n",
      "Epoch 121 / 200 | iteration 110 / 171 | Total Loss: 3.587824583053589 | KNN Loss: 3.576846122741699 | CLS Loss: 0.010978538542985916\n",
      "Epoch 121 / 200 | iteration 120 / 171 | Total Loss: 3.5898702144622803 | KNN Loss: 3.5798423290252686 | CLS Loss: 0.010027880780398846\n",
      "Epoch 121 / 200 | iteration 130 / 171 | Total Loss: 3.5902860164642334 | KNN Loss: 3.5840795040130615 | CLS Loss: 0.006206469144672155\n",
      "Epoch 121 / 200 | iteration 140 / 171 | Total Loss: 3.5888209342956543 | KNN Loss: 3.584151029586792 | CLS Loss: 0.0046699983067810535\n",
      "Epoch 121 / 200 | iteration 150 / 171 | Total Loss: 3.6139957904815674 | KNN Loss: 3.6010630130767822 | CLS Loss: 0.012932809069752693\n",
      "Epoch 121 / 200 | iteration 160 / 171 | Total Loss: 3.6200973987579346 | KNN Loss: 3.6069748401641846 | CLS Loss: 0.013122511096298695\n",
      "Epoch 121 / 200 | iteration 170 / 171 | Total Loss: 3.5749659538269043 | KNN Loss: 3.5713155269622803 | CLS Loss: 0.003650529542937875\n",
      "Epoch: 121, Loss: 3.6163, Train: 0.9972, Valid: 0.9866, Best: 0.9881\n",
      "Epoch 122 / 200 | iteration 0 / 171 | Total Loss: 3.6403236389160156 | KNN Loss: 3.6320855617523193 | CLS Loss: 0.0082381097599864\n",
      "Epoch 122 / 200 | iteration 10 / 171 | Total Loss: 3.5884652137756348 | KNN Loss: 3.5874991416931152 | CLS Loss: 0.0009660093928687274\n",
      "Epoch 122 / 200 | iteration 20 / 171 | Total Loss: 3.616725444793701 | KNN Loss: 3.6106252670288086 | CLS Loss: 0.006100112572312355\n",
      "Epoch 122 / 200 | iteration 30 / 171 | Total Loss: 3.643306016921997 | KNN Loss: 3.637122631072998 | CLS Loss: 0.00618332251906395\n",
      "Epoch 122 / 200 | iteration 40 / 171 | Total Loss: 3.586637258529663 | KNN Loss: 3.5712666511535645 | CLS Loss: 0.015370514243841171\n",
      "Epoch 122 / 200 | iteration 50 / 171 | Total Loss: 3.640754222869873 | KNN Loss: 3.6247706413269043 | CLS Loss: 0.01598348096013069\n",
      "Epoch 122 / 200 | iteration 60 / 171 | Total Loss: 3.6240170001983643 | KNN Loss: 3.599658727645874 | CLS Loss: 0.024358168244361877\n",
      "Epoch 122 / 200 | iteration 70 / 171 | Total Loss: 3.594444990158081 | KNN Loss: 3.5728378295898438 | CLS Loss: 0.02160710282623768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 / 200 | iteration 80 / 171 | Total Loss: 3.652555465698242 | KNN Loss: 3.632920742034912 | CLS Loss: 0.019634706899523735\n",
      "Epoch 122 / 200 | iteration 90 / 171 | Total Loss: 3.608720302581787 | KNN Loss: 3.6025447845458984 | CLS Loss: 0.006175558548420668\n",
      "Epoch 122 / 200 | iteration 100 / 171 | Total Loss: 3.617546796798706 | KNN Loss: 3.6056737899780273 | CLS Loss: 0.011872935108840466\n",
      "Epoch 122 / 200 | iteration 110 / 171 | Total Loss: 3.594090700149536 | KNN Loss: 3.5758755207061768 | CLS Loss: 0.018215246498584747\n",
      "Epoch 122 / 200 | iteration 120 / 171 | Total Loss: 3.575608253479004 | KNN Loss: 3.561797618865967 | CLS Loss: 0.013810553587973118\n",
      "Epoch 122 / 200 | iteration 130 / 171 | Total Loss: 3.6691012382507324 | KNN Loss: 3.6638784408569336 | CLS Loss: 0.005222736392170191\n",
      "Epoch 122 / 200 | iteration 140 / 171 | Total Loss: 3.6868655681610107 | KNN Loss: 3.6741299629211426 | CLS Loss: 0.012735721655189991\n",
      "Epoch 122 / 200 | iteration 150 / 171 | Total Loss: 3.628342866897583 | KNN Loss: 3.6132090091705322 | CLS Loss: 0.01513380091637373\n",
      "Epoch 122 / 200 | iteration 160 / 171 | Total Loss: 3.5839173793792725 | KNN Loss: 3.583219289779663 | CLS Loss: 0.000698145420756191\n",
      "Epoch 122 / 200 | iteration 170 / 171 | Total Loss: 3.6572437286376953 | KNN Loss: 3.6482131481170654 | CLS Loss: 0.009030505083501339\n",
      "Epoch: 122, Loss: 3.6192, Train: 0.9961, Valid: 0.9850, Best: 0.9881\n",
      "Epoch 123 / 200 | iteration 0 / 171 | Total Loss: 3.6758224964141846 | KNN Loss: 3.656235694885254 | CLS Loss: 0.019586805254220963\n",
      "Epoch 123 / 200 | iteration 10 / 171 | Total Loss: 3.649721145629883 | KNN Loss: 3.605001211166382 | CLS Loss: 0.04471993073821068\n",
      "Epoch 123 / 200 | iteration 20 / 171 | Total Loss: 3.6429460048675537 | KNN Loss: 3.608910322189331 | CLS Loss: 0.03403572365641594\n",
      "Epoch 123 / 200 | iteration 30 / 171 | Total Loss: 3.5987656116485596 | KNN Loss: 3.5812618732452393 | CLS Loss: 0.01750371791422367\n",
      "Epoch 123 / 200 | iteration 40 / 171 | Total Loss: 3.650784969329834 | KNN Loss: 3.645695447921753 | CLS Loss: 0.005089465994387865\n",
      "Epoch 123 / 200 | iteration 50 / 171 | Total Loss: 3.6437196731567383 | KNN Loss: 3.62211012840271 | CLS Loss: 0.021609630435705185\n",
      "Epoch 123 / 200 | iteration 60 / 171 | Total Loss: 3.5941379070281982 | KNN Loss: 3.5826878547668457 | CLS Loss: 0.011450007557868958\n",
      "Epoch 123 / 200 | iteration 70 / 171 | Total Loss: 3.6703102588653564 | KNN Loss: 3.639723777770996 | CLS Loss: 0.03058653324842453\n",
      "Epoch 123 / 200 | iteration 80 / 171 | Total Loss: 3.6124541759490967 | KNN Loss: 3.585925340652466 | CLS Loss: 0.026528852060437202\n",
      "Epoch 123 / 200 | iteration 90 / 171 | Total Loss: 3.6051485538482666 | KNN Loss: 3.5942845344543457 | CLS Loss: 0.010863997042179108\n",
      "Epoch 123 / 200 | iteration 100 / 171 | Total Loss: 3.6342203617095947 | KNN Loss: 3.6104376316070557 | CLS Loss: 0.023782745003700256\n",
      "Epoch 123 / 200 | iteration 110 / 171 | Total Loss: 3.630979537963867 | KNN Loss: 3.611680507659912 | CLS Loss: 0.01929893158376217\n",
      "Epoch 123 / 200 | iteration 120 / 171 | Total Loss: 3.58921217918396 | KNN Loss: 3.5878281593322754 | CLS Loss: 0.0013841125182807446\n",
      "Epoch 123 / 200 | iteration 130 / 171 | Total Loss: 3.659518003463745 | KNN Loss: 3.638331413269043 | CLS Loss: 0.02118670381605625\n",
      "Epoch 123 / 200 | iteration 140 / 171 | Total Loss: 3.614262104034424 | KNN Loss: 3.600128412246704 | CLS Loss: 0.014133702963590622\n",
      "Epoch 123 / 200 | iteration 150 / 171 | Total Loss: 3.6417441368103027 | KNN Loss: 3.6287615299224854 | CLS Loss: 0.012982703745365143\n",
      "Epoch 123 / 200 | iteration 160 / 171 | Total Loss: 3.577768087387085 | KNN Loss: 3.5536739826202393 | CLS Loss: 0.02409403584897518\n",
      "Epoch 123 / 200 | iteration 170 / 171 | Total Loss: 3.584088087081909 | KNN Loss: 3.5813281536102295 | CLS Loss: 0.0027600484900176525\n",
      "Epoch: 123, Loss: 3.6230, Train: 0.9968, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 124 / 200 | iteration 0 / 171 | Total Loss: 3.620692491531372 | KNN Loss: 3.600191116333008 | CLS Loss: 0.020501315593719482\n",
      "Epoch 124 / 200 | iteration 10 / 171 | Total Loss: 3.61287522315979 | KNN Loss: 3.58951735496521 | CLS Loss: 0.023357758298516273\n",
      "Epoch 124 / 200 | iteration 20 / 171 | Total Loss: 3.602287769317627 | KNN Loss: 3.5899033546447754 | CLS Loss: 0.012384298257529736\n",
      "Epoch 124 / 200 | iteration 30 / 171 | Total Loss: 3.590467691421509 | KNN Loss: 3.5841078758239746 | CLS Loss: 0.006359849125146866\n",
      "Epoch 124 / 200 | iteration 40 / 171 | Total Loss: 3.5821335315704346 | KNN Loss: 3.5771336555480957 | CLS Loss: 0.004999980796128511\n",
      "Epoch 124 / 200 | iteration 50 / 171 | Total Loss: 3.609649419784546 | KNN Loss: 3.590916872024536 | CLS Loss: 0.018732495605945587\n",
      "Epoch 124 / 200 | iteration 60 / 171 | Total Loss: 3.5986108779907227 | KNN Loss: 3.5935490131378174 | CLS Loss: 0.005061922129243612\n",
      "Epoch 124 / 200 | iteration 70 / 171 | Total Loss: 3.641385793685913 | KNN Loss: 3.622821807861328 | CLS Loss: 0.01856408827006817\n",
      "Epoch 124 / 200 | iteration 80 / 171 | Total Loss: 3.586894989013672 | KNN Loss: 3.583463191986084 | CLS Loss: 0.00343175302259624\n",
      "Epoch 124 / 200 | iteration 90 / 171 | Total Loss: 3.640409231185913 | KNN Loss: 3.63525128364563 | CLS Loss: 0.00515802251175046\n",
      "Epoch 124 / 200 | iteration 100 / 171 | Total Loss: 3.6687183380126953 | KNN Loss: 3.658214807510376 | CLS Loss: 0.010503439232707024\n",
      "Epoch 124 / 200 | iteration 110 / 171 | Total Loss: 3.6566829681396484 | KNN Loss: 3.6383845806121826 | CLS Loss: 0.01829831302165985\n",
      "Epoch 124 / 200 | iteration 120 / 171 | Total Loss: 3.617112874984741 | KNN Loss: 3.6124987602233887 | CLS Loss: 0.0046140169724822044\n",
      "Epoch 124 / 200 | iteration 130 / 171 | Total Loss: 3.611985683441162 | KNN Loss: 3.6106061935424805 | CLS Loss: 0.001379525288939476\n",
      "Epoch 124 / 200 | iteration 140 / 171 | Total Loss: 3.6756653785705566 | KNN Loss: 3.6699609756469727 | CLS Loss: 0.005704296287149191\n",
      "Epoch 124 / 200 | iteration 150 / 171 | Total Loss: 3.6219441890716553 | KNN Loss: 3.6019134521484375 | CLS Loss: 0.020030619576573372\n",
      "Epoch 124 / 200 | iteration 160 / 171 | Total Loss: 3.5845413208007812 | KNN Loss: 3.5763802528381348 | CLS Loss: 0.008161003701388836\n",
      "Epoch 124 / 200 | iteration 170 / 171 | Total Loss: 3.6563141345977783 | KNN Loss: 3.609161853790283 | CLS Loss: 0.047152165323495865\n",
      "Epoch: 124, Loss: 3.6180, Train: 0.9958, Valid: 0.9869, Best: 0.9881\n",
      "Epoch 125 / 200 | iteration 0 / 171 | Total Loss: 3.5964913368225098 | KNN Loss: 3.5827925205230713 | CLS Loss: 0.013698839582502842\n",
      "Epoch 125 / 200 | iteration 10 / 171 | Total Loss: 3.6369528770446777 | KNN Loss: 3.624725341796875 | CLS Loss: 0.012227622792124748\n",
      "Epoch 125 / 200 | iteration 20 / 171 | Total Loss: 3.5935747623443604 | KNN Loss: 3.592412233352661 | CLS Loss: 0.001162618980742991\n",
      "Epoch 125 / 200 | iteration 30 / 171 | Total Loss: 3.5975921154022217 | KNN Loss: 3.591012477874756 | CLS Loss: 0.0065795378759503365\n",
      "Epoch 125 / 200 | iteration 40 / 171 | Total Loss: 3.599989652633667 | KNN Loss: 3.594170331954956 | CLS Loss: 0.005819209851324558\n",
      "Epoch 125 / 200 | iteration 50 / 171 | Total Loss: 3.6525752544403076 | KNN Loss: 3.640324354171753 | CLS Loss: 0.012250981293618679\n",
      "Epoch 125 / 200 | iteration 60 / 171 | Total Loss: 3.6416120529174805 | KNN Loss: 3.6205532550811768 | CLS Loss: 0.02105884440243244\n",
      "Epoch 125 / 200 | iteration 70 / 171 | Total Loss: 3.586543560028076 | KNN Loss: 3.578319549560547 | CLS Loss: 0.00822404120117426\n",
      "Epoch 125 / 200 | iteration 80 / 171 | Total Loss: 3.623494863510132 | KNN Loss: 3.606377363204956 | CLS Loss: 0.01711752638220787\n",
      "Epoch 125 / 200 | iteration 90 / 171 | Total Loss: 3.5757017135620117 | KNN Loss: 3.5709736347198486 | CLS Loss: 0.00472801411524415\n",
      "Epoch 125 / 200 | iteration 100 / 171 | Total Loss: 3.6140332221984863 | KNN Loss: 3.5973548889160156 | CLS Loss: 0.016678407788276672\n",
      "Epoch 125 / 200 | iteration 110 / 171 | Total Loss: 3.6001784801483154 | KNN Loss: 3.5870814323425293 | CLS Loss: 0.013096933253109455\n",
      "Epoch 125 / 200 | iteration 120 / 171 | Total Loss: 3.594484806060791 | KNN Loss: 3.5795552730560303 | CLS Loss: 0.014929494820535183\n",
      "Epoch 125 / 200 | iteration 130 / 171 | Total Loss: 3.646564245223999 | KNN Loss: 3.633108615875244 | CLS Loss: 0.013455706648528576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 / 200 | iteration 140 / 171 | Total Loss: 3.625856637954712 | KNN Loss: 3.608428478240967 | CLS Loss: 0.017428120598196983\n",
      "Epoch 125 / 200 | iteration 150 / 171 | Total Loss: 3.572056293487549 | KNN Loss: 3.5525996685028076 | CLS Loss: 0.019456731155514717\n",
      "Epoch 125 / 200 | iteration 160 / 171 | Total Loss: 3.640126943588257 | KNN Loss: 3.6269543170928955 | CLS Loss: 0.013172728940844536\n",
      "Epoch 125 / 200 | iteration 170 / 171 | Total Loss: 3.595499277114868 | KNN Loss: 3.5779781341552734 | CLS Loss: 0.017521236091852188\n",
      "Epoch: 125, Loss: 3.6183, Train: 0.9955, Valid: 0.9864, Best: 0.9881\n",
      "Epoch 126 / 200 | iteration 0 / 171 | Total Loss: 3.592500686645508 | KNN Loss: 3.570540189743042 | CLS Loss: 0.021960459649562836\n",
      "Epoch 126 / 200 | iteration 10 / 171 | Total Loss: 3.6385421752929688 | KNN Loss: 3.6291301250457764 | CLS Loss: 0.009412012994289398\n",
      "Epoch 126 / 200 | iteration 20 / 171 | Total Loss: 3.619993209838867 | KNN Loss: 3.617649555206299 | CLS Loss: 0.0023437202908098698\n",
      "Epoch 126 / 200 | iteration 30 / 171 | Total Loss: 3.611311912536621 | KNN Loss: 3.5998916625976562 | CLS Loss: 0.011420239694416523\n",
      "Epoch 126 / 200 | iteration 40 / 171 | Total Loss: 3.7044484615325928 | KNN Loss: 3.6535274982452393 | CLS Loss: 0.0509210005402565\n",
      "Epoch 126 / 200 | iteration 50 / 171 | Total Loss: 3.648653745651245 | KNN Loss: 3.620271682739258 | CLS Loss: 0.028382057324051857\n",
      "Epoch 126 / 200 | iteration 60 / 171 | Total Loss: 3.7001311779022217 | KNN Loss: 3.657487630844116 | CLS Loss: 0.04264364391565323\n",
      "Epoch 126 / 200 | iteration 70 / 171 | Total Loss: 3.583268165588379 | KNN Loss: 3.577460765838623 | CLS Loss: 0.005807432811707258\n",
      "Epoch 126 / 200 | iteration 80 / 171 | Total Loss: 3.586693048477173 | KNN Loss: 3.5752148628234863 | CLS Loss: 0.011478115804493427\n",
      "Epoch 126 / 200 | iteration 90 / 171 | Total Loss: 3.6203958988189697 | KNN Loss: 3.580066442489624 | CLS Loss: 0.04032938927412033\n",
      "Epoch 126 / 200 | iteration 100 / 171 | Total Loss: 3.620932102203369 | KNN Loss: 3.604299306869507 | CLS Loss: 0.01663276180624962\n",
      "Epoch 126 / 200 | iteration 110 / 171 | Total Loss: 3.621753454208374 | KNN Loss: 3.6090166568756104 | CLS Loss: 0.012736841104924679\n",
      "Epoch 126 / 200 | iteration 120 / 171 | Total Loss: 3.5910370349884033 | KNN Loss: 3.5872066020965576 | CLS Loss: 0.0038304037880152464\n",
      "Epoch 126 / 200 | iteration 130 / 171 | Total Loss: 3.64320969581604 | KNN Loss: 3.6162233352661133 | CLS Loss: 0.026986466720700264\n",
      "Epoch 126 / 200 | iteration 140 / 171 | Total Loss: 3.608138084411621 | KNN Loss: 3.5831542015075684 | CLS Loss: 0.024983903393149376\n",
      "Epoch 126 / 200 | iteration 150 / 171 | Total Loss: 3.623413562774658 | KNN Loss: 3.6094462871551514 | CLS Loss: 0.013967295177280903\n",
      "Epoch 126 / 200 | iteration 160 / 171 | Total Loss: 3.603710651397705 | KNN Loss: 3.5999717712402344 | CLS Loss: 0.0037388706114143133\n",
      "Epoch 126 / 200 | iteration 170 / 171 | Total Loss: 3.6773717403411865 | KNN Loss: 3.6562180519104004 | CLS Loss: 0.021153733134269714\n",
      "Epoch: 126, Loss: 3.6213, Train: 0.9955, Valid: 0.9853, Best: 0.9881\n",
      "Epoch 127 / 200 | iteration 0 / 171 | Total Loss: 3.6305429935455322 | KNN Loss: 3.6239075660705566 | CLS Loss: 0.006635414902120829\n",
      "Epoch 127 / 200 | iteration 10 / 171 | Total Loss: 3.6036252975463867 | KNN Loss: 3.5966484546661377 | CLS Loss: 0.006976816803216934\n",
      "Epoch 127 / 200 | iteration 20 / 171 | Total Loss: 3.623265027999878 | KNN Loss: 3.599010944366455 | CLS Loss: 0.02425413206219673\n",
      "Epoch 127 / 200 | iteration 30 / 171 | Total Loss: 3.577008008956909 | KNN Loss: 3.571938991546631 | CLS Loss: 0.005068948958069086\n",
      "Epoch 127 / 200 | iteration 40 / 171 | Total Loss: 3.6137330532073975 | KNN Loss: 3.6068673133850098 | CLS Loss: 0.0068658082745969296\n",
      "Epoch 127 / 200 | iteration 50 / 171 | Total Loss: 3.5958781242370605 | KNN Loss: 3.588273048400879 | CLS Loss: 0.007604957092553377\n",
      "Epoch 127 / 200 | iteration 60 / 171 | Total Loss: 3.646430253982544 | KNN Loss: 3.6357057094573975 | CLS Loss: 0.01072457805275917\n",
      "Epoch 127 / 200 | iteration 70 / 171 | Total Loss: 3.5699408054351807 | KNN Loss: 3.5609190464019775 | CLS Loss: 0.009021657519042492\n",
      "Epoch 127 / 200 | iteration 80 / 171 | Total Loss: 3.615492343902588 | KNN Loss: 3.59647798538208 | CLS Loss: 0.019014379009604454\n",
      "Epoch 127 / 200 | iteration 90 / 171 | Total Loss: 3.6244404315948486 | KNN Loss: 3.6217150688171387 | CLS Loss: 0.0027252528816461563\n",
      "Epoch 127 / 200 | iteration 100 / 171 | Total Loss: 3.6022586822509766 | KNN Loss: 3.5752639770507812 | CLS Loss: 0.02699476107954979\n",
      "Epoch 127 / 200 | iteration 110 / 171 | Total Loss: 3.5854873657226562 | KNN Loss: 3.581677198410034 | CLS Loss: 0.003810165449976921\n",
      "Epoch 127 / 200 | iteration 120 / 171 | Total Loss: 3.6069412231445312 | KNN Loss: 3.5983943939208984 | CLS Loss: 0.008546925149857998\n",
      "Epoch 127 / 200 | iteration 130 / 171 | Total Loss: 3.597654104232788 | KNN Loss: 3.5802884101867676 | CLS Loss: 0.01736568659543991\n",
      "Epoch 127 / 200 | iteration 140 / 171 | Total Loss: 3.6024816036224365 | KNN Loss: 3.5896120071411133 | CLS Loss: 0.012869586236774921\n",
      "Epoch 127 / 200 | iteration 150 / 171 | Total Loss: 3.6237990856170654 | KNN Loss: 3.6160640716552734 | CLS Loss: 0.007734995801001787\n",
      "Epoch 127 / 200 | iteration 160 / 171 | Total Loss: 3.578256130218506 | KNN Loss: 3.571861982345581 | CLS Loss: 0.006394238211214542\n",
      "Epoch 127 / 200 | iteration 170 / 171 | Total Loss: 3.6009020805358887 | KNN Loss: 3.5978221893310547 | CLS Loss: 0.0030799356754869223\n",
      "Epoch: 127, Loss: 3.6122, Train: 0.9977, Valid: 0.9865, Best: 0.9881\n",
      "Epoch 128 / 200 | iteration 0 / 171 | Total Loss: 3.6029279232025146 | KNN Loss: 3.594146966934204 | CLS Loss: 0.008780925534665585\n",
      "Epoch 128 / 200 | iteration 10 / 171 | Total Loss: 3.593151807785034 | KNN Loss: 3.564047336578369 | CLS Loss: 0.029104381799697876\n",
      "Epoch 128 / 200 | iteration 20 / 171 | Total Loss: 3.607879877090454 | KNN Loss: 3.600430727005005 | CLS Loss: 0.007449149154126644\n",
      "Epoch 128 / 200 | iteration 30 / 171 | Total Loss: 3.6086266040802 | KNN Loss: 3.5955467224121094 | CLS Loss: 0.013079939410090446\n",
      "Epoch 128 / 200 | iteration 40 / 171 | Total Loss: 3.587523937225342 | KNN Loss: 3.5830934047698975 | CLS Loss: 0.004430529195815325\n",
      "Epoch 128 / 200 | iteration 50 / 171 | Total Loss: 3.5941667556762695 | KNN Loss: 3.5844273567199707 | CLS Loss: 0.009739415720105171\n",
      "Epoch 128 / 200 | iteration 60 / 171 | Total Loss: 3.5915918350219727 | KNN Loss: 3.589148998260498 | CLS Loss: 0.0024429357144981623\n",
      "Epoch 128 / 200 | iteration 70 / 171 | Total Loss: 3.5990116596221924 | KNN Loss: 3.596283435821533 | CLS Loss: 0.002728305757045746\n",
      "Epoch 128 / 200 | iteration 80 / 171 | Total Loss: 3.632934093475342 | KNN Loss: 3.6229465007781982 | CLS Loss: 0.00998751912266016\n",
      "Epoch 128 / 200 | iteration 90 / 171 | Total Loss: 3.594329357147217 | KNN Loss: 3.5703771114349365 | CLS Loss: 0.02395213395357132\n",
      "Epoch 128 / 200 | iteration 100 / 171 | Total Loss: 3.6401803493499756 | KNN Loss: 3.625128984451294 | CLS Loss: 0.015051319263875484\n",
      "Epoch 128 / 200 | iteration 110 / 171 | Total Loss: 3.607334613800049 | KNN Loss: 3.6035189628601074 | CLS Loss: 0.0038157012313604355\n",
      "Epoch 128 / 200 | iteration 120 / 171 | Total Loss: 3.5840699672698975 | KNN Loss: 3.5746452808380127 | CLS Loss: 0.00942468736320734\n",
      "Epoch 128 / 200 | iteration 130 / 171 | Total Loss: 3.640934944152832 | KNN Loss: 3.628664016723633 | CLS Loss: 0.012271000072360039\n",
      "Epoch 128 / 200 | iteration 140 / 171 | Total Loss: 3.6413321495056152 | KNN Loss: 3.6285400390625 | CLS Loss: 0.012792135588824749\n",
      "Epoch 128 / 200 | iteration 150 / 171 | Total Loss: 3.6458077430725098 | KNN Loss: 3.640223503112793 | CLS Loss: 0.0055841365829110146\n",
      "Epoch 128 / 200 | iteration 160 / 171 | Total Loss: 3.661891222000122 | KNN Loss: 3.6566874980926514 | CLS Loss: 0.005203659180551767\n",
      "Epoch 128 / 200 | iteration 170 / 171 | Total Loss: 3.640660047531128 | KNN Loss: 3.630049705505371 | CLS Loss: 0.010610230267047882\n",
      "Epoch: 128, Loss: 3.6157, Train: 0.9962, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 129 / 200 | iteration 0 / 171 | Total Loss: 3.6609184741973877 | KNN Loss: 3.6367998123168945 | CLS Loss: 0.024118773639202118\n",
      "Epoch 129 / 200 | iteration 10 / 171 | Total Loss: 3.593080997467041 | KNN Loss: 3.5895938873291016 | CLS Loss: 0.0034870512317866087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 / 200 | iteration 20 / 171 | Total Loss: 3.591430902481079 | KNN Loss: 3.588898181915283 | CLS Loss: 0.002532710786908865\n",
      "Epoch 129 / 200 | iteration 30 / 171 | Total Loss: 3.6317508220672607 | KNN Loss: 3.6221466064453125 | CLS Loss: 0.009604228660464287\n",
      "Epoch 129 / 200 | iteration 40 / 171 | Total Loss: 3.6359524726867676 | KNN Loss: 3.6015257835388184 | CLS Loss: 0.034426577389240265\n",
      "Epoch 129 / 200 | iteration 50 / 171 | Total Loss: 3.6138741970062256 | KNN Loss: 3.589832305908203 | CLS Loss: 0.0240419190376997\n",
      "Epoch 129 / 200 | iteration 60 / 171 | Total Loss: 3.5843639373779297 | KNN Loss: 3.5764667987823486 | CLS Loss: 0.007897049188613892\n",
      "Epoch 129 / 200 | iteration 70 / 171 | Total Loss: 3.5820722579956055 | KNN Loss: 3.5799121856689453 | CLS Loss: 0.0021600862964987755\n",
      "Epoch 129 / 200 | iteration 80 / 171 | Total Loss: 3.603118419647217 | KNN Loss: 3.5968575477600098 | CLS Loss: 0.006260890047997236\n",
      "Epoch 129 / 200 | iteration 90 / 171 | Total Loss: 3.623067855834961 | KNN Loss: 3.60595440864563 | CLS Loss: 0.01711345836520195\n",
      "Epoch 129 / 200 | iteration 100 / 171 | Total Loss: 3.636575698852539 | KNN Loss: 3.622349739074707 | CLS Loss: 0.014226018451154232\n",
      "Epoch 129 / 200 | iteration 110 / 171 | Total Loss: 3.5908026695251465 | KNN Loss: 3.5713868141174316 | CLS Loss: 0.01941584423184395\n",
      "Epoch 129 / 200 | iteration 120 / 171 | Total Loss: 3.675065755844116 | KNN Loss: 3.6692020893096924 | CLS Loss: 0.005863559897989035\n",
      "Epoch 129 / 200 | iteration 130 / 171 | Total Loss: 3.6059908866882324 | KNN Loss: 3.5919318199157715 | CLS Loss: 0.01405895035713911\n",
      "Epoch 129 / 200 | iteration 140 / 171 | Total Loss: 3.6689488887786865 | KNN Loss: 3.6408681869506836 | CLS Loss: 0.028080597519874573\n",
      "Epoch 129 / 200 | iteration 150 / 171 | Total Loss: 3.6264092922210693 | KNN Loss: 3.6206235885620117 | CLS Loss: 0.0057857888750731945\n",
      "Epoch 129 / 200 | iteration 160 / 171 | Total Loss: 3.594362497329712 | KNN Loss: 3.5778439044952393 | CLS Loss: 0.01651863567531109\n",
      "Epoch 129 / 200 | iteration 170 / 171 | Total Loss: 3.6167068481445312 | KNN Loss: 3.605372905731201 | CLS Loss: 0.011333928443491459\n",
      "Epoch: 129, Loss: 3.6190, Train: 0.9954, Valid: 0.9855, Best: 0.9881\n",
      "Epoch 130 / 200 | iteration 0 / 171 | Total Loss: 3.61745023727417 | KNN Loss: 3.6016557216644287 | CLS Loss: 0.015794625505805016\n",
      "Epoch 130 / 200 | iteration 10 / 171 | Total Loss: 3.6749515533447266 | KNN Loss: 3.663677453994751 | CLS Loss: 0.011274105869233608\n",
      "Epoch 130 / 200 | iteration 20 / 171 | Total Loss: 3.6636462211608887 | KNN Loss: 3.6415517330169678 | CLS Loss: 0.02209451235830784\n",
      "Epoch 130 / 200 | iteration 30 / 171 | Total Loss: 3.6195406913757324 | KNN Loss: 3.608956813812256 | CLS Loss: 0.010583980940282345\n",
      "Epoch 130 / 200 | iteration 40 / 171 | Total Loss: 3.621864080429077 | KNN Loss: 3.611538887023926 | CLS Loss: 0.010325195267796516\n",
      "Epoch 130 / 200 | iteration 50 / 171 | Total Loss: 3.637611150741577 | KNN Loss: 3.625551700592041 | CLS Loss: 0.012059531174600124\n",
      "Epoch 130 / 200 | iteration 60 / 171 | Total Loss: 3.624873638153076 | KNN Loss: 3.600045680999756 | CLS Loss: 0.024827901273965836\n",
      "Epoch 130 / 200 | iteration 70 / 171 | Total Loss: 3.6378846168518066 | KNN Loss: 3.6314263343811035 | CLS Loss: 0.006458269897848368\n",
      "Epoch 130 / 200 | iteration 80 / 171 | Total Loss: 3.606727361679077 | KNN Loss: 3.5955398082733154 | CLS Loss: 0.01118756178766489\n",
      "Epoch 130 / 200 | iteration 90 / 171 | Total Loss: 3.628150463104248 | KNN Loss: 3.616954803466797 | CLS Loss: 0.011195666156709194\n",
      "Epoch 130 / 200 | iteration 100 / 171 | Total Loss: 3.5989034175872803 | KNN Loss: 3.595344305038452 | CLS Loss: 0.0035592298954725266\n",
      "Epoch 130 / 200 | iteration 110 / 171 | Total Loss: 3.626582384109497 | KNN Loss: 3.616600275039673 | CLS Loss: 0.00998220220208168\n",
      "Epoch 130 / 200 | iteration 120 / 171 | Total Loss: 3.62971568107605 | KNN Loss: 3.605217933654785 | CLS Loss: 0.024497725069522858\n",
      "Epoch 130 / 200 | iteration 130 / 171 | Total Loss: 3.610121011734009 | KNN Loss: 3.5893971920013428 | CLS Loss: 0.020723747089505196\n",
      "Epoch 130 / 200 | iteration 140 / 171 | Total Loss: 3.5864603519439697 | KNN Loss: 3.585432291030884 | CLS Loss: 0.0010281639406457543\n",
      "Epoch 130 / 200 | iteration 150 / 171 | Total Loss: 3.6035192012786865 | KNN Loss: 3.5951099395751953 | CLS Loss: 0.008409188129007816\n",
      "Epoch 130 / 200 | iteration 160 / 171 | Total Loss: 3.688728094100952 | KNN Loss: 3.6720101833343506 | CLS Loss: 0.0167178213596344\n",
      "Epoch 130 / 200 | iteration 170 / 171 | Total Loss: 3.6788299083709717 | KNN Loss: 3.6735875606536865 | CLS Loss: 0.005242330953478813\n",
      "Epoch: 130, Loss: 3.6255, Train: 0.9955, Valid: 0.9862, Best: 0.9881\n",
      "Epoch 131 / 200 | iteration 0 / 171 | Total Loss: 3.624347448348999 | KNN Loss: 3.608926296234131 | CLS Loss: 0.01542107854038477\n",
      "Epoch 131 / 200 | iteration 10 / 171 | Total Loss: 3.6316041946411133 | KNN Loss: 3.622811794281006 | CLS Loss: 0.008792363107204437\n",
      "Epoch 131 / 200 | iteration 20 / 171 | Total Loss: 3.6230413913726807 | KNN Loss: 3.616483688354492 | CLS Loss: 0.006557646207511425\n",
      "Epoch 131 / 200 | iteration 30 / 171 | Total Loss: 3.596069574356079 | KNN Loss: 3.585702419281006 | CLS Loss: 0.010367108508944511\n",
      "Epoch 131 / 200 | iteration 40 / 171 | Total Loss: 3.6065304279327393 | KNN Loss: 3.590604066848755 | CLS Loss: 0.01592637039721012\n",
      "Epoch 131 / 200 | iteration 50 / 171 | Total Loss: 3.6023495197296143 | KNN Loss: 3.593212366104126 | CLS Loss: 0.009137089364230633\n",
      "Epoch 131 / 200 | iteration 60 / 171 | Total Loss: 3.614924669265747 | KNN Loss: 3.6111299991607666 | CLS Loss: 0.0037946784868836403\n",
      "Epoch 131 / 200 | iteration 70 / 171 | Total Loss: 3.5943026542663574 | KNN Loss: 3.587705612182617 | CLS Loss: 0.006597157567739487\n",
      "Epoch 131 / 200 | iteration 80 / 171 | Total Loss: 3.6052396297454834 | KNN Loss: 3.5891785621643066 | CLS Loss: 0.01606108993291855\n",
      "Epoch 131 / 200 | iteration 90 / 171 | Total Loss: 3.599956750869751 | KNN Loss: 3.5753259658813477 | CLS Loss: 0.024630853906273842\n",
      "Epoch 131 / 200 | iteration 100 / 171 | Total Loss: 3.635664701461792 | KNN Loss: 3.6145472526550293 | CLS Loss: 0.02111745811998844\n",
      "Epoch 131 / 200 | iteration 110 / 171 | Total Loss: 3.6322081089019775 | KNN Loss: 3.6157915592193604 | CLS Loss: 0.016416558995842934\n",
      "Epoch 131 / 200 | iteration 120 / 171 | Total Loss: 3.625683069229126 | KNN Loss: 3.6174511909484863 | CLS Loss: 0.00823194906115532\n",
      "Epoch 131 / 200 | iteration 130 / 171 | Total Loss: 3.6090750694274902 | KNN Loss: 3.5862832069396973 | CLS Loss: 0.022791853174567223\n",
      "Epoch 131 / 200 | iteration 140 / 171 | Total Loss: 3.606410026550293 | KNN Loss: 3.576702356338501 | CLS Loss: 0.029707761481404305\n",
      "Epoch 131 / 200 | iteration 150 / 171 | Total Loss: 3.642092227935791 | KNN Loss: 3.6360421180725098 | CLS Loss: 0.006050139665603638\n",
      "Epoch 131 / 200 | iteration 160 / 171 | Total Loss: 3.6374123096466064 | KNN Loss: 3.6340301036834717 | CLS Loss: 0.0033821375109255314\n",
      "Epoch 131 / 200 | iteration 170 / 171 | Total Loss: 3.603569746017456 | KNN Loss: 3.593796491622925 | CLS Loss: 0.009773275814950466\n",
      "Epoch: 131, Loss: 3.6174, Train: 0.9968, Valid: 0.9872, Best: 0.9881\n",
      "Epoch 132 / 200 | iteration 0 / 171 | Total Loss: 3.615658760070801 | KNN Loss: 3.608381986618042 | CLS Loss: 0.007276873104274273\n",
      "Epoch 132 / 200 | iteration 10 / 171 | Total Loss: 3.6268999576568604 | KNN Loss: 3.6067686080932617 | CLS Loss: 0.020131314173340797\n",
      "Epoch 132 / 200 | iteration 20 / 171 | Total Loss: 3.5963408946990967 | KNN Loss: 3.5890567302703857 | CLS Loss: 0.007284262683242559\n",
      "Epoch 132 / 200 | iteration 30 / 171 | Total Loss: 3.578343629837036 | KNN Loss: 3.5747227668762207 | CLS Loss: 0.003620776114985347\n",
      "Epoch 132 / 200 | iteration 40 / 171 | Total Loss: 3.596740961074829 | KNN Loss: 3.593242883682251 | CLS Loss: 0.0034980583004653454\n",
      "Epoch 132 / 200 | iteration 50 / 171 | Total Loss: 3.629932165145874 | KNN Loss: 3.6230921745300293 | CLS Loss: 0.006840010639280081\n",
      "Epoch 132 / 200 | iteration 60 / 171 | Total Loss: 3.6058576107025146 | KNN Loss: 3.5950980186462402 | CLS Loss: 0.010759648866951466\n",
      "Epoch 132 / 200 | iteration 70 / 171 | Total Loss: 3.6066017150878906 | KNN Loss: 3.5842092037200928 | CLS Loss: 0.022392574697732925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 / 200 | iteration 80 / 171 | Total Loss: 3.59708571434021 | KNN Loss: 3.5937249660491943 | CLS Loss: 0.0033608004450798035\n",
      "Epoch 132 / 200 | iteration 90 / 171 | Total Loss: 3.5914409160614014 | KNN Loss: 3.5786988735198975 | CLS Loss: 0.012742137536406517\n",
      "Epoch 132 / 200 | iteration 100 / 171 | Total Loss: 3.60382080078125 | KNN Loss: 3.573345899581909 | CLS Loss: 0.030475009232759476\n",
      "Epoch 132 / 200 | iteration 110 / 171 | Total Loss: 3.574259042739868 | KNN Loss: 3.5666537284851074 | CLS Loss: 0.007605295162647963\n",
      "Epoch 132 / 200 | iteration 120 / 171 | Total Loss: 3.590351104736328 | KNN Loss: 3.582319498062134 | CLS Loss: 0.008031499572098255\n",
      "Epoch 132 / 200 | iteration 130 / 171 | Total Loss: 3.5852653980255127 | KNN Loss: 3.574251890182495 | CLS Loss: 0.01101356465369463\n",
      "Epoch 132 / 200 | iteration 140 / 171 | Total Loss: 3.619638204574585 | KNN Loss: 3.5997350215911865 | CLS Loss: 0.019903244450688362\n",
      "Epoch 132 / 200 | iteration 150 / 171 | Total Loss: 3.7050676345825195 | KNN Loss: 3.6925342082977295 | CLS Loss: 0.012533478438854218\n",
      "Epoch 132 / 200 | iteration 160 / 171 | Total Loss: 3.5974371433258057 | KNN Loss: 3.5832865238189697 | CLS Loss: 0.014150610193610191\n",
      "Epoch 132 / 200 | iteration 170 / 171 | Total Loss: 3.5973246097564697 | KNN Loss: 3.592449903488159 | CLS Loss: 0.004874724894762039\n",
      "Epoch: 132, Loss: 3.6129, Train: 0.9970, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 133 / 200 | iteration 0 / 171 | Total Loss: 3.617957353591919 | KNN Loss: 3.6073055267333984 | CLS Loss: 0.010651771910488605\n",
      "Epoch 133 / 200 | iteration 10 / 171 | Total Loss: 3.6538500785827637 | KNN Loss: 3.644589900970459 | CLS Loss: 0.00926019437611103\n",
      "Epoch 133 / 200 | iteration 20 / 171 | Total Loss: 3.6291537284851074 | KNN Loss: 3.6068902015686035 | CLS Loss: 0.02226349338889122\n",
      "Epoch 133 / 200 | iteration 30 / 171 | Total Loss: 3.6015446186065674 | KNN Loss: 3.593663215637207 | CLS Loss: 0.007881512865424156\n",
      "Epoch 133 / 200 | iteration 40 / 171 | Total Loss: 3.625446319580078 | KNN Loss: 3.6025421619415283 | CLS Loss: 0.022904131561517715\n",
      "Epoch 133 / 200 | iteration 50 / 171 | Total Loss: 3.641167640686035 | KNN Loss: 3.6021337509155273 | CLS Loss: 0.039033807814121246\n",
      "Epoch 133 / 200 | iteration 60 / 171 | Total Loss: 3.57460880279541 | KNN Loss: 3.5604300498962402 | CLS Loss: 0.014178737998008728\n",
      "Epoch 133 / 200 | iteration 70 / 171 | Total Loss: 3.6143815517425537 | KNN Loss: 3.60807466506958 | CLS Loss: 0.006306942086666822\n",
      "Epoch 133 / 200 | iteration 80 / 171 | Total Loss: 3.5944621562957764 | KNN Loss: 3.571465492248535 | CLS Loss: 0.022996600717306137\n",
      "Epoch 133 / 200 | iteration 90 / 171 | Total Loss: 3.581653594970703 | KNN Loss: 3.5734143257141113 | CLS Loss: 0.008239293470978737\n",
      "Epoch 133 / 200 | iteration 100 / 171 | Total Loss: 3.610206127166748 | KNN Loss: 3.6041259765625 | CLS Loss: 0.006080179009586573\n",
      "Epoch 133 / 200 | iteration 110 / 171 | Total Loss: 3.634859800338745 | KNN Loss: 3.629650592803955 | CLS Loss: 0.005209245253354311\n",
      "Epoch 133 / 200 | iteration 120 / 171 | Total Loss: 3.615487813949585 | KNN Loss: 3.60932993888855 | CLS Loss: 0.0061578406020998955\n",
      "Epoch 133 / 200 | iteration 130 / 171 | Total Loss: 3.6242713928222656 | KNN Loss: 3.5997767448425293 | CLS Loss: 0.024494593963027\n",
      "Epoch 133 / 200 | iteration 140 / 171 | Total Loss: 3.608858823776245 | KNN Loss: 3.5886433124542236 | CLS Loss: 0.020215613767504692\n",
      "Epoch 133 / 200 | iteration 150 / 171 | Total Loss: 3.6095690727233887 | KNN Loss: 3.6026017665863037 | CLS Loss: 0.006967349909245968\n",
      "Epoch 133 / 200 | iteration 160 / 171 | Total Loss: 3.6701276302337646 | KNN Loss: 3.647364854812622 | CLS Loss: 0.022762713953852654\n",
      "Epoch 133 / 200 | iteration 170 / 171 | Total Loss: 3.574369192123413 | KNN Loss: 3.5580592155456543 | CLS Loss: 0.016309918835759163\n",
      "Epoch: 133, Loss: 3.6125, Train: 0.9977, Valid: 0.9869, Best: 0.9881\n",
      "Epoch 134 / 200 | iteration 0 / 171 | Total Loss: 3.61460280418396 | KNN Loss: 3.612643003463745 | CLS Loss: 0.001959815388545394\n",
      "Epoch 134 / 200 | iteration 10 / 171 | Total Loss: 3.6125235557556152 | KNN Loss: 3.592118501663208 | CLS Loss: 0.020405033603310585\n",
      "Epoch 134 / 200 | iteration 20 / 171 | Total Loss: 3.58355712890625 | KNN Loss: 3.564440965652466 | CLS Loss: 0.01911616325378418\n",
      "Epoch 134 / 200 | iteration 30 / 171 | Total Loss: 3.612078905105591 | KNN Loss: 3.579179286956787 | CLS Loss: 0.032899707555770874\n",
      "Epoch 134 / 200 | iteration 40 / 171 | Total Loss: 3.604830265045166 | KNN Loss: 3.6030466556549072 | CLS Loss: 0.0017836426850408316\n",
      "Epoch 134 / 200 | iteration 50 / 171 | Total Loss: 3.593517541885376 | KNN Loss: 3.5762434005737305 | CLS Loss: 0.017274213954806328\n",
      "Epoch 134 / 200 | iteration 60 / 171 | Total Loss: 3.634066581726074 | KNN Loss: 3.6047778129577637 | CLS Loss: 0.02928883023560047\n",
      "Epoch 134 / 200 | iteration 70 / 171 | Total Loss: 3.623465061187744 | KNN Loss: 3.6105778217315674 | CLS Loss: 0.012887298129498959\n",
      "Epoch 134 / 200 | iteration 80 / 171 | Total Loss: 3.605024576187134 | KNN Loss: 3.5988857746124268 | CLS Loss: 0.0061386930756270885\n",
      "Epoch 134 / 200 | iteration 90 / 171 | Total Loss: 3.621220827102661 | KNN Loss: 3.6090891361236572 | CLS Loss: 0.012131699360907078\n",
      "Epoch 134 / 200 | iteration 100 / 171 | Total Loss: 3.6488518714904785 | KNN Loss: 3.642486572265625 | CLS Loss: 0.006365208886563778\n",
      "Epoch 134 / 200 | iteration 110 / 171 | Total Loss: 3.5973520278930664 | KNN Loss: 3.5857739448547363 | CLS Loss: 0.011578081175684929\n",
      "Epoch 134 / 200 | iteration 120 / 171 | Total Loss: 3.6049489974975586 | KNN Loss: 3.604336977005005 | CLS Loss: 0.0006120015750639141\n",
      "Epoch 134 / 200 | iteration 130 / 171 | Total Loss: 3.607271909713745 | KNN Loss: 3.602530002593994 | CLS Loss: 0.004741880111396313\n",
      "Epoch 134 / 200 | iteration 140 / 171 | Total Loss: 3.5985007286071777 | KNN Loss: 3.595709800720215 | CLS Loss: 0.0027909711934626102\n",
      "Epoch 134 / 200 | iteration 150 / 171 | Total Loss: 3.5966951847076416 | KNN Loss: 3.574254035949707 | CLS Loss: 0.022441145032644272\n",
      "Epoch 134 / 200 | iteration 160 / 171 | Total Loss: 3.609450578689575 | KNN Loss: 3.5951526165008545 | CLS Loss: 0.014297996647655964\n",
      "Epoch 134 / 200 | iteration 170 / 171 | Total Loss: 3.608351469039917 | KNN Loss: 3.588684558868408 | CLS Loss: 0.019666844978928566\n",
      "Epoch: 134, Loss: 3.6086, Train: 0.9974, Valid: 0.9865, Best: 0.9881\n",
      "Epoch 135 / 200 | iteration 0 / 171 | Total Loss: 3.5780467987060547 | KNN Loss: 3.5743372440338135 | CLS Loss: 0.0037095393054187298\n",
      "Epoch 135 / 200 | iteration 10 / 171 | Total Loss: 3.574120283126831 | KNN Loss: 3.568246603012085 | CLS Loss: 0.0058736735954880714\n",
      "Epoch 135 / 200 | iteration 20 / 171 | Total Loss: 3.624246597290039 | KNN Loss: 3.621769428253174 | CLS Loss: 0.0024771192111074924\n",
      "Epoch 135 / 200 | iteration 30 / 171 | Total Loss: 3.6048660278320312 | KNN Loss: 3.5970468521118164 | CLS Loss: 0.007819143123924732\n",
      "Epoch 135 / 200 | iteration 40 / 171 | Total Loss: 3.652371883392334 | KNN Loss: 3.6136581897735596 | CLS Loss: 0.038713645190000534\n",
      "Epoch 135 / 200 | iteration 50 / 171 | Total Loss: 3.6096129417419434 | KNN Loss: 3.5977272987365723 | CLS Loss: 0.011885523796081543\n",
      "Epoch 135 / 200 | iteration 60 / 171 | Total Loss: 3.607830762863159 | KNN Loss: 3.5834362506866455 | CLS Loss: 0.024394448846578598\n",
      "Epoch 135 / 200 | iteration 70 / 171 | Total Loss: 3.645420551300049 | KNN Loss: 3.6196460723876953 | CLS Loss: 0.02577447146177292\n",
      "Epoch 135 / 200 | iteration 80 / 171 | Total Loss: 3.6055970191955566 | KNN Loss: 3.5930445194244385 | CLS Loss: 0.012552562169730663\n",
      "Epoch 135 / 200 | iteration 90 / 171 | Total Loss: 3.598068952560425 | KNN Loss: 3.594360589981079 | CLS Loss: 0.00370843056589365\n",
      "Epoch 135 / 200 | iteration 100 / 171 | Total Loss: 3.5862488746643066 | KNN Loss: 3.572361707687378 | CLS Loss: 0.013887109234929085\n",
      "Epoch 135 / 200 | iteration 110 / 171 | Total Loss: 3.5971877574920654 | KNN Loss: 3.589718818664551 | CLS Loss: 0.007468968164175749\n",
      "Epoch 135 / 200 | iteration 120 / 171 | Total Loss: 3.6294407844543457 | KNN Loss: 3.619516134262085 | CLS Loss: 0.00992463156580925\n",
      "Epoch 135 / 200 | iteration 130 / 171 | Total Loss: 3.5905535221099854 | KNN Loss: 3.5831596851348877 | CLS Loss: 0.007393718231469393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 / 200 | iteration 140 / 171 | Total Loss: 3.638998508453369 | KNN Loss: 3.6181862354278564 | CLS Loss: 0.02081228606402874\n",
      "Epoch 135 / 200 | iteration 150 / 171 | Total Loss: 3.6016907691955566 | KNN Loss: 3.5941572189331055 | CLS Loss: 0.007533504161983728\n",
      "Epoch 135 / 200 | iteration 160 / 171 | Total Loss: 3.614584445953369 | KNN Loss: 3.601925849914551 | CLS Loss: 0.012658597901463509\n",
      "Epoch 135 / 200 | iteration 170 / 171 | Total Loss: 3.588029623031616 | KNN Loss: 3.5850725173950195 | CLS Loss: 0.002957066288217902\n",
      "Epoch: 135, Loss: 3.6185, Train: 0.9970, Valid: 0.9866, Best: 0.9881\n",
      "Epoch 136 / 200 | iteration 0 / 171 | Total Loss: 3.635249137878418 | KNN Loss: 3.632143497467041 | CLS Loss: 0.003105557058006525\n",
      "Epoch 136 / 200 | iteration 10 / 171 | Total Loss: 3.5765738487243652 | KNN Loss: 3.5744457244873047 | CLS Loss: 0.0021280148066580296\n",
      "Epoch 136 / 200 | iteration 20 / 171 | Total Loss: 3.6222288608551025 | KNN Loss: 3.6037158966064453 | CLS Loss: 0.0185129065066576\n",
      "Epoch 136 / 200 | iteration 30 / 171 | Total Loss: 3.612175703048706 | KNN Loss: 3.604515314102173 | CLS Loss: 0.007660417817533016\n",
      "Epoch 136 / 200 | iteration 40 / 171 | Total Loss: 3.6040170192718506 | KNN Loss: 3.598559617996216 | CLS Loss: 0.005457442253828049\n",
      "Epoch 136 / 200 | iteration 50 / 171 | Total Loss: 3.5598912239074707 | KNN Loss: 3.551069736480713 | CLS Loss: 0.008821394294500351\n",
      "Epoch 136 / 200 | iteration 60 / 171 | Total Loss: 3.59962797164917 | KNN Loss: 3.586564302444458 | CLS Loss: 0.013063651509582996\n",
      "Epoch 136 / 200 | iteration 70 / 171 | Total Loss: 3.622291326522827 | KNN Loss: 3.598400115966797 | CLS Loss: 0.023891227319836617\n",
      "Epoch 136 / 200 | iteration 80 / 171 | Total Loss: 3.6160666942596436 | KNN Loss: 3.611682415008545 | CLS Loss: 0.004384166095405817\n",
      "Epoch 136 / 200 | iteration 90 / 171 | Total Loss: 3.5761048793792725 | KNN Loss: 3.5659334659576416 | CLS Loss: 0.010171479545533657\n",
      "Epoch 136 / 200 | iteration 100 / 171 | Total Loss: 3.5717716217041016 | KNN Loss: 3.566281795501709 | CLS Loss: 0.005489910487085581\n",
      "Epoch 136 / 200 | iteration 110 / 171 | Total Loss: 3.5908470153808594 | KNN Loss: 3.5681002140045166 | CLS Loss: 0.022746896371245384\n",
      "Epoch 136 / 200 | iteration 120 / 171 | Total Loss: 3.6292741298675537 | KNN Loss: 3.6129276752471924 | CLS Loss: 0.016346396878361702\n",
      "Epoch 136 / 200 | iteration 130 / 171 | Total Loss: 3.596447706222534 | KNN Loss: 3.5873427391052246 | CLS Loss: 0.009104917757213116\n",
      "Epoch 136 / 200 | iteration 140 / 171 | Total Loss: 3.5947203636169434 | KNN Loss: 3.589486598968506 | CLS Loss: 0.005233750678598881\n",
      "Epoch 136 / 200 | iteration 150 / 171 | Total Loss: 3.5771210193634033 | KNN Loss: 3.5749566555023193 | CLS Loss: 0.002164265839383006\n",
      "Epoch 136 / 200 | iteration 160 / 171 | Total Loss: 3.6100146770477295 | KNN Loss: 3.605928421020508 | CLS Loss: 0.004086186643689871\n",
      "Epoch 136 / 200 | iteration 170 / 171 | Total Loss: 3.6138198375701904 | KNN Loss: 3.6118366718292236 | CLS Loss: 0.001983078895136714\n",
      "Epoch: 136, Loss: 3.6123, Train: 0.9963, Valid: 0.9868, Best: 0.9881\n",
      "Epoch 137 / 200 | iteration 0 / 171 | Total Loss: 3.5994858741760254 | KNN Loss: 3.588216543197632 | CLS Loss: 0.011269250884652138\n",
      "Epoch 137 / 200 | iteration 10 / 171 | Total Loss: 3.6137101650238037 | KNN Loss: 3.6040170192718506 | CLS Loss: 0.009693103842437267\n",
      "Epoch 137 / 200 | iteration 20 / 171 | Total Loss: 3.6199426651000977 | KNN Loss: 3.61549711227417 | CLS Loss: 0.004445606376975775\n",
      "Epoch 137 / 200 | iteration 30 / 171 | Total Loss: 3.585195302963257 | KNN Loss: 3.5770061016082764 | CLS Loss: 0.008189177140593529\n",
      "Epoch 137 / 200 | iteration 40 / 171 | Total Loss: 3.60128116607666 | KNN Loss: 3.5727856159210205 | CLS Loss: 0.0284956693649292\n",
      "Epoch 137 / 200 | iteration 50 / 171 | Total Loss: 3.628084182739258 | KNN Loss: 3.6186330318450928 | CLS Loss: 0.009451188147068024\n",
      "Epoch 137 / 200 | iteration 60 / 171 | Total Loss: 3.5949716567993164 | KNN Loss: 3.574516534805298 | CLS Loss: 0.020455220714211464\n",
      "Epoch 137 / 200 | iteration 70 / 171 | Total Loss: 3.5972933769226074 | KNN Loss: 3.590904951095581 | CLS Loss: 0.006388475187122822\n",
      "Epoch 137 / 200 | iteration 80 / 171 | Total Loss: 3.599958658218384 | KNN Loss: 3.5938117504119873 | CLS Loss: 0.006146852858364582\n",
      "Epoch 137 / 200 | iteration 90 / 171 | Total Loss: 3.6043543815612793 | KNN Loss: 3.5983829498291016 | CLS Loss: 0.005971332546323538\n",
      "Epoch 137 / 200 | iteration 100 / 171 | Total Loss: 3.6080212593078613 | KNN Loss: 3.5950114727020264 | CLS Loss: 0.01300972979515791\n",
      "Epoch 137 / 200 | iteration 110 / 171 | Total Loss: 3.624677896499634 | KNN Loss: 3.604987144470215 | CLS Loss: 0.019690651446580887\n",
      "Epoch 137 / 200 | iteration 120 / 171 | Total Loss: 3.62095046043396 | KNN Loss: 3.6089928150177 | CLS Loss: 0.01195757370442152\n",
      "Epoch 137 / 200 | iteration 130 / 171 | Total Loss: 3.589592695236206 | KNN Loss: 3.582205057144165 | CLS Loss: 0.007387681398540735\n",
      "Epoch 137 / 200 | iteration 140 / 171 | Total Loss: 3.608785390853882 | KNN Loss: 3.585977554321289 | CLS Loss: 0.02280782163143158\n",
      "Epoch 137 / 200 | iteration 150 / 171 | Total Loss: 3.617779493331909 | KNN Loss: 3.603991985321045 | CLS Loss: 0.013787519186735153\n",
      "Epoch 137 / 200 | iteration 160 / 171 | Total Loss: 3.570143699645996 | KNN Loss: 3.5524322986602783 | CLS Loss: 0.017711343243718147\n",
      "Epoch 137 / 200 | iteration 170 / 171 | Total Loss: 3.6087918281555176 | KNN Loss: 3.5985829830169678 | CLS Loss: 0.010208802297711372\n",
      "Epoch: 137, Loss: 3.6149, Train: 0.9976, Valid: 0.9868, Best: 0.9881\n",
      "Epoch 138 / 200 | iteration 0 / 171 | Total Loss: 3.579392194747925 | KNN Loss: 3.57560396194458 | CLS Loss: 0.0037882388569414616\n",
      "Epoch 138 / 200 | iteration 10 / 171 | Total Loss: 3.6580822467803955 | KNN Loss: 3.651883602142334 | CLS Loss: 0.006198560819029808\n",
      "Epoch 138 / 200 | iteration 20 / 171 | Total Loss: 3.605761766433716 | KNN Loss: 3.599159002304077 | CLS Loss: 0.006602738052606583\n",
      "Epoch 138 / 200 | iteration 30 / 171 | Total Loss: 3.601783275604248 | KNN Loss: 3.5948596000671387 | CLS Loss: 0.006923649925738573\n",
      "Epoch 138 / 200 | iteration 40 / 171 | Total Loss: 3.620979070663452 | KNN Loss: 3.615285873413086 | CLS Loss: 0.005693246144801378\n",
      "Epoch 138 / 200 | iteration 50 / 171 | Total Loss: 3.618601083755493 | KNN Loss: 3.6059682369232178 | CLS Loss: 0.012632741592824459\n",
      "Epoch 138 / 200 | iteration 60 / 171 | Total Loss: 3.5896904468536377 | KNN Loss: 3.5852880477905273 | CLS Loss: 0.00440230593085289\n",
      "Epoch 138 / 200 | iteration 70 / 171 | Total Loss: 3.605381488800049 | KNN Loss: 3.6010658740997314 | CLS Loss: 0.004315658006817102\n",
      "Epoch 138 / 200 | iteration 80 / 171 | Total Loss: 3.59722900390625 | KNN Loss: 3.5947980880737305 | CLS Loss: 0.0024309461005032063\n",
      "Epoch 138 / 200 | iteration 90 / 171 | Total Loss: 3.619924306869507 | KNN Loss: 3.6087839603424072 | CLS Loss: 0.011140361428260803\n",
      "Epoch 138 / 200 | iteration 100 / 171 | Total Loss: 3.597092628479004 | KNN Loss: 3.583944797515869 | CLS Loss: 0.01314774714410305\n",
      "Epoch 138 / 200 | iteration 110 / 171 | Total Loss: 3.656538248062134 | KNN Loss: 3.6169612407684326 | CLS Loss: 0.039577048271894455\n",
      "Epoch 138 / 200 | iteration 120 / 171 | Total Loss: 3.5826256275177 | KNN Loss: 3.5738296508789062 | CLS Loss: 0.008796057663857937\n",
      "Epoch 138 / 200 | iteration 130 / 171 | Total Loss: 3.6238179206848145 | KNN Loss: 3.617307424545288 | CLS Loss: 0.00651047145947814\n",
      "Epoch 138 / 200 | iteration 140 / 171 | Total Loss: 3.6622745990753174 | KNN Loss: 3.656126022338867 | CLS Loss: 0.006148552056401968\n",
      "Epoch 138 / 200 | iteration 150 / 171 | Total Loss: 3.6000187397003174 | KNN Loss: 3.594273328781128 | CLS Loss: 0.0057454644702374935\n",
      "Epoch 138 / 200 | iteration 160 / 171 | Total Loss: 3.595458507537842 | KNN Loss: 3.581209182739258 | CLS Loss: 0.014249376952648163\n",
      "Epoch 138 / 200 | iteration 170 / 171 | Total Loss: 3.608604907989502 | KNN Loss: 3.6009786128997803 | CLS Loss: 0.007626182399690151\n",
      "Epoch: 138, Loss: 3.6074, Train: 0.9974, Valid: 0.9868, Best: 0.9881\n",
      "Epoch 139 / 200 | iteration 0 / 171 | Total Loss: 3.6817591190338135 | KNN Loss: 3.649430513381958 | CLS Loss: 0.032328587025403976\n",
      "Epoch 139 / 200 | iteration 10 / 171 | Total Loss: 3.6369335651397705 | KNN Loss: 3.6292455196380615 | CLS Loss: 0.007687997538596392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 / 200 | iteration 20 / 171 | Total Loss: 3.620741605758667 | KNN Loss: 3.610426664352417 | CLS Loss: 0.010314843617379665\n",
      "Epoch 139 / 200 | iteration 30 / 171 | Total Loss: 3.565764904022217 | KNN Loss: 3.558926582336426 | CLS Loss: 0.006838324014097452\n",
      "Epoch 139 / 200 | iteration 40 / 171 | Total Loss: 3.5933353900909424 | KNN Loss: 3.5923497676849365 | CLS Loss: 0.0009857024997472763\n",
      "Epoch 139 / 200 | iteration 50 / 171 | Total Loss: 3.6001458168029785 | KNN Loss: 3.5923349857330322 | CLS Loss: 0.0078109088353812695\n",
      "Epoch 139 / 200 | iteration 60 / 171 | Total Loss: 3.5672271251678467 | KNN Loss: 3.5647635459899902 | CLS Loss: 0.002463472541421652\n",
      "Epoch 139 / 200 | iteration 70 / 171 | Total Loss: 3.567338705062866 | KNN Loss: 3.559861660003662 | CLS Loss: 0.007477061823010445\n",
      "Epoch 139 / 200 | iteration 80 / 171 | Total Loss: 3.6141796112060547 | KNN Loss: 3.6078758239746094 | CLS Loss: 0.006303807720541954\n",
      "Epoch 139 / 200 | iteration 90 / 171 | Total Loss: 3.6710164546966553 | KNN Loss: 3.656677484512329 | CLS Loss: 0.01433893758803606\n",
      "Epoch 139 / 200 | iteration 100 / 171 | Total Loss: 3.586334705352783 | KNN Loss: 3.5699474811553955 | CLS Loss: 0.016387272626161575\n",
      "Epoch 139 / 200 | iteration 110 / 171 | Total Loss: 3.6089768409729004 | KNN Loss: 3.599235773086548 | CLS Loss: 0.009741038084030151\n",
      "Epoch 139 / 200 | iteration 120 / 171 | Total Loss: 3.5617270469665527 | KNN Loss: 3.5607969760894775 | CLS Loss: 0.0009301253012381494\n",
      "Epoch 139 / 200 | iteration 130 / 171 | Total Loss: 3.6180384159088135 | KNN Loss: 3.605142831802368 | CLS Loss: 0.01289566420018673\n",
      "Epoch 139 / 200 | iteration 140 / 171 | Total Loss: 3.5891454219818115 | KNN Loss: 3.584284782409668 | CLS Loss: 0.004860663786530495\n",
      "Epoch 139 / 200 | iteration 150 / 171 | Total Loss: 3.5744974613189697 | KNN Loss: 3.573042392730713 | CLS Loss: 0.001454991870559752\n",
      "Epoch 139 / 200 | iteration 160 / 171 | Total Loss: 3.612555503845215 | KNN Loss: 3.60636830329895 | CLS Loss: 0.0061871749348938465\n",
      "Epoch 139 / 200 | iteration 170 / 171 | Total Loss: 3.638218879699707 | KNN Loss: 3.625943183898926 | CLS Loss: 0.012275606393814087\n",
      "Epoch: 139, Loss: 3.6083, Train: 0.9963, Valid: 0.9869, Best: 0.9881\n",
      "Epoch 140 / 200 | iteration 0 / 171 | Total Loss: 3.730773687362671 | KNN Loss: 3.7137904167175293 | CLS Loss: 0.01698337122797966\n",
      "Epoch 140 / 200 | iteration 10 / 171 | Total Loss: 3.5961265563964844 | KNN Loss: 3.5809383392333984 | CLS Loss: 0.015188180841505527\n",
      "Epoch 140 / 200 | iteration 20 / 171 | Total Loss: 3.6617629528045654 | KNN Loss: 3.655479669570923 | CLS Loss: 0.006283373571932316\n",
      "Epoch 140 / 200 | iteration 30 / 171 | Total Loss: 3.6126794815063477 | KNN Loss: 3.601861000061035 | CLS Loss: 0.010818424634635448\n",
      "Epoch 140 / 200 | iteration 40 / 171 | Total Loss: 3.6037299633026123 | KNN Loss: 3.600461483001709 | CLS Loss: 0.0032684265170246363\n",
      "Epoch 140 / 200 | iteration 50 / 171 | Total Loss: 3.5850391387939453 | KNN Loss: 3.579684019088745 | CLS Loss: 0.005355190951377153\n",
      "Epoch 140 / 200 | iteration 60 / 171 | Total Loss: 3.5646250247955322 | KNN Loss: 3.559244155883789 | CLS Loss: 0.005380755756050348\n",
      "Epoch 140 / 200 | iteration 70 / 171 | Total Loss: 3.63622784614563 | KNN Loss: 3.6343014240264893 | CLS Loss: 0.0019264154834672809\n",
      "Epoch 140 / 200 | iteration 80 / 171 | Total Loss: 3.588822364807129 | KNN Loss: 3.5870251655578613 | CLS Loss: 0.001797147560864687\n",
      "Epoch 140 / 200 | iteration 90 / 171 | Total Loss: 3.6037352085113525 | KNN Loss: 3.6019365787506104 | CLS Loss: 0.0017986120656132698\n",
      "Epoch 140 / 200 | iteration 100 / 171 | Total Loss: 3.579451084136963 | KNN Loss: 3.5731751918792725 | CLS Loss: 0.006275895982980728\n",
      "Epoch 140 / 200 | iteration 110 / 171 | Total Loss: 3.6196634769439697 | KNN Loss: 3.614025115966797 | CLS Loss: 0.005638270638883114\n",
      "Epoch 140 / 200 | iteration 120 / 171 | Total Loss: 3.6261134147644043 | KNN Loss: 3.6175613403320312 | CLS Loss: 0.008551961742341518\n",
      "Epoch 140 / 200 | iteration 130 / 171 | Total Loss: 3.5957047939300537 | KNN Loss: 3.5924761295318604 | CLS Loss: 0.003228760790079832\n",
      "Epoch 140 / 200 | iteration 140 / 171 | Total Loss: 3.6115641593933105 | KNN Loss: 3.579360008239746 | CLS Loss: 0.032204095274209976\n",
      "Epoch 140 / 200 | iteration 150 / 171 | Total Loss: 3.6642305850982666 | KNN Loss: 3.644688844680786 | CLS Loss: 0.0195416621863842\n",
      "Epoch 140 / 200 | iteration 160 / 171 | Total Loss: 3.5703890323638916 | KNN Loss: 3.569340229034424 | CLS Loss: 0.001048737671226263\n",
      "Epoch 140 / 200 | iteration 170 / 171 | Total Loss: 3.5912492275238037 | KNN Loss: 3.5874571800231934 | CLS Loss: 0.0037919930182397366\n",
      "Epoch: 140, Loss: 3.6112, Train: 0.9973, Valid: 0.9873, Best: 0.9881\n",
      "Epoch 141 / 200 | iteration 0 / 171 | Total Loss: 3.607020616531372 | KNN Loss: 3.5995748043060303 | CLS Loss: 0.007445760536938906\n",
      "Epoch 141 / 200 | iteration 10 / 171 | Total Loss: 3.6232776641845703 | KNN Loss: 3.6185779571533203 | CLS Loss: 0.004699788521975279\n",
      "Epoch 141 / 200 | iteration 20 / 171 | Total Loss: 3.5685160160064697 | KNN Loss: 3.568010091781616 | CLS Loss: 0.0005059012910351157\n",
      "Epoch 141 / 200 | iteration 30 / 171 | Total Loss: 3.6761937141418457 | KNN Loss: 3.658083915710449 | CLS Loss: 0.018109695985913277\n",
      "Epoch 141 / 200 | iteration 40 / 171 | Total Loss: 3.5742504596710205 | KNN Loss: 3.571164846420288 | CLS Loss: 0.003085576230660081\n",
      "Epoch 141 / 200 | iteration 50 / 171 | Total Loss: 3.613020420074463 | KNN Loss: 3.6113171577453613 | CLS Loss: 0.0017033737385645509\n",
      "Epoch 141 / 200 | iteration 60 / 171 | Total Loss: 3.610886335372925 | KNN Loss: 3.5912227630615234 | CLS Loss: 0.01966349221765995\n",
      "Epoch 141 / 200 | iteration 70 / 171 | Total Loss: 3.60622239112854 | KNN Loss: 3.5912082195281982 | CLS Loss: 0.015014206059277058\n",
      "Epoch 141 / 200 | iteration 80 / 171 | Total Loss: 3.6119329929351807 | KNN Loss: 3.6007843017578125 | CLS Loss: 0.011148707941174507\n",
      "Epoch 141 / 200 | iteration 90 / 171 | Total Loss: 3.599522829055786 | KNN Loss: 3.593839406967163 | CLS Loss: 0.005683335941284895\n",
      "Epoch 141 / 200 | iteration 100 / 171 | Total Loss: 3.576917886734009 | KNN Loss: 3.5590264797210693 | CLS Loss: 0.01789146475493908\n",
      "Epoch 141 / 200 | iteration 110 / 171 | Total Loss: 3.5969607830047607 | KNN Loss: 3.5812387466430664 | CLS Loss: 0.01572207175195217\n",
      "Epoch 141 / 200 | iteration 120 / 171 | Total Loss: 3.6028800010681152 | KNN Loss: 3.6002426147460938 | CLS Loss: 0.002637340920045972\n",
      "Epoch 141 / 200 | iteration 130 / 171 | Total Loss: 3.5898966789245605 | KNN Loss: 3.5844779014587402 | CLS Loss: 0.005418894812464714\n",
      "Epoch 141 / 200 | iteration 140 / 171 | Total Loss: 3.573451519012451 | KNN Loss: 3.571739435195923 | CLS Loss: 0.001711965654976666\n",
      "Epoch 141 / 200 | iteration 150 / 171 | Total Loss: 3.5905044078826904 | KNN Loss: 3.583815574645996 | CLS Loss: 0.006688748020678759\n",
      "Epoch 141 / 200 | iteration 160 / 171 | Total Loss: 3.6100375652313232 | KNN Loss: 3.5956995487213135 | CLS Loss: 0.014337918721139431\n",
      "Epoch 141 / 200 | iteration 170 / 171 | Total Loss: 3.5941405296325684 | KNN Loss: 3.582090139389038 | CLS Loss: 0.012050372548401356\n",
      "Epoch: 141, Loss: 3.6082, Train: 0.9969, Valid: 0.9853, Best: 0.9881\n",
      "Epoch 142 / 200 | iteration 0 / 171 | Total Loss: 3.6175122261047363 | KNN Loss: 3.6095805168151855 | CLS Loss: 0.007931734435260296\n",
      "Epoch 142 / 200 | iteration 10 / 171 | Total Loss: 3.6063168048858643 | KNN Loss: 3.5930089950561523 | CLS Loss: 0.013307828456163406\n",
      "Epoch 142 / 200 | iteration 20 / 171 | Total Loss: 3.6471054553985596 | KNN Loss: 3.6390342712402344 | CLS Loss: 0.008071109652519226\n",
      "Epoch 142 / 200 | iteration 30 / 171 | Total Loss: 3.597285032272339 | KNN Loss: 3.584254741668701 | CLS Loss: 0.01303018070757389\n",
      "Epoch 142 / 200 | iteration 40 / 171 | Total Loss: 3.695047616958618 | KNN Loss: 3.628358840942383 | CLS Loss: 0.0666886642575264\n",
      "Epoch 142 / 200 | iteration 50 / 171 | Total Loss: 3.5965325832366943 | KNN Loss: 3.590592384338379 | CLS Loss: 0.00594014348462224\n",
      "Epoch 142 / 200 | iteration 60 / 171 | Total Loss: 3.6144301891326904 | KNN Loss: 3.6039319038391113 | CLS Loss: 0.010498245246708393\n",
      "Epoch 142 / 200 | iteration 70 / 171 | Total Loss: 3.6099722385406494 | KNN Loss: 3.6050033569335938 | CLS Loss: 0.004968823865056038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 / 200 | iteration 80 / 171 | Total Loss: 3.63802170753479 | KNN Loss: 3.6356401443481445 | CLS Loss: 0.002381605328992009\n",
      "Epoch 142 / 200 | iteration 90 / 171 | Total Loss: 3.6373796463012695 | KNN Loss: 3.6069679260253906 | CLS Loss: 0.030411651358008385\n",
      "Epoch 142 / 200 | iteration 100 / 171 | Total Loss: 3.617928981781006 | KNN Loss: 3.6127731800079346 | CLS Loss: 0.005155717954039574\n",
      "Epoch 142 / 200 | iteration 110 / 171 | Total Loss: 3.6379926204681396 | KNN Loss: 3.6239194869995117 | CLS Loss: 0.01407324057072401\n",
      "Epoch 142 / 200 | iteration 120 / 171 | Total Loss: 3.615962266921997 | KNN Loss: 3.6140403747558594 | CLS Loss: 0.001922010094858706\n",
      "Epoch 142 / 200 | iteration 130 / 171 | Total Loss: 3.6017777919769287 | KNN Loss: 3.5948679447174072 | CLS Loss: 0.006909769494086504\n",
      "Epoch 142 / 200 | iteration 140 / 171 | Total Loss: 3.6013970375061035 | KNN Loss: 3.599187135696411 | CLS Loss: 0.002209796104580164\n",
      "Epoch 142 / 200 | iteration 150 / 171 | Total Loss: 3.612819194793701 | KNN Loss: 3.5970444679260254 | CLS Loss: 0.01577472686767578\n",
      "Epoch 142 / 200 | iteration 160 / 171 | Total Loss: 3.5902628898620605 | KNN Loss: 3.5881597995758057 | CLS Loss: 0.002103150123730302\n",
      "Epoch 142 / 200 | iteration 170 / 171 | Total Loss: 3.6195249557495117 | KNN Loss: 3.603759527206421 | CLS Loss: 0.015765370801091194\n",
      "Epoch: 142, Loss: 3.6186, Train: 0.9970, Valid: 0.9869, Best: 0.9881\n",
      "Epoch 143 / 200 | iteration 0 / 171 | Total Loss: 3.6410229206085205 | KNN Loss: 3.6287002563476562 | CLS Loss: 0.012322758324444294\n",
      "Epoch 143 / 200 | iteration 10 / 171 | Total Loss: 3.699755907058716 | KNN Loss: 3.692488670349121 | CLS Loss: 0.007267241831868887\n",
      "Epoch 143 / 200 | iteration 20 / 171 | Total Loss: 3.5627286434173584 | KNN Loss: 3.5601963996887207 | CLS Loss: 0.0025322125293314457\n",
      "Epoch 143 / 200 | iteration 30 / 171 | Total Loss: 3.591134548187256 | KNN Loss: 3.5740654468536377 | CLS Loss: 0.017069028690457344\n",
      "Epoch 143 / 200 | iteration 40 / 171 | Total Loss: 3.566080093383789 | KNN Loss: 3.559238910675049 | CLS Loss: 0.006841232068836689\n",
      "Epoch 143 / 200 | iteration 50 / 171 | Total Loss: 3.6118719577789307 | KNN Loss: 3.5988945960998535 | CLS Loss: 0.012977279722690582\n",
      "Epoch 143 / 200 | iteration 60 / 171 | Total Loss: 3.57098650932312 | KNN Loss: 3.5562143325805664 | CLS Loss: 0.01477222889661789\n",
      "Epoch 143 / 200 | iteration 70 / 171 | Total Loss: 3.6316945552825928 | KNN Loss: 3.6125199794769287 | CLS Loss: 0.019174493849277496\n",
      "Epoch 143 / 200 | iteration 80 / 171 | Total Loss: 3.6056034564971924 | KNN Loss: 3.597907304763794 | CLS Loss: 0.007696081884205341\n",
      "Epoch 143 / 200 | iteration 90 / 171 | Total Loss: 3.6220145225524902 | KNN Loss: 3.603640556335449 | CLS Loss: 0.01837390661239624\n",
      "Epoch 143 / 200 | iteration 100 / 171 | Total Loss: 3.5934131145477295 | KNN Loss: 3.5895917415618896 | CLS Loss: 0.0038213443476706743\n",
      "Epoch 143 / 200 | iteration 110 / 171 | Total Loss: 3.59519362449646 | KNN Loss: 3.591029644012451 | CLS Loss: 0.00416395952925086\n",
      "Epoch 143 / 200 | iteration 120 / 171 | Total Loss: 3.6237761974334717 | KNN Loss: 3.6196398735046387 | CLS Loss: 0.004136343952268362\n",
      "Epoch 143 / 200 | iteration 130 / 171 | Total Loss: 3.603254795074463 | KNN Loss: 3.6006908416748047 | CLS Loss: 0.0025639364030212164\n",
      "Epoch 143 / 200 | iteration 140 / 171 | Total Loss: 3.604883909225464 | KNN Loss: 3.5979154109954834 | CLS Loss: 0.0069685038179159164\n",
      "Epoch 143 / 200 | iteration 150 / 171 | Total Loss: 3.6560451984405518 | KNN Loss: 3.6287410259246826 | CLS Loss: 0.027304166927933693\n",
      "Epoch 143 / 200 | iteration 160 / 171 | Total Loss: 3.6750147342681885 | KNN Loss: 3.6638851165771484 | CLS Loss: 0.01112968847155571\n",
      "Epoch 143 / 200 | iteration 170 / 171 | Total Loss: 3.6226179599761963 | KNN Loss: 3.6138837337493896 | CLS Loss: 0.008734150789678097\n",
      "Epoch: 143, Loss: 3.6196, Train: 0.9956, Valid: 0.9862, Best: 0.9881\n",
      "Epoch 144 / 200 | iteration 0 / 171 | Total Loss: 3.64617657661438 | KNN Loss: 3.61313533782959 | CLS Loss: 0.03304116800427437\n",
      "Epoch 144 / 200 | iteration 10 / 171 | Total Loss: 3.6504366397857666 | KNN Loss: 3.6132583618164062 | CLS Loss: 0.037178218364715576\n",
      "Epoch 144 / 200 | iteration 20 / 171 | Total Loss: 3.5874664783477783 | KNN Loss: 3.5792899131774902 | CLS Loss: 0.008176629431545734\n",
      "Epoch 144 / 200 | iteration 30 / 171 | Total Loss: 3.660595655441284 | KNN Loss: 3.659271001815796 | CLS Loss: 0.0013246189337223768\n",
      "Epoch 144 / 200 | iteration 40 / 171 | Total Loss: 3.5913639068603516 | KNN Loss: 3.586089611053467 | CLS Loss: 0.005274208262562752\n",
      "Epoch 144 / 200 | iteration 50 / 171 | Total Loss: 3.583261489868164 | KNN Loss: 3.5754506587982178 | CLS Loss: 0.007810754701495171\n",
      "Epoch 144 / 200 | iteration 60 / 171 | Total Loss: 3.6467034816741943 | KNN Loss: 3.626915216445923 | CLS Loss: 0.019788183271884918\n",
      "Epoch 144 / 200 | iteration 70 / 171 | Total Loss: 3.5844898223876953 | KNN Loss: 3.5806941986083984 | CLS Loss: 0.003795717377215624\n",
      "Epoch 144 / 200 | iteration 80 / 171 | Total Loss: 3.607707977294922 | KNN Loss: 3.6006298065185547 | CLS Loss: 0.0070781041868031025\n",
      "Epoch 144 / 200 | iteration 90 / 171 | Total Loss: 3.606276512145996 | KNN Loss: 3.6045901775360107 | CLS Loss: 0.0016863730270415545\n",
      "Epoch 144 / 200 | iteration 100 / 171 | Total Loss: 3.6034131050109863 | KNN Loss: 3.593477725982666 | CLS Loss: 0.00993544515222311\n",
      "Epoch 144 / 200 | iteration 110 / 171 | Total Loss: 3.5839953422546387 | KNN Loss: 3.5711400508880615 | CLS Loss: 0.012855305336415768\n",
      "Epoch 144 / 200 | iteration 120 / 171 | Total Loss: 3.5850508213043213 | KNN Loss: 3.570793628692627 | CLS Loss: 0.014257194474339485\n",
      "Epoch 144 / 200 | iteration 130 / 171 | Total Loss: 3.648918390274048 | KNN Loss: 3.6399545669555664 | CLS Loss: 0.00896374136209488\n",
      "Epoch 144 / 200 | iteration 140 / 171 | Total Loss: 3.601040840148926 | KNN Loss: 3.593580722808838 | CLS Loss: 0.007460029795765877\n",
      "Epoch 144 / 200 | iteration 150 / 171 | Total Loss: 3.6171364784240723 | KNN Loss: 3.5966122150421143 | CLS Loss: 0.02052430249750614\n",
      "Epoch 144 / 200 | iteration 160 / 171 | Total Loss: 3.595149517059326 | KNN Loss: 3.5928831100463867 | CLS Loss: 0.0022664284333586693\n",
      "Epoch 144 / 200 | iteration 170 / 171 | Total Loss: 3.5955731868743896 | KNN Loss: 3.5784785747528076 | CLS Loss: 0.017094582319259644\n",
      "Epoch: 144, Loss: 3.6126, Train: 0.9966, Valid: 0.9864, Best: 0.9881\n",
      "Epoch 145 / 200 | iteration 0 / 171 | Total Loss: 3.6519615650177 | KNN Loss: 3.6449129581451416 | CLS Loss: 0.007048586383461952\n",
      "Epoch 145 / 200 | iteration 10 / 171 | Total Loss: 3.6574556827545166 | KNN Loss: 3.640889883041382 | CLS Loss: 0.0165657140314579\n",
      "Epoch 145 / 200 | iteration 20 / 171 | Total Loss: 3.620980739593506 | KNN Loss: 3.6196742057800293 | CLS Loss: 0.0013065895764157176\n",
      "Epoch 145 / 200 | iteration 30 / 171 | Total Loss: 3.625260353088379 | KNN Loss: 3.6176180839538574 | CLS Loss: 0.007642342709004879\n",
      "Epoch 145 / 200 | iteration 40 / 171 | Total Loss: 3.6030499935150146 | KNN Loss: 3.600846529006958 | CLS Loss: 0.0022035345900803804\n",
      "Epoch 145 / 200 | iteration 50 / 171 | Total Loss: 3.6178994178771973 | KNN Loss: 3.6109938621520996 | CLS Loss: 0.006905656773597002\n",
      "Epoch 145 / 200 | iteration 60 / 171 | Total Loss: 3.609501838684082 | KNN Loss: 3.6033337116241455 | CLS Loss: 0.00616821926087141\n",
      "Epoch 145 / 200 | iteration 70 / 171 | Total Loss: 3.635162115097046 | KNN Loss: 3.6292779445648193 | CLS Loss: 0.005884230136871338\n",
      "Epoch 145 / 200 | iteration 80 / 171 | Total Loss: 3.5959949493408203 | KNN Loss: 3.5831854343414307 | CLS Loss: 0.012809629552066326\n",
      "Epoch 145 / 200 | iteration 90 / 171 | Total Loss: 3.579770088195801 | KNN Loss: 3.5717971324920654 | CLS Loss: 0.00797298364341259\n",
      "Epoch 145 / 200 | iteration 100 / 171 | Total Loss: 3.597743511199951 | KNN Loss: 3.5934031009674072 | CLS Loss: 0.004340465180575848\n",
      "Epoch 145 / 200 | iteration 110 / 171 | Total Loss: 3.606741428375244 | KNN Loss: 3.59775447845459 | CLS Loss: 0.00898691825568676\n",
      "Epoch 145 / 200 | iteration 120 / 171 | Total Loss: 3.6145026683807373 | KNN Loss: 3.603867292404175 | CLS Loss: 0.010635295882821083\n",
      "Epoch 145 / 200 | iteration 130 / 171 | Total Loss: 3.5994150638580322 | KNN Loss: 3.5763776302337646 | CLS Loss: 0.02303745038807392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 / 200 | iteration 140 / 171 | Total Loss: 3.619194746017456 | KNN Loss: 3.6101105213165283 | CLS Loss: 0.009084267541766167\n",
      "Epoch 145 / 200 | iteration 150 / 171 | Total Loss: 3.6200993061065674 | KNN Loss: 3.6127164363861084 | CLS Loss: 0.007382981013506651\n",
      "Epoch 145 / 200 | iteration 160 / 171 | Total Loss: 3.622480630874634 | KNN Loss: 3.5836446285247803 | CLS Loss: 0.03883596137166023\n",
      "Epoch 145 / 200 | iteration 170 / 171 | Total Loss: 3.6269521713256836 | KNN Loss: 3.595228672027588 | CLS Loss: 0.03172346577048302\n",
      "Epoch: 145, Loss: 3.6076, Train: 0.9959, Valid: 0.9855, Best: 0.9881\n",
      "Epoch 146 / 200 | iteration 0 / 171 | Total Loss: 3.5707640647888184 | KNN Loss: 3.543552875518799 | CLS Loss: 0.027211103588342667\n",
      "Epoch 146 / 200 | iteration 10 / 171 | Total Loss: 3.635529041290283 | KNN Loss: 3.628830909729004 | CLS Loss: 0.0066981082782149315\n",
      "Epoch 146 / 200 | iteration 20 / 171 | Total Loss: 3.6629738807678223 | KNN Loss: 3.6550395488739014 | CLS Loss: 0.007934286259114742\n",
      "Epoch 146 / 200 | iteration 30 / 171 | Total Loss: 3.6738977432250977 | KNN Loss: 3.6337761878967285 | CLS Loss: 0.040121618658304214\n",
      "Epoch 146 / 200 | iteration 40 / 171 | Total Loss: 3.613837957382202 | KNN Loss: 3.6002986431121826 | CLS Loss: 0.013539403676986694\n",
      "Epoch 146 / 200 | iteration 50 / 171 | Total Loss: 3.5981521606445312 | KNN Loss: 3.5872488021850586 | CLS Loss: 0.010903419926762581\n",
      "Epoch 146 / 200 | iteration 60 / 171 | Total Loss: 3.6254377365112305 | KNN Loss: 3.615504741668701 | CLS Loss: 0.009932941757142544\n",
      "Epoch 146 / 200 | iteration 70 / 171 | Total Loss: 3.625091552734375 | KNN Loss: 3.6113333702087402 | CLS Loss: 0.013758097775280476\n",
      "Epoch 146 / 200 | iteration 80 / 171 | Total Loss: 3.6035513877868652 | KNN Loss: 3.5860798358917236 | CLS Loss: 0.01747150532901287\n",
      "Epoch 146 / 200 | iteration 90 / 171 | Total Loss: 3.64009428024292 | KNN Loss: 3.6350345611572266 | CLS Loss: 0.00505963945761323\n",
      "Epoch 146 / 200 | iteration 100 / 171 | Total Loss: 3.6403541564941406 | KNN Loss: 3.628058433532715 | CLS Loss: 0.012295798398554325\n",
      "Epoch 146 / 200 | iteration 110 / 171 | Total Loss: 3.6277596950531006 | KNN Loss: 3.611929178237915 | CLS Loss: 0.01583045721054077\n",
      "Epoch 146 / 200 | iteration 120 / 171 | Total Loss: 3.5998318195343018 | KNN Loss: 3.5961532592773438 | CLS Loss: 0.003678532550111413\n",
      "Epoch 146 / 200 | iteration 130 / 171 | Total Loss: 3.612794876098633 | KNN Loss: 3.6040937900543213 | CLS Loss: 0.008700995706021786\n",
      "Epoch 146 / 200 | iteration 140 / 171 | Total Loss: 3.5976343154907227 | KNN Loss: 3.560359001159668 | CLS Loss: 0.03727530688047409\n",
      "Epoch 146 / 200 | iteration 150 / 171 | Total Loss: 3.629742383956909 | KNN Loss: 3.60900616645813 | CLS Loss: 0.02073614113032818\n",
      "Epoch 146 / 200 | iteration 160 / 171 | Total Loss: 3.6378629207611084 | KNN Loss: 3.6316092014312744 | CLS Loss: 0.006253750529140234\n",
      "Epoch 146 / 200 | iteration 170 / 171 | Total Loss: 3.6145904064178467 | KNN Loss: 3.604104518890381 | CLS Loss: 0.010485858656466007\n",
      "Epoch: 146, Loss: 3.6083, Train: 0.9975, Valid: 0.9880, Best: 0.9881\n",
      "Epoch 147 / 200 | iteration 0 / 171 | Total Loss: 3.6096298694610596 | KNN Loss: 3.60528564453125 | CLS Loss: 0.004344290588051081\n",
      "Epoch 147 / 200 | iteration 10 / 171 | Total Loss: 3.6537041664123535 | KNN Loss: 3.649806261062622 | CLS Loss: 0.0038978299126029015\n",
      "Epoch 147 / 200 | iteration 20 / 171 | Total Loss: 3.5741164684295654 | KNN Loss: 3.563397169113159 | CLS Loss: 0.010719269514083862\n",
      "Epoch 147 / 200 | iteration 30 / 171 | Total Loss: 3.5678529739379883 | KNN Loss: 3.5528740882873535 | CLS Loss: 0.01497890055179596\n",
      "Epoch 147 / 200 | iteration 40 / 171 | Total Loss: 3.6065471172332764 | KNN Loss: 3.601017475128174 | CLS Loss: 0.005529666319489479\n",
      "Epoch 147 / 200 | iteration 50 / 171 | Total Loss: 3.5629894733428955 | KNN Loss: 3.5593643188476562 | CLS Loss: 0.0036251209676265717\n",
      "Epoch 147 / 200 | iteration 60 / 171 | Total Loss: 3.612719774246216 | KNN Loss: 3.607819080352783 | CLS Loss: 0.0049006137996912\n",
      "Epoch 147 / 200 | iteration 70 / 171 | Total Loss: 3.578138828277588 | KNN Loss: 3.5704026222229004 | CLS Loss: 0.007736307568848133\n",
      "Epoch 147 / 200 | iteration 80 / 171 | Total Loss: 3.608686685562134 | KNN Loss: 3.604095935821533 | CLS Loss: 0.004590731114149094\n",
      "Epoch 147 / 200 | iteration 90 / 171 | Total Loss: 3.5997986793518066 | KNN Loss: 3.598224401473999 | CLS Loss: 0.001574287423864007\n",
      "Epoch 147 / 200 | iteration 100 / 171 | Total Loss: 3.6351728439331055 | KNN Loss: 3.6160430908203125 | CLS Loss: 0.019129779189825058\n",
      "Epoch 147 / 200 | iteration 110 / 171 | Total Loss: 3.656791925430298 | KNN Loss: 3.6514017581939697 | CLS Loss: 0.005390257574617863\n",
      "Epoch 147 / 200 | iteration 120 / 171 | Total Loss: 3.578648805618286 | KNN Loss: 3.5740132331848145 | CLS Loss: 0.004635506309568882\n",
      "Epoch 147 / 200 | iteration 130 / 171 | Total Loss: 3.6604154109954834 | KNN Loss: 3.640393018722534 | CLS Loss: 0.02002248540520668\n",
      "Epoch 147 / 200 | iteration 140 / 171 | Total Loss: 3.607717514038086 | KNN Loss: 3.591926097869873 | CLS Loss: 0.01579149253666401\n",
      "Epoch 147 / 200 | iteration 150 / 171 | Total Loss: 3.6274075508117676 | KNN Loss: 3.612427234649658 | CLS Loss: 0.014980344101786613\n",
      "Epoch 147 / 200 | iteration 160 / 171 | Total Loss: 3.629836082458496 | KNN Loss: 3.612245798110962 | CLS Loss: 0.017590273171663284\n",
      "Epoch 147 / 200 | iteration 170 / 171 | Total Loss: 3.610729217529297 | KNN Loss: 3.595547676086426 | CLS Loss: 0.015181479044258595\n",
      "Epoch: 147, Loss: 3.6118, Train: 0.9959, Valid: 0.9856, Best: 0.9881\n",
      "Epoch 148 / 200 | iteration 0 / 171 | Total Loss: 3.5941569805145264 | KNN Loss: 3.573681116104126 | CLS Loss: 0.02047593891620636\n",
      "Epoch 148 / 200 | iteration 10 / 171 | Total Loss: 3.5800414085388184 | KNN Loss: 3.577359437942505 | CLS Loss: 0.0026819894555956125\n",
      "Epoch 148 / 200 | iteration 20 / 171 | Total Loss: 3.60151743888855 | KNN Loss: 3.595944881439209 | CLS Loss: 0.00557249691337347\n",
      "Epoch 148 / 200 | iteration 30 / 171 | Total Loss: 3.575451135635376 | KNN Loss: 3.5676040649414062 | CLS Loss: 0.007846958003938198\n",
      "Epoch 148 / 200 | iteration 40 / 171 | Total Loss: 3.5920567512512207 | KNN Loss: 3.580221176147461 | CLS Loss: 0.01183551549911499\n",
      "Epoch 148 / 200 | iteration 50 / 171 | Total Loss: 3.631770133972168 | KNN Loss: 3.6084201335906982 | CLS Loss: 0.02334994450211525\n",
      "Epoch 148 / 200 | iteration 60 / 171 | Total Loss: 3.6344363689422607 | KNN Loss: 3.6264030933380127 | CLS Loss: 0.008033308200538158\n",
      "Epoch 148 / 200 | iteration 70 / 171 | Total Loss: 3.571593999862671 | KNN Loss: 3.5544369220733643 | CLS Loss: 0.01715710386633873\n",
      "Epoch 148 / 200 | iteration 80 / 171 | Total Loss: 3.5862228870391846 | KNN Loss: 3.581205368041992 | CLS Loss: 0.005017482675611973\n",
      "Epoch 148 / 200 | iteration 90 / 171 | Total Loss: 3.6056430339813232 | KNN Loss: 3.5885560512542725 | CLS Loss: 0.01708688959479332\n",
      "Epoch 148 / 200 | iteration 100 / 171 | Total Loss: 3.623976707458496 | KNN Loss: 3.621018648147583 | CLS Loss: 0.002958090743049979\n",
      "Epoch 148 / 200 | iteration 110 / 171 | Total Loss: 3.6359002590179443 | KNN Loss: 3.613046407699585 | CLS Loss: 0.0228537879884243\n",
      "Epoch 148 / 200 | iteration 120 / 171 | Total Loss: 3.6368191242218018 | KNN Loss: 3.6016016006469727 | CLS Loss: 0.03521756827831268\n",
      "Epoch 148 / 200 | iteration 130 / 171 | Total Loss: 3.6405186653137207 | KNN Loss: 3.6164417266845703 | CLS Loss: 0.024077052250504494\n",
      "Epoch 148 / 200 | iteration 140 / 171 | Total Loss: 3.612298011779785 | KNN Loss: 3.604247808456421 | CLS Loss: 0.008050265721976757\n",
      "Epoch 148 / 200 | iteration 150 / 171 | Total Loss: 3.628519058227539 | KNN Loss: 3.6123032569885254 | CLS Loss: 0.016215704381465912\n",
      "Epoch 148 / 200 | iteration 160 / 171 | Total Loss: 3.654120683670044 | KNN Loss: 3.638530731201172 | CLS Loss: 0.015589972026646137\n",
      "Epoch 148 / 200 | iteration 170 / 171 | Total Loss: 3.6305902004241943 | KNN Loss: 3.613711357116699 | CLS Loss: 0.016878746449947357\n",
      "Epoch: 148, Loss: 3.6240, Train: 0.9951, Valid: 0.9855, Best: 0.9881\n",
      "Epoch 149 / 200 | iteration 0 / 171 | Total Loss: 3.5977067947387695 | KNN Loss: 3.5923008918762207 | CLS Loss: 0.005406013689935207\n",
      "Epoch 149 / 200 | iteration 10 / 171 | Total Loss: 3.64119029045105 | KNN Loss: 3.6227450370788574 | CLS Loss: 0.018445290625095367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 / 200 | iteration 20 / 171 | Total Loss: 3.61661434173584 | KNN Loss: 3.595770835876465 | CLS Loss: 0.020843585953116417\n",
      "Epoch 149 / 200 | iteration 30 / 171 | Total Loss: 3.615825891494751 | KNN Loss: 3.6063807010650635 | CLS Loss: 0.009445198811590672\n",
      "Epoch 149 / 200 | iteration 40 / 171 | Total Loss: 3.578794479370117 | KNN Loss: 3.571270704269409 | CLS Loss: 0.007523700129240751\n",
      "Epoch 149 / 200 | iteration 50 / 171 | Total Loss: 3.6378655433654785 | KNN Loss: 3.597137451171875 | CLS Loss: 0.04072817787528038\n",
      "Epoch 149 / 200 | iteration 60 / 171 | Total Loss: 3.600748062133789 | KNN Loss: 3.5907275676727295 | CLS Loss: 0.010020378045737743\n",
      "Epoch 149 / 200 | iteration 70 / 171 | Total Loss: 3.5854859352111816 | KNN Loss: 3.579847574234009 | CLS Loss: 0.005638458766043186\n",
      "Epoch 149 / 200 | iteration 80 / 171 | Total Loss: 3.598257303237915 | KNN Loss: 3.590209722518921 | CLS Loss: 0.008047573268413544\n",
      "Epoch 149 / 200 | iteration 90 / 171 | Total Loss: 3.611137866973877 | KNN Loss: 3.6053168773651123 | CLS Loss: 0.005820953752845526\n",
      "Epoch 149 / 200 | iteration 100 / 171 | Total Loss: 3.5996909141540527 | KNN Loss: 3.5905776023864746 | CLS Loss: 0.00911337323486805\n",
      "Epoch 149 / 200 | iteration 110 / 171 | Total Loss: 3.5839955806732178 | KNN Loss: 3.579714298248291 | CLS Loss: 0.004281394183635712\n",
      "Epoch 149 / 200 | iteration 120 / 171 | Total Loss: 3.6059529781341553 | KNN Loss: 3.5993220806121826 | CLS Loss: 0.0066308146342635155\n",
      "Epoch 149 / 200 | iteration 130 / 171 | Total Loss: 3.6140875816345215 | KNN Loss: 3.602935314178467 | CLS Loss: 0.011152255348861217\n",
      "Epoch 149 / 200 | iteration 140 / 171 | Total Loss: 3.59932804107666 | KNN Loss: 3.5905327796936035 | CLS Loss: 0.00879534799605608\n",
      "Epoch 149 / 200 | iteration 150 / 171 | Total Loss: 3.604581117630005 | KNN Loss: 3.602813959121704 | CLS Loss: 0.0017671652603894472\n",
      "Epoch 149 / 200 | iteration 160 / 171 | Total Loss: 3.602590799331665 | KNN Loss: 3.596132516860962 | CLS Loss: 0.00645818468183279\n",
      "Epoch 149 / 200 | iteration 170 / 171 | Total Loss: 3.6019396781921387 | KNN Loss: 3.58846378326416 | CLS Loss: 0.013475792482495308\n",
      "Epoch: 149, Loss: 3.6158, Train: 0.9962, Valid: 0.9867, Best: 0.9881\n",
      "Epoch 150 / 200 | iteration 0 / 171 | Total Loss: 3.598970413208008 | KNN Loss: 3.593562126159668 | CLS Loss: 0.005408251658082008\n",
      "Epoch 150 / 200 | iteration 10 / 171 | Total Loss: 3.581632137298584 | KNN Loss: 3.5799105167388916 | CLS Loss: 0.0017215297557413578\n",
      "Epoch 150 / 200 | iteration 20 / 171 | Total Loss: 3.6167333126068115 | KNN Loss: 3.603778600692749 | CLS Loss: 0.012954720295965672\n",
      "Epoch 150 / 200 | iteration 30 / 171 | Total Loss: 3.5832579135894775 | KNN Loss: 3.574802875518799 | CLS Loss: 0.008454925380647182\n",
      "Epoch 150 / 200 | iteration 40 / 171 | Total Loss: 3.618565082550049 | KNN Loss: 3.6037323474884033 | CLS Loss: 0.014832735992968082\n",
      "Epoch 150 / 200 | iteration 50 / 171 | Total Loss: 3.598402976989746 | KNN Loss: 3.586663246154785 | CLS Loss: 0.011739720590412617\n",
      "Epoch 150 / 200 | iteration 60 / 171 | Total Loss: 3.6779000759124756 | KNN Loss: 3.6455013751983643 | CLS Loss: 0.032398730516433716\n",
      "Epoch 150 / 200 | iteration 70 / 171 | Total Loss: 3.6038577556610107 | KNN Loss: 3.602113962173462 | CLS Loss: 0.0017437577480450273\n",
      "Epoch 150 / 200 | iteration 80 / 171 | Total Loss: 3.5927934646606445 | KNN Loss: 3.5907063484191895 | CLS Loss: 0.00208719982765615\n",
      "Epoch 150 / 200 | iteration 90 / 171 | Total Loss: 3.61007022857666 | KNN Loss: 3.6086347103118896 | CLS Loss: 0.0014356353785842657\n",
      "Epoch 150 / 200 | iteration 100 / 171 | Total Loss: 3.6125802993774414 | KNN Loss: 3.6026999950408936 | CLS Loss: 0.009880376979708672\n",
      "Epoch 150 / 200 | iteration 110 / 171 | Total Loss: 3.6355555057525635 | KNN Loss: 3.616006851196289 | CLS Loss: 0.019548704847693443\n",
      "Epoch 150 / 200 | iteration 120 / 171 | Total Loss: 3.6227121353149414 | KNN Loss: 3.5924417972564697 | CLS Loss: 0.030270321294665337\n",
      "Epoch 150 / 200 | iteration 130 / 171 | Total Loss: 3.6093719005584717 | KNN Loss: 3.591331958770752 | CLS Loss: 0.018039843067526817\n",
      "Epoch 150 / 200 | iteration 140 / 171 | Total Loss: 3.6144185066223145 | KNN Loss: 3.6097402572631836 | CLS Loss: 0.00467824237421155\n",
      "Epoch 150 / 200 | iteration 150 / 171 | Total Loss: 3.5911645889282227 | KNN Loss: 3.576856851577759 | CLS Loss: 0.014307735487818718\n",
      "Epoch 150 / 200 | iteration 160 / 171 | Total Loss: 3.611295700073242 | KNN Loss: 3.598813533782959 | CLS Loss: 0.01248224452137947\n",
      "Epoch 150 / 200 | iteration 170 / 171 | Total Loss: 3.7014553546905518 | KNN Loss: 3.700502395629883 | CLS Loss: 0.0009530694806016982\n",
      "Epoch: 150, Loss: 3.6104, Train: 0.9967, Valid: 0.9866, Best: 0.9881\n",
      "Epoch 151 / 200 | iteration 0 / 171 | Total Loss: 3.6132330894470215 | KNN Loss: 3.5999529361724854 | CLS Loss: 0.013280127197504044\n",
      "Epoch 151 / 200 | iteration 10 / 171 | Total Loss: 3.6169958114624023 | KNN Loss: 3.604849100112915 | CLS Loss: 0.012146806344389915\n",
      "Epoch 151 / 200 | iteration 20 / 171 | Total Loss: 3.5814833641052246 | KNN Loss: 3.5719144344329834 | CLS Loss: 0.009569015353918076\n",
      "Epoch 151 / 200 | iteration 30 / 171 | Total Loss: 3.646934747695923 | KNN Loss: 3.637856960296631 | CLS Loss: 0.009077794849872589\n",
      "Epoch 151 / 200 | iteration 40 / 171 | Total Loss: 3.564358949661255 | KNN Loss: 3.56195068359375 | CLS Loss: 0.002408349886536598\n",
      "Epoch 151 / 200 | iteration 50 / 171 | Total Loss: 3.6278719902038574 | KNN Loss: 3.6104681491851807 | CLS Loss: 0.017403781414031982\n",
      "Epoch 151 / 200 | iteration 60 / 171 | Total Loss: 3.5932865142822266 | KNN Loss: 3.5838067531585693 | CLS Loss: 0.009479841217398643\n",
      "Epoch 151 / 200 | iteration 70 / 171 | Total Loss: 3.579216718673706 | KNN Loss: 3.5765275955200195 | CLS Loss: 0.00268922233954072\n",
      "Epoch 151 / 200 | iteration 80 / 171 | Total Loss: 3.591762065887451 | KNN Loss: 3.5882816314697266 | CLS Loss: 0.0034803650341928005\n",
      "Epoch 151 / 200 | iteration 90 / 171 | Total Loss: 3.648651361465454 | KNN Loss: 3.641077756881714 | CLS Loss: 0.007573659066110849\n",
      "Epoch 151 / 200 | iteration 100 / 171 | Total Loss: 3.5872750282287598 | KNN Loss: 3.5849783420562744 | CLS Loss: 0.002296573482453823\n",
      "Epoch 151 / 200 | iteration 110 / 171 | Total Loss: 3.6222636699676514 | KNN Loss: 3.6088640689849854 | CLS Loss: 0.013399521820247173\n",
      "Epoch 151 / 200 | iteration 120 / 171 | Total Loss: 3.6006126403808594 | KNN Loss: 3.5793328285217285 | CLS Loss: 0.021279850974678993\n",
      "Epoch 151 / 200 | iteration 130 / 171 | Total Loss: 3.5728588104248047 | KNN Loss: 3.560023784637451 | CLS Loss: 0.012835105881094933\n",
      "Epoch 151 / 200 | iteration 140 / 171 | Total Loss: 3.610137701034546 | KNN Loss: 3.5915608406066895 | CLS Loss: 0.018576806411147118\n",
      "Epoch 151 / 200 | iteration 150 / 171 | Total Loss: 3.6294963359832764 | KNN Loss: 3.6182336807250977 | CLS Loss: 0.011262552812695503\n",
      "Epoch 151 / 200 | iteration 160 / 171 | Total Loss: 3.630422353744507 | KNN Loss: 3.6121625900268555 | CLS Loss: 0.018259715288877487\n",
      "Epoch 151 / 200 | iteration 170 / 171 | Total Loss: 3.6547930240631104 | KNN Loss: 3.6416068077087402 | CLS Loss: 0.013186329044401646\n",
      "Epoch: 151, Loss: 3.6120, Train: 0.9979, Valid: 0.9870, Best: 0.9881\n",
      "Epoch 152 / 200 | iteration 0 / 171 | Total Loss: 3.5894699096679688 | KNN Loss: 3.576871633529663 | CLS Loss: 0.01259828545153141\n",
      "Epoch 152 / 200 | iteration 10 / 171 | Total Loss: 3.59130597114563 | KNN Loss: 3.581998109817505 | CLS Loss: 0.009307879954576492\n",
      "Epoch 152 / 200 | iteration 20 / 171 | Total Loss: 3.624739170074463 | KNN Loss: 3.611438274383545 | CLS Loss: 0.013300910592079163\n",
      "Epoch 152 / 200 | iteration 30 / 171 | Total Loss: 3.5735816955566406 | KNN Loss: 3.5625293254852295 | CLS Loss: 0.011052453890442848\n",
      "Epoch 152 / 200 | iteration 40 / 171 | Total Loss: 3.609282970428467 | KNN Loss: 3.595076322555542 | CLS Loss: 0.014206767082214355\n",
      "Epoch 152 / 200 | iteration 50 / 171 | Total Loss: 3.6559712886810303 | KNN Loss: 3.6323654651641846 | CLS Loss: 0.023605745285749435\n",
      "Epoch 152 / 200 | iteration 60 / 171 | Total Loss: 3.6121647357940674 | KNN Loss: 3.6104390621185303 | CLS Loss: 0.0017257574945688248\n",
      "Epoch 152 / 200 | iteration 70 / 171 | Total Loss: 3.608445644378662 | KNN Loss: 3.5851309299468994 | CLS Loss: 0.023314695805311203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 / 200 | iteration 80 / 171 | Total Loss: 3.656128406524658 | KNN Loss: 3.6495559215545654 | CLS Loss: 0.00657245796173811\n",
      "Epoch 152 / 200 | iteration 90 / 171 | Total Loss: 3.649089813232422 | KNN Loss: 3.6288185119628906 | CLS Loss: 0.02027127519249916\n",
      "Epoch 152 / 200 | iteration 100 / 171 | Total Loss: 3.6156325340270996 | KNN Loss: 3.598353624343872 | CLS Loss: 0.017278896644711494\n",
      "Epoch 152 / 200 | iteration 110 / 171 | Total Loss: 3.6222665309906006 | KNN Loss: 3.6105713844299316 | CLS Loss: 0.011695112101733685\n",
      "Epoch 152 / 200 | iteration 120 / 171 | Total Loss: 3.6158249378204346 | KNN Loss: 3.6053824424743652 | CLS Loss: 0.010442475788295269\n",
      "Epoch 152 / 200 | iteration 130 / 171 | Total Loss: 3.587689161300659 | KNN Loss: 3.5831356048583984 | CLS Loss: 0.004553659353405237\n",
      "Epoch 152 / 200 | iteration 140 / 171 | Total Loss: 3.602689266204834 | KNN Loss: 3.5993494987487793 | CLS Loss: 0.003339653369039297\n",
      "Epoch 152 / 200 | iteration 150 / 171 | Total Loss: 3.599412202835083 | KNN Loss: 3.5864548683166504 | CLS Loss: 0.012957379221916199\n",
      "Epoch 152 / 200 | iteration 160 / 171 | Total Loss: 3.619927167892456 | KNN Loss: 3.612725019454956 | CLS Loss: 0.007202143780887127\n",
      "Epoch 152 / 200 | iteration 170 / 171 | Total Loss: 3.6276638507843018 | KNN Loss: 3.621596574783325 | CLS Loss: 0.006067336071282625\n",
      "Epoch: 152, Loss: 3.6105, Train: 0.9957, Valid: 0.9851, Best: 0.9881\n",
      "Epoch 153 / 200 | iteration 0 / 171 | Total Loss: 3.6057546138763428 | KNN Loss: 3.589801073074341 | CLS Loss: 0.015953540802001953\n",
      "Epoch 153 / 200 | iteration 10 / 171 | Total Loss: 3.6087305545806885 | KNN Loss: 3.5958404541015625 | CLS Loss: 0.012890062294900417\n",
      "Epoch 153 / 200 | iteration 20 / 171 | Total Loss: 3.6593360900878906 | KNN Loss: 3.658612012863159 | CLS Loss: 0.0007241829880513251\n",
      "Epoch 153 / 200 | iteration 30 / 171 | Total Loss: 3.618119239807129 | KNN Loss: 3.6095001697540283 | CLS Loss: 0.008618972264230251\n",
      "Epoch 153 / 200 | iteration 40 / 171 | Total Loss: 3.598278045654297 | KNN Loss: 3.5923099517822266 | CLS Loss: 0.005968017969280481\n",
      "Epoch 153 / 200 | iteration 50 / 171 | Total Loss: 3.636298656463623 | KNN Loss: 3.6300008296966553 | CLS Loss: 0.006297897547483444\n",
      "Epoch 153 / 200 | iteration 60 / 171 | Total Loss: 3.640932559967041 | KNN Loss: 3.631910800933838 | CLS Loss: 0.009021845646202564\n",
      "Epoch 153 / 200 | iteration 70 / 171 | Total Loss: 3.6295158863067627 | KNN Loss: 3.6221272945404053 | CLS Loss: 0.007388574071228504\n",
      "Epoch 153 / 200 | iteration 80 / 171 | Total Loss: 3.6270461082458496 | KNN Loss: 3.616272211074829 | CLS Loss: 0.010773991234600544\n",
      "Epoch 153 / 200 | iteration 90 / 171 | Total Loss: 3.6744487285614014 | KNN Loss: 3.6617794036865234 | CLS Loss: 0.01266923826187849\n",
      "Epoch 153 / 200 | iteration 100 / 171 | Total Loss: 3.6656687259674072 | KNN Loss: 3.6542515754699707 | CLS Loss: 0.01141709927469492\n",
      "Epoch 153 / 200 | iteration 110 / 171 | Total Loss: 3.5809175968170166 | KNN Loss: 3.5772337913513184 | CLS Loss: 0.003683809656649828\n",
      "Epoch 153 / 200 | iteration 120 / 171 | Total Loss: 3.652113199234009 | KNN Loss: 3.6424636840820312 | CLS Loss: 0.009649398736655712\n",
      "Epoch 153 / 200 | iteration 130 / 171 | Total Loss: 3.5854482650756836 | KNN Loss: 3.578462600708008 | CLS Loss: 0.006985604763031006\n",
      "Epoch 153 / 200 | iteration 140 / 171 | Total Loss: 3.5878546237945557 | KNN Loss: 3.583749532699585 | CLS Loss: 0.004105015192180872\n",
      "Epoch 153 / 200 | iteration 150 / 171 | Total Loss: 3.582812547683716 | KNN Loss: 3.5787229537963867 | CLS Loss: 0.004089605528861284\n",
      "Epoch 153 / 200 | iteration 160 / 171 | Total Loss: 3.613889694213867 | KNN Loss: 3.611644744873047 | CLS Loss: 0.0022449034731835127\n",
      "Epoch 153 / 200 | iteration 170 / 171 | Total Loss: 3.5992298126220703 | KNN Loss: 3.5894320011138916 | CLS Loss: 0.009797725826501846\n",
      "Epoch: 153, Loss: 3.6167, Train: 0.9971, Valid: 0.9864, Best: 0.9881\n",
      "Epoch 154 / 200 | iteration 0 / 171 | Total Loss: 3.609060049057007 | KNN Loss: 3.6024386882781982 | CLS Loss: 0.00662141153588891\n",
      "Epoch 154 / 200 | iteration 10 / 171 | Total Loss: 3.5862107276916504 | KNN Loss: 3.572687864303589 | CLS Loss: 0.01352285873144865\n",
      "Epoch 154 / 200 | iteration 20 / 171 | Total Loss: 3.6039113998413086 | KNN Loss: 3.5955207347869873 | CLS Loss: 0.00839067343622446\n",
      "Epoch 154 / 200 | iteration 30 / 171 | Total Loss: 3.6380741596221924 | KNN Loss: 3.6359848976135254 | CLS Loss: 0.002089172601699829\n",
      "Epoch 154 / 200 | iteration 40 / 171 | Total Loss: 3.6056199073791504 | KNN Loss: 3.599595308303833 | CLS Loss: 0.006024644710123539\n",
      "Epoch 154 / 200 | iteration 50 / 171 | Total Loss: 3.5956411361694336 | KNN Loss: 3.5800416469573975 | CLS Loss: 0.015599404461681843\n",
      "Epoch 154 / 200 | iteration 60 / 171 | Total Loss: 3.588118553161621 | KNN Loss: 3.57503604888916 | CLS Loss: 0.013082623481750488\n",
      "Epoch 154 / 200 | iteration 70 / 171 | Total Loss: 3.632354259490967 | KNN Loss: 3.6010589599609375 | CLS Loss: 0.03129531070590019\n",
      "Epoch 154 / 200 | iteration 80 / 171 | Total Loss: 3.6726999282836914 | KNN Loss: 3.6602210998535156 | CLS Loss: 0.012478947639465332\n",
      "Epoch 154 / 200 | iteration 90 / 171 | Total Loss: 3.5921154022216797 | KNN Loss: 3.5911664962768555 | CLS Loss: 0.0009489558287896216\n",
      "Epoch 154 / 200 | iteration 100 / 171 | Total Loss: 3.6097636222839355 | KNN Loss: 3.606423854827881 | CLS Loss: 0.0033396498765796423\n",
      "Epoch 154 / 200 | iteration 110 / 171 | Total Loss: 3.6292951107025146 | KNN Loss: 3.624295949935913 | CLS Loss: 0.004999130964279175\n",
      "Epoch 154 / 200 | iteration 120 / 171 | Total Loss: 3.660038948059082 | KNN Loss: 3.6495513916015625 | CLS Loss: 0.0104875722900033\n",
      "Epoch 154 / 200 | iteration 130 / 171 | Total Loss: 3.5930752754211426 | KNN Loss: 3.569591522216797 | CLS Loss: 0.02348373644053936\n",
      "Epoch 154 / 200 | iteration 140 / 171 | Total Loss: 3.6615426540374756 | KNN Loss: 3.6456668376922607 | CLS Loss: 0.015875786542892456\n",
      "Epoch 154 / 200 | iteration 150 / 171 | Total Loss: 3.6661698818206787 | KNN Loss: 3.6238391399383545 | CLS Loss: 0.0423307791352272\n",
      "Epoch 154 / 200 | iteration 160 / 171 | Total Loss: 3.6845345497131348 | KNN Loss: 3.677070140838623 | CLS Loss: 0.007464483380317688\n",
      "Epoch 154 / 200 | iteration 170 / 171 | Total Loss: 3.6134843826293945 | KNN Loss: 3.599949359893799 | CLS Loss: 0.013534940779209137\n",
      "Epoch: 154, Loss: 3.6130, Train: 0.9965, Valid: 0.9870, Best: 0.9881\n",
      "Epoch 155 / 200 | iteration 0 / 171 | Total Loss: 3.6268539428710938 | KNN Loss: 3.6144142150878906 | CLS Loss: 0.01243975292891264\n",
      "Epoch 155 / 200 | iteration 10 / 171 | Total Loss: 3.5959999561309814 | KNN Loss: 3.5815446376800537 | CLS Loss: 0.014455210417509079\n",
      "Epoch 155 / 200 | iteration 20 / 171 | Total Loss: 3.5892815589904785 | KNN Loss: 3.5838701725006104 | CLS Loss: 0.005411454476416111\n",
      "Epoch 155 / 200 | iteration 30 / 171 | Total Loss: 3.6231133937835693 | KNN Loss: 3.617929697036743 | CLS Loss: 0.005183587782084942\n",
      "Epoch 155 / 200 | iteration 40 / 171 | Total Loss: 3.5581841468811035 | KNN Loss: 3.5573508739471436 | CLS Loss: 0.0008331778808496892\n",
      "Epoch 155 / 200 | iteration 50 / 171 | Total Loss: 3.6146092414855957 | KNN Loss: 3.6087472438812256 | CLS Loss: 0.005861914250999689\n",
      "Epoch 155 / 200 | iteration 60 / 171 | Total Loss: 3.6300249099731445 | KNN Loss: 3.6234757900238037 | CLS Loss: 0.006549077108502388\n",
      "Epoch 155 / 200 | iteration 70 / 171 | Total Loss: 3.608309030532837 | KNN Loss: 3.603874683380127 | CLS Loss: 0.004434280563145876\n",
      "Epoch 155 / 200 | iteration 80 / 171 | Total Loss: 3.584491729736328 | KNN Loss: 3.579841375350952 | CLS Loss: 0.00465024309232831\n",
      "Epoch 155 / 200 | iteration 90 / 171 | Total Loss: 3.6202237606048584 | KNN Loss: 3.5912673473358154 | CLS Loss: 0.02895633690059185\n",
      "Epoch 155 / 200 | iteration 100 / 171 | Total Loss: 3.6526827812194824 | KNN Loss: 3.63604474067688 | CLS Loss: 0.01663813181221485\n",
      "Epoch 155 / 200 | iteration 110 / 171 | Total Loss: 3.6788079738616943 | KNN Loss: 3.673517942428589 | CLS Loss: 0.00528997927904129\n",
      "Epoch 155 / 200 | iteration 120 / 171 | Total Loss: 3.6097705364227295 | KNN Loss: 3.596064329147339 | CLS Loss: 0.013706192374229431\n",
      "Epoch 155 / 200 | iteration 130 / 171 | Total Loss: 3.6307241916656494 | KNN Loss: 3.610520124435425 | CLS Loss: 0.020203974097967148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 / 200 | iteration 140 / 171 | Total Loss: 3.6331231594085693 | KNN Loss: 3.623807430267334 | CLS Loss: 0.009315677918493748\n",
      "Epoch 155 / 200 | iteration 150 / 171 | Total Loss: 3.582397937774658 | KNN Loss: 3.5760319232940674 | CLS Loss: 0.0063661313615739346\n",
      "Epoch 155 / 200 | iteration 160 / 171 | Total Loss: 3.5692152976989746 | KNN Loss: 3.5606164932250977 | CLS Loss: 0.00859872717410326\n",
      "Epoch 155 / 200 | iteration 170 / 171 | Total Loss: 3.577214479446411 | KNN Loss: 3.575634241104126 | CLS Loss: 0.0015801527770236135\n",
      "Epoch: 155, Loss: 3.6080, Train: 0.9975, Valid: 0.9873, Best: 0.9881\n",
      "Epoch 156 / 200 | iteration 0 / 171 | Total Loss: 3.6580278873443604 | KNN Loss: 3.637699604034424 | CLS Loss: 0.02032817155122757\n",
      "Epoch 156 / 200 | iteration 10 / 171 | Total Loss: 3.634885549545288 | KNN Loss: 3.631197929382324 | CLS Loss: 0.0036876776721328497\n",
      "Epoch 156 / 200 | iteration 20 / 171 | Total Loss: 3.597041368484497 | KNN Loss: 3.59324312210083 | CLS Loss: 0.003798344172537327\n",
      "Epoch 156 / 200 | iteration 30 / 171 | Total Loss: 3.596845865249634 | KNN Loss: 3.5917623043060303 | CLS Loss: 0.005083580035716295\n",
      "Epoch 156 / 200 | iteration 40 / 171 | Total Loss: 3.617189645767212 | KNN Loss: 3.605517625808716 | CLS Loss: 0.011671911925077438\n",
      "Epoch 156 / 200 | iteration 50 / 171 | Total Loss: 3.6044435501098633 | KNN Loss: 3.592540979385376 | CLS Loss: 0.011902564205229282\n",
      "Epoch 156 / 200 | iteration 60 / 171 | Total Loss: 3.635307788848877 | KNN Loss: 3.630481243133545 | CLS Loss: 0.004826602526009083\n",
      "Epoch 156 / 200 | iteration 70 / 171 | Total Loss: 3.6261627674102783 | KNN Loss: 3.623591423034668 | CLS Loss: 0.002571237040683627\n",
      "Epoch 156 / 200 | iteration 80 / 171 | Total Loss: 3.625107765197754 | KNN Loss: 3.618457555770874 | CLS Loss: 0.006650183815509081\n",
      "Epoch 156 / 200 | iteration 90 / 171 | Total Loss: 3.5874595642089844 | KNN Loss: 3.569722890853882 | CLS Loss: 0.01773659512400627\n",
      "Epoch 156 / 200 | iteration 100 / 171 | Total Loss: 3.5967860221862793 | KNN Loss: 3.5705935955047607 | CLS Loss: 0.026192545890808105\n",
      "Epoch 156 / 200 | iteration 110 / 171 | Total Loss: 3.596313238143921 | KNN Loss: 3.5834991931915283 | CLS Loss: 0.012814084067940712\n",
      "Epoch 156 / 200 | iteration 120 / 171 | Total Loss: 3.593881368637085 | KNN Loss: 3.5900611877441406 | CLS Loss: 0.0038200998678803444\n",
      "Epoch 156 / 200 | iteration 130 / 171 | Total Loss: 3.610027313232422 | KNN Loss: 3.58335280418396 | CLS Loss: 0.02667449228465557\n",
      "Epoch 156 / 200 | iteration 140 / 171 | Total Loss: 3.641235589981079 | KNN Loss: 3.6282081604003906 | CLS Loss: 0.013027315028011799\n",
      "Epoch 156 / 200 | iteration 150 / 171 | Total Loss: 3.606981039047241 | KNN Loss: 3.5856409072875977 | CLS Loss: 0.021340064704418182\n",
      "Epoch 156 / 200 | iteration 160 / 171 | Total Loss: 3.5603692531585693 | KNN Loss: 3.5591323375701904 | CLS Loss: 0.0012368271127343178\n",
      "Epoch 156 / 200 | iteration 170 / 171 | Total Loss: 3.602531909942627 | KNN Loss: 3.5602118968963623 | CLS Loss: 0.04232010990381241\n",
      "Epoch: 156, Loss: 3.6061, Train: 0.9975, Valid: 0.9874, Best: 0.9881\n",
      "Epoch 157 / 200 | iteration 0 / 171 | Total Loss: 3.5724401473999023 | KNN Loss: 3.5699613094329834 | CLS Loss: 0.002478777663782239\n",
      "Epoch 157 / 200 | iteration 10 / 171 | Total Loss: 3.5889031887054443 | KNN Loss: 3.5802905559539795 | CLS Loss: 0.008612528443336487\n",
      "Epoch 157 / 200 | iteration 20 / 171 | Total Loss: 3.5961153507232666 | KNN Loss: 3.5916531085968018 | CLS Loss: 0.0044622099958360195\n",
      "Epoch 157 / 200 | iteration 30 / 171 | Total Loss: 3.596790313720703 | KNN Loss: 3.5861825942993164 | CLS Loss: 0.010607649572193623\n",
      "Epoch 157 / 200 | iteration 40 / 171 | Total Loss: 3.6325271129608154 | KNN Loss: 3.6158196926116943 | CLS Loss: 0.016707418486475945\n",
      "Epoch 157 / 200 | iteration 50 / 171 | Total Loss: 3.633553981781006 | KNN Loss: 3.6203887462615967 | CLS Loss: 0.013165307231247425\n",
      "Epoch 157 / 200 | iteration 60 / 171 | Total Loss: 3.6069774627685547 | KNN Loss: 3.605192184448242 | CLS Loss: 0.0017852304736152291\n",
      "Epoch 157 / 200 | iteration 70 / 171 | Total Loss: 3.6394200325012207 | KNN Loss: 3.6347546577453613 | CLS Loss: 0.004665265791118145\n",
      "Epoch 157 / 200 | iteration 80 / 171 | Total Loss: 3.666454792022705 | KNN Loss: 3.6361687183380127 | CLS Loss: 0.030286109074950218\n",
      "Epoch 157 / 200 | iteration 90 / 171 | Total Loss: 3.6227927207946777 | KNN Loss: 3.6020267009735107 | CLS Loss: 0.02076595276594162\n",
      "Epoch 157 / 200 | iteration 100 / 171 | Total Loss: 3.657221555709839 | KNN Loss: 3.6406028270721436 | CLS Loss: 0.016618646681308746\n",
      "Epoch 157 / 200 | iteration 110 / 171 | Total Loss: 3.6562767028808594 | KNN Loss: 3.6274945735931396 | CLS Loss: 0.02878224290907383\n",
      "Epoch 157 / 200 | iteration 120 / 171 | Total Loss: 3.5807878971099854 | KNN Loss: 3.577918529510498 | CLS Loss: 0.0028693240601569414\n",
      "Epoch 157 / 200 | iteration 130 / 171 | Total Loss: 3.621309518814087 | KNN Loss: 3.5938315391540527 | CLS Loss: 0.027478065341711044\n",
      "Epoch 157 / 200 | iteration 140 / 171 | Total Loss: 3.594870090484619 | KNN Loss: 3.5827598571777344 | CLS Loss: 0.012110242620110512\n",
      "Epoch 157 / 200 | iteration 150 / 171 | Total Loss: 3.633084774017334 | KNN Loss: 3.6280677318573 | CLS Loss: 0.00501713203266263\n",
      "Epoch 157 / 200 | iteration 160 / 171 | Total Loss: 3.6508686542510986 | KNN Loss: 3.6163251399993896 | CLS Loss: 0.034543514251708984\n",
      "Epoch 157 / 200 | iteration 170 / 171 | Total Loss: 3.5832431316375732 | KNN Loss: 3.5728564262390137 | CLS Loss: 0.010386730544269085\n",
      "Epoch: 157, Loss: 3.6139, Train: 0.9966, Valid: 0.9870, Best: 0.9881\n",
      "Epoch 158 / 200 | iteration 0 / 171 | Total Loss: 3.6004300117492676 | KNN Loss: 3.5959084033966064 | CLS Loss: 0.00452151196077466\n",
      "Epoch 158 / 200 | iteration 10 / 171 | Total Loss: 3.6328234672546387 | KNN Loss: 3.625516653060913 | CLS Loss: 0.007306864485144615\n",
      "Epoch 158 / 200 | iteration 20 / 171 | Total Loss: 3.6132378578186035 | KNN Loss: 3.603084087371826 | CLS Loss: 0.010153664276003838\n",
      "Epoch 158 / 200 | iteration 30 / 171 | Total Loss: 3.612323045730591 | KNN Loss: 3.6002769470214844 | CLS Loss: 0.01204617228358984\n",
      "Epoch 158 / 200 | iteration 40 / 171 | Total Loss: 3.6367087364196777 | KNN Loss: 3.6188693046569824 | CLS Loss: 0.017839526757597923\n",
      "Epoch 158 / 200 | iteration 50 / 171 | Total Loss: 3.6296322345733643 | KNN Loss: 3.5963072776794434 | CLS Loss: 0.03332491219043732\n",
      "Epoch 158 / 200 | iteration 60 / 171 | Total Loss: 3.609447956085205 | KNN Loss: 3.5966074466705322 | CLS Loss: 0.012840582057833672\n",
      "Epoch 158 / 200 | iteration 70 / 171 | Total Loss: 3.6378536224365234 | KNN Loss: 3.6282737255096436 | CLS Loss: 0.009579933248460293\n",
      "Epoch 158 / 200 | iteration 80 / 171 | Total Loss: 3.5994555950164795 | KNN Loss: 3.576227903366089 | CLS Loss: 0.02322765253484249\n",
      "Epoch 158 / 200 | iteration 90 / 171 | Total Loss: 3.607426643371582 | KNN Loss: 3.5985453128814697 | CLS Loss: 0.0088814003393054\n",
      "Epoch 158 / 200 | iteration 100 / 171 | Total Loss: 3.655280113220215 | KNN Loss: 3.6410889625549316 | CLS Loss: 0.014191199094057083\n",
      "Epoch 158 / 200 | iteration 110 / 171 | Total Loss: 3.680380344390869 | KNN Loss: 3.669710397720337 | CLS Loss: 0.010669909417629242\n",
      "Epoch 158 / 200 | iteration 120 / 171 | Total Loss: 3.5774683952331543 | KNN Loss: 3.5725386142730713 | CLS Loss: 0.004929812625050545\n",
      "Epoch 158 / 200 | iteration 130 / 171 | Total Loss: 3.5850882530212402 | KNN Loss: 3.554734230041504 | CLS Loss: 0.030354084447026253\n",
      "Epoch 158 / 200 | iteration 140 / 171 | Total Loss: 3.5979511737823486 | KNN Loss: 3.588972806930542 | CLS Loss: 0.008978391997516155\n",
      "Epoch 158 / 200 | iteration 150 / 171 | Total Loss: 3.60587477684021 | KNN Loss: 3.588428497314453 | CLS Loss: 0.017446348443627357\n",
      "Epoch 158 / 200 | iteration 160 / 171 | Total Loss: 3.6361024379730225 | KNN Loss: 3.612236738204956 | CLS Loss: 0.02386573702096939\n",
      "Epoch 158 / 200 | iteration 170 / 171 | Total Loss: 3.5951149463653564 | KNN Loss: 3.579133987426758 | CLS Loss: 0.01598096638917923\n",
      "Epoch: 158, Loss: 3.6172, Train: 0.9967, Valid: 0.9865, Best: 0.9881\n",
      "Epoch 159 / 200 | iteration 0 / 171 | Total Loss: 3.603339195251465 | KNN Loss: 3.5985403060913086 | CLS Loss: 0.0047989790327847\n",
      "Epoch 159 / 200 | iteration 10 / 171 | Total Loss: 3.594174861907959 | KNN Loss: 3.5749058723449707 | CLS Loss: 0.019269004464149475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 / 200 | iteration 20 / 171 | Total Loss: 3.6185574531555176 | KNN Loss: 3.5999081134796143 | CLS Loss: 0.018649283796548843\n",
      "Epoch 159 / 200 | iteration 30 / 171 | Total Loss: 3.602532148361206 | KNN Loss: 3.600550413131714 | CLS Loss: 0.001981717301532626\n",
      "Epoch 159 / 200 | iteration 40 / 171 | Total Loss: 3.598616123199463 | KNN Loss: 3.5965113639831543 | CLS Loss: 0.0021047741174697876\n",
      "Epoch 159 / 200 | iteration 50 / 171 | Total Loss: 3.6107890605926514 | KNN Loss: 3.5970678329467773 | CLS Loss: 0.013721192255616188\n",
      "Epoch 159 / 200 | iteration 60 / 171 | Total Loss: 3.632171630859375 | KNN Loss: 3.6282150745391846 | CLS Loss: 0.00395645946264267\n",
      "Epoch 159 / 200 | iteration 70 / 171 | Total Loss: 3.6164462566375732 | KNN Loss: 3.6070451736450195 | CLS Loss: 0.009401059709489346\n",
      "Epoch 159 / 200 | iteration 80 / 171 | Total Loss: 3.573749303817749 | KNN Loss: 3.5688915252685547 | CLS Loss: 0.004857802297919989\n",
      "Epoch 159 / 200 | iteration 90 / 171 | Total Loss: 3.5650649070739746 | KNN Loss: 3.5554556846618652 | CLS Loss: 0.009609262458980083\n",
      "Epoch 159 / 200 | iteration 100 / 171 | Total Loss: 3.65462064743042 | KNN Loss: 3.6420931816101074 | CLS Loss: 0.012527510523796082\n",
      "Epoch 159 / 200 | iteration 110 / 171 | Total Loss: 3.591621160507202 | KNN Loss: 3.5809943675994873 | CLS Loss: 0.010626807808876038\n",
      "Epoch 159 / 200 | iteration 120 / 171 | Total Loss: 3.621516227722168 | KNN Loss: 3.617058515548706 | CLS Loss: 0.004457616712898016\n",
      "Epoch 159 / 200 | iteration 130 / 171 | Total Loss: 3.5941593647003174 | KNN Loss: 3.5920090675354004 | CLS Loss: 0.0021503509487956762\n",
      "Epoch 159 / 200 | iteration 140 / 171 | Total Loss: 3.5943493843078613 | KNN Loss: 3.5724422931671143 | CLS Loss: 0.021907078102231026\n",
      "Epoch 159 / 200 | iteration 150 / 171 | Total Loss: 3.5931224822998047 | KNN Loss: 3.5917844772338867 | CLS Loss: 0.001338107860647142\n",
      "Epoch 159 / 200 | iteration 160 / 171 | Total Loss: 3.623227119445801 | KNN Loss: 3.601439952850342 | CLS Loss: 0.021787256002426147\n",
      "Epoch 159 / 200 | iteration 170 / 171 | Total Loss: 3.643354654312134 | KNN Loss: 3.6349711418151855 | CLS Loss: 0.008383629843592644\n",
      "Epoch: 159, Loss: 3.6063, Train: 0.9976, Valid: 0.9876, Best: 0.9881\n",
      "Epoch 160 / 200 | iteration 0 / 171 | Total Loss: 3.598762273788452 | KNN Loss: 3.5970733165740967 | CLS Loss: 0.001688869670033455\n",
      "Epoch 160 / 200 | iteration 10 / 171 | Total Loss: 3.6520931720733643 | KNN Loss: 3.6189591884613037 | CLS Loss: 0.03313400596380234\n",
      "Epoch 160 / 200 | iteration 20 / 171 | Total Loss: 3.623305082321167 | KNN Loss: 3.6135549545288086 | CLS Loss: 0.009750020690262318\n",
      "Epoch 160 / 200 | iteration 30 / 171 | Total Loss: 3.6261541843414307 | KNN Loss: 3.6114470958709717 | CLS Loss: 0.014707185328006744\n",
      "Epoch 160 / 200 | iteration 40 / 171 | Total Loss: 3.6187686920166016 | KNN Loss: 3.615618944168091 | CLS Loss: 0.0031496984884142876\n",
      "Epoch 160 / 200 | iteration 50 / 171 | Total Loss: 3.6520702838897705 | KNN Loss: 3.6479716300964355 | CLS Loss: 0.004098570439964533\n",
      "Epoch 160 / 200 | iteration 60 / 171 | Total Loss: 3.5780961513519287 | KNN Loss: 3.5722527503967285 | CLS Loss: 0.005843294784426689\n",
      "Epoch 160 / 200 | iteration 70 / 171 | Total Loss: 3.586259365081787 | KNN Loss: 3.5775153636932373 | CLS Loss: 0.008744076825678349\n",
      "Epoch 160 / 200 | iteration 80 / 171 | Total Loss: 3.619168758392334 | KNN Loss: 3.6053779125213623 | CLS Loss: 0.01379080954939127\n",
      "Epoch 160 / 200 | iteration 90 / 171 | Total Loss: 3.6117959022521973 | KNN Loss: 3.5803089141845703 | CLS Loss: 0.0314868725836277\n",
      "Epoch 160 / 200 | iteration 100 / 171 | Total Loss: 3.6612095832824707 | KNN Loss: 3.6519436836242676 | CLS Loss: 0.009266001172363758\n",
      "Epoch 160 / 200 | iteration 110 / 171 | Total Loss: 3.6036434173583984 | KNN Loss: 3.5885167121887207 | CLS Loss: 0.015126696787774563\n",
      "Epoch 160 / 200 | iteration 120 / 171 | Total Loss: 3.589090585708618 | KNN Loss: 3.576230764389038 | CLS Loss: 0.012859759852290154\n",
      "Epoch 160 / 200 | iteration 130 / 171 | Total Loss: 3.6054720878601074 | KNN Loss: 3.5960700511932373 | CLS Loss: 0.009402097202837467\n",
      "Epoch 160 / 200 | iteration 140 / 171 | Total Loss: 3.562450647354126 | KNN Loss: 3.5594615936279297 | CLS Loss: 0.0029891584999859333\n",
      "Epoch 160 / 200 | iteration 150 / 171 | Total Loss: 3.619300127029419 | KNN Loss: 3.6096696853637695 | CLS Loss: 0.0096304751932621\n",
      "Epoch 160 / 200 | iteration 160 / 171 | Total Loss: 3.615772247314453 | KNN Loss: 3.6129605770111084 | CLS Loss: 0.0028116877656430006\n",
      "Epoch 160 / 200 | iteration 170 / 171 | Total Loss: 3.6117262840270996 | KNN Loss: 3.602241277694702 | CLS Loss: 0.009485040791332722\n",
      "Epoch: 160, Loss: 3.6112, Train: 0.9952, Valid: 0.9854, Best: 0.9881\n",
      "Epoch 161 / 200 | iteration 0 / 171 | Total Loss: 3.634570360183716 | KNN Loss: 3.6248514652252197 | CLS Loss: 0.009718937799334526\n",
      "Epoch 161 / 200 | iteration 10 / 171 | Total Loss: 3.5995287895202637 | KNN Loss: 3.591434955596924 | CLS Loss: 0.008093760348856449\n",
      "Epoch 161 / 200 | iteration 20 / 171 | Total Loss: 3.626004219055176 | KNN Loss: 3.600499391555786 | CLS Loss: 0.02550475299358368\n",
      "Epoch 161 / 200 | iteration 30 / 171 | Total Loss: 3.5954225063323975 | KNN Loss: 3.5732545852661133 | CLS Loss: 0.022167831659317017\n",
      "Epoch 161 / 200 | iteration 40 / 171 | Total Loss: 3.628159284591675 | KNN Loss: 3.621516704559326 | CLS Loss: 0.0066426536068320274\n",
      "Epoch 161 / 200 | iteration 50 / 171 | Total Loss: 3.6076526641845703 | KNN Loss: 3.6032769680023193 | CLS Loss: 0.004375687800347805\n",
      "Epoch 161 / 200 | iteration 60 / 171 | Total Loss: 3.6523051261901855 | KNN Loss: 3.643080949783325 | CLS Loss: 0.009224104695022106\n",
      "Epoch 161 / 200 | iteration 70 / 171 | Total Loss: 3.642176389694214 | KNN Loss: 3.6376211643218994 | CLS Loss: 0.00455516716465354\n",
      "Epoch 161 / 200 | iteration 80 / 171 | Total Loss: 3.621065616607666 | KNN Loss: 3.6171140670776367 | CLS Loss: 0.003951436839997768\n",
      "Epoch 161 / 200 | iteration 90 / 171 | Total Loss: 3.6297237873077393 | KNN Loss: 3.619771957397461 | CLS Loss: 0.009951934218406677\n",
      "Epoch 161 / 200 | iteration 100 / 171 | Total Loss: 3.6116831302642822 | KNN Loss: 3.587759494781494 | CLS Loss: 0.023923596367239952\n",
      "Epoch 161 / 200 | iteration 110 / 171 | Total Loss: 3.5859615802764893 | KNN Loss: 3.5779242515563965 | CLS Loss: 0.008037278428673744\n",
      "Epoch 161 / 200 | iteration 120 / 171 | Total Loss: 3.6161205768585205 | KNN Loss: 3.608402967453003 | CLS Loss: 0.007717527914792299\n",
      "Epoch 161 / 200 | iteration 130 / 171 | Total Loss: 3.6136021614074707 | KNN Loss: 3.602757453918457 | CLS Loss: 0.010844680480659008\n",
      "Epoch 161 / 200 | iteration 140 / 171 | Total Loss: 3.675173044204712 | KNN Loss: 3.6440975666046143 | CLS Loss: 0.03107541799545288\n",
      "Epoch 161 / 200 | iteration 150 / 171 | Total Loss: 3.6242363452911377 | KNN Loss: 3.6129868030548096 | CLS Loss: 0.011249655857682228\n",
      "Epoch 161 / 200 | iteration 160 / 171 | Total Loss: 3.6815643310546875 | KNN Loss: 3.645779609680176 | CLS Loss: 0.03578466549515724\n",
      "Epoch 161 / 200 | iteration 170 / 171 | Total Loss: 3.5827584266662598 | KNN Loss: 3.575228691101074 | CLS Loss: 0.007529840338975191\n",
      "Epoch: 161, Loss: 3.6174, Train: 0.9968, Valid: 0.9868, Best: 0.9881\n",
      "Epoch 162 / 200 | iteration 0 / 171 | Total Loss: 3.591900587081909 | KNN Loss: 3.586139440536499 | CLS Loss: 0.005761124659329653\n",
      "Epoch 162 / 200 | iteration 10 / 171 | Total Loss: 3.5661003589630127 | KNN Loss: 3.563725709915161 | CLS Loss: 0.0023746641818434\n",
      "Epoch 162 / 200 | iteration 20 / 171 | Total Loss: 3.595684766769409 | KNN Loss: 3.5935497283935547 | CLS Loss: 0.002134960377588868\n",
      "Epoch 162 / 200 | iteration 30 / 171 | Total Loss: 3.5934343338012695 | KNN Loss: 3.581709384918213 | CLS Loss: 0.011724870651960373\n",
      "Epoch 162 / 200 | iteration 40 / 171 | Total Loss: 3.6266634464263916 | KNN Loss: 3.612332344055176 | CLS Loss: 0.014331193640828133\n",
      "Epoch 162 / 200 | iteration 50 / 171 | Total Loss: 3.5920610427856445 | KNN Loss: 3.5771002769470215 | CLS Loss: 0.014960747212171555\n",
      "Epoch 162 / 200 | iteration 60 / 171 | Total Loss: 3.626629590988159 | KNN Loss: 3.6044373512268066 | CLS Loss: 0.02219233289361\n",
      "Epoch 162 / 200 | iteration 70 / 171 | Total Loss: 3.5885512828826904 | KNN Loss: 3.5805416107177734 | CLS Loss: 0.008009565994143486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 / 200 | iteration 80 / 171 | Total Loss: 3.59816837310791 | KNN Loss: 3.584925889968872 | CLS Loss: 0.01324236486107111\n",
      "Epoch 162 / 200 | iteration 90 / 171 | Total Loss: 3.6189887523651123 | KNN Loss: 3.6036689281463623 | CLS Loss: 0.015319869853556156\n",
      "Epoch 162 / 200 | iteration 100 / 171 | Total Loss: 3.5916478633880615 | KNN Loss: 3.587113857269287 | CLS Loss: 0.004533973056823015\n",
      "Epoch 162 / 200 | iteration 110 / 171 | Total Loss: 3.647597074508667 | KNN Loss: 3.598750591278076 | CLS Loss: 0.048846494406461716\n",
      "Epoch 162 / 200 | iteration 120 / 171 | Total Loss: 3.620100498199463 | KNN Loss: 3.6078479290008545 | CLS Loss: 0.012252485379576683\n",
      "Epoch 162 / 200 | iteration 130 / 171 | Total Loss: 3.6257102489471436 | KNN Loss: 3.6220171451568604 | CLS Loss: 0.0036931296344846487\n",
      "Epoch 162 / 200 | iteration 140 / 171 | Total Loss: 3.60410475730896 | KNN Loss: 3.596083402633667 | CLS Loss: 0.008021265268325806\n",
      "Epoch 162 / 200 | iteration 150 / 171 | Total Loss: 3.6099836826324463 | KNN Loss: 3.5862152576446533 | CLS Loss: 0.023768382146954536\n",
      "Epoch 162 / 200 | iteration 160 / 171 | Total Loss: 3.643331289291382 | KNN Loss: 3.6330156326293945 | CLS Loss: 0.010315688326954842\n",
      "Epoch 162 / 200 | iteration 170 / 171 | Total Loss: 3.645975112915039 | KNN Loss: 3.6429314613342285 | CLS Loss: 0.0030435912776738405\n",
      "Epoch: 162, Loss: 3.6068, Train: 0.9972, Valid: 0.9869, Best: 0.9881\n",
      "Epoch 163 / 200 | iteration 0 / 171 | Total Loss: 3.681438446044922 | KNN Loss: 3.660069227218628 | CLS Loss: 0.021369241178035736\n",
      "Epoch 163 / 200 | iteration 10 / 171 | Total Loss: 3.619656801223755 | KNN Loss: 3.6165008544921875 | CLS Loss: 0.0031559327617287636\n",
      "Epoch 163 / 200 | iteration 20 / 171 | Total Loss: 3.5814807415008545 | KNN Loss: 3.568084716796875 | CLS Loss: 0.013396111316978931\n",
      "Epoch 163 / 200 | iteration 30 / 171 | Total Loss: 3.5948543548583984 | KNN Loss: 3.581861734390259 | CLS Loss: 0.01299265306442976\n",
      "Epoch 163 / 200 | iteration 40 / 171 | Total Loss: 3.5889604091644287 | KNN Loss: 3.582909345626831 | CLS Loss: 0.006051153875887394\n",
      "Epoch 163 / 200 | iteration 50 / 171 | Total Loss: 3.598426580429077 | KNN Loss: 3.5799269676208496 | CLS Loss: 0.01849971152842045\n",
      "Epoch 163 / 200 | iteration 60 / 171 | Total Loss: 3.638502597808838 | KNN Loss: 3.6359548568725586 | CLS Loss: 0.002547795418649912\n",
      "Epoch 163 / 200 | iteration 70 / 171 | Total Loss: 3.578399658203125 | KNN Loss: 3.5766987800598145 | CLS Loss: 0.001700776512734592\n",
      "Epoch 163 / 200 | iteration 80 / 171 | Total Loss: 3.6115005016326904 | KNN Loss: 3.6074914932250977 | CLS Loss: 0.004008895251899958\n",
      "Epoch 163 / 200 | iteration 90 / 171 | Total Loss: 3.6014957427978516 | KNN Loss: 3.586815118789673 | CLS Loss: 0.014680619351565838\n",
      "Epoch 163 / 200 | iteration 100 / 171 | Total Loss: 3.6125128269195557 | KNN Loss: 3.602834939956665 | CLS Loss: 0.009677993133664131\n",
      "Epoch 163 / 200 | iteration 110 / 171 | Total Loss: 3.588620662689209 | KNN Loss: 3.579827308654785 | CLS Loss: 0.00879331398755312\n",
      "Epoch 163 / 200 | iteration 120 / 171 | Total Loss: 3.618802785873413 | KNN Loss: 3.60278582572937 | CLS Loss: 0.016016904264688492\n",
      "Epoch 163 / 200 | iteration 130 / 171 | Total Loss: 3.628993272781372 | KNN Loss: 3.610996961593628 | CLS Loss: 0.017996428534388542\n",
      "Epoch 163 / 200 | iteration 140 / 171 | Total Loss: 3.695913076400757 | KNN Loss: 3.690244436264038 | CLS Loss: 0.0056687528267502785\n",
      "Epoch 163 / 200 | iteration 150 / 171 | Total Loss: 3.58048677444458 | KNN Loss: 3.5754292011260986 | CLS Loss: 0.005057635251432657\n",
      "Epoch 163 / 200 | iteration 160 / 171 | Total Loss: 3.5950586795806885 | KNN Loss: 3.591493844985962 | CLS Loss: 0.0035649477504193783\n",
      "Epoch 163 / 200 | iteration 170 / 171 | Total Loss: 3.596648693084717 | KNN Loss: 3.591066360473633 | CLS Loss: 0.005582342389971018\n",
      "Epoch: 163, Loss: 3.6083, Train: 0.9967, Valid: 0.9861, Best: 0.9881\n",
      "Epoch 164 / 200 | iteration 0 / 171 | Total Loss: 3.6021556854248047 | KNN Loss: 3.582540988922119 | CLS Loss: 0.019614696502685547\n",
      "Epoch 164 / 200 | iteration 10 / 171 | Total Loss: 3.5841293334960938 | KNN Loss: 3.576809883117676 | CLS Loss: 0.007319385185837746\n",
      "Epoch 164 / 200 | iteration 20 / 171 | Total Loss: 3.63047456741333 | KNN Loss: 3.621880531311035 | CLS Loss: 0.008594008162617683\n",
      "Epoch 164 / 200 | iteration 30 / 171 | Total Loss: 3.5826869010925293 | KNN Loss: 3.5732173919677734 | CLS Loss: 0.009469405747950077\n",
      "Epoch 164 / 200 | iteration 40 / 171 | Total Loss: 3.5767698287963867 | KNN Loss: 3.5683541297912598 | CLS Loss: 0.008415629155933857\n",
      "Epoch 164 / 200 | iteration 50 / 171 | Total Loss: 3.59858775138855 | KNN Loss: 3.5825865268707275 | CLS Loss: 0.0160012599080801\n",
      "Epoch 164 / 200 | iteration 60 / 171 | Total Loss: 3.5917954444885254 | KNN Loss: 3.5712852478027344 | CLS Loss: 0.0205101165920496\n",
      "Epoch 164 / 200 | iteration 70 / 171 | Total Loss: 3.622363567352295 | KNN Loss: 3.616316795349121 | CLS Loss: 0.006046745926141739\n",
      "Epoch 164 / 200 | iteration 80 / 171 | Total Loss: 3.6227197647094727 | KNN Loss: 3.6197400093078613 | CLS Loss: 0.002979832701385021\n",
      "Epoch 164 / 200 | iteration 90 / 171 | Total Loss: 3.6006453037261963 | KNN Loss: 3.595442056655884 | CLS Loss: 0.005203334614634514\n",
      "Epoch 164 / 200 | iteration 100 / 171 | Total Loss: 3.5953152179718018 | KNN Loss: 3.59332537651062 | CLS Loss: 0.001989818876609206\n",
      "Epoch 164 / 200 | iteration 110 / 171 | Total Loss: 3.5925071239471436 | KNN Loss: 3.5847251415252686 | CLS Loss: 0.0077818939462304115\n",
      "Epoch 164 / 200 | iteration 120 / 171 | Total Loss: 3.6115171909332275 | KNN Loss: 3.602991819381714 | CLS Loss: 0.00852530263364315\n",
      "Epoch 164 / 200 | iteration 130 / 171 | Total Loss: 3.6379220485687256 | KNN Loss: 3.6178369522094727 | CLS Loss: 0.02008514665067196\n",
      "Epoch 164 / 200 | iteration 140 / 171 | Total Loss: 3.589975118637085 | KNN Loss: 3.5768706798553467 | CLS Loss: 0.013104439713060856\n",
      "Epoch 164 / 200 | iteration 150 / 171 | Total Loss: 3.6296823024749756 | KNN Loss: 3.6145036220550537 | CLS Loss: 0.01517877820879221\n",
      "Epoch 164 / 200 | iteration 160 / 171 | Total Loss: 3.6261661052703857 | KNN Loss: 3.608081340789795 | CLS Loss: 0.018084757030010223\n",
      "Epoch 164 / 200 | iteration 170 / 171 | Total Loss: 3.613077163696289 | KNN Loss: 3.605558395385742 | CLS Loss: 0.007518835831433535\n",
      "Epoch: 164, Loss: 3.6125, Train: 0.9973, Valid: 0.9872, Best: 0.9881\n",
      "Epoch 165 / 200 | iteration 0 / 171 | Total Loss: 3.597970724105835 | KNN Loss: 3.5831456184387207 | CLS Loss: 0.014825105667114258\n",
      "Epoch 165 / 200 | iteration 10 / 171 | Total Loss: 3.568615436553955 | KNN Loss: 3.5675880908966064 | CLS Loss: 0.0010272655636072159\n",
      "Epoch 165 / 200 | iteration 20 / 171 | Total Loss: 3.5944759845733643 | KNN Loss: 3.5828585624694824 | CLS Loss: 0.011617488227784634\n",
      "Epoch 165 / 200 | iteration 30 / 171 | Total Loss: 3.567462921142578 | KNN Loss: 3.563262701034546 | CLS Loss: 0.0042002941481769085\n",
      "Epoch 165 / 200 | iteration 40 / 171 | Total Loss: 3.6324682235717773 | KNN Loss: 3.6218483448028564 | CLS Loss: 0.01061997003853321\n",
      "Epoch 165 / 200 | iteration 50 / 171 | Total Loss: 3.630180835723877 | KNN Loss: 3.6186392307281494 | CLS Loss: 0.011541541665792465\n",
      "Epoch 165 / 200 | iteration 60 / 171 | Total Loss: 3.6122961044311523 | KNN Loss: 3.599500894546509 | CLS Loss: 0.01279528345912695\n",
      "Epoch 165 / 200 | iteration 70 / 171 | Total Loss: 3.5696873664855957 | KNN Loss: 3.565699577331543 | CLS Loss: 0.0039876908995211124\n",
      "Epoch 165 / 200 | iteration 80 / 171 | Total Loss: 3.5809803009033203 | KNN Loss: 3.5776941776275635 | CLS Loss: 0.0032860413193702698\n",
      "Epoch 165 / 200 | iteration 90 / 171 | Total Loss: 3.5970113277435303 | KNN Loss: 3.5943925380706787 | CLS Loss: 0.002618908416479826\n",
      "Epoch 165 / 200 | iteration 100 / 171 | Total Loss: 3.6198554039001465 | KNN Loss: 3.5881848335266113 | CLS Loss: 0.0316704623401165\n",
      "Epoch 165 / 200 | iteration 110 / 171 | Total Loss: 3.6414849758148193 | KNN Loss: 3.6206448078155518 | CLS Loss: 0.020840218290686607\n",
      "Epoch 165 / 200 | iteration 120 / 171 | Total Loss: 3.6208715438842773 | KNN Loss: 3.6046361923217773 | CLS Loss: 0.01623537391424179\n",
      "Epoch 165 / 200 | iteration 130 / 171 | Total Loss: 3.6180367469787598 | KNN Loss: 3.6147563457489014 | CLS Loss: 0.0032804335933178663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 / 200 | iteration 140 / 171 | Total Loss: 3.566638946533203 | KNN Loss: 3.55916428565979 | CLS Loss: 0.007474665064364672\n",
      "Epoch 165 / 200 | iteration 150 / 171 | Total Loss: 3.650378465652466 | KNN Loss: 3.644834041595459 | CLS Loss: 0.0055445232428610325\n",
      "Epoch 165 / 200 | iteration 160 / 171 | Total Loss: 3.650665044784546 | KNN Loss: 3.6418678760528564 | CLS Loss: 0.00879719015210867\n",
      "Epoch 165 / 200 | iteration 170 / 171 | Total Loss: 3.638160228729248 | KNN Loss: 3.626802444458008 | CLS Loss: 0.01135767437517643\n",
      "Epoch: 165, Loss: 3.6076, Train: 0.9957, Valid: 0.9862, Best: 0.9881\n",
      "Epoch 166 / 200 | iteration 0 / 171 | Total Loss: 3.5909039974212646 | KNN Loss: 3.568639039993286 | CLS Loss: 0.022265035659074783\n",
      "Epoch 166 / 200 | iteration 10 / 171 | Total Loss: 3.6396291255950928 | KNN Loss: 3.631071090698242 | CLS Loss: 0.008558094501495361\n",
      "Epoch 166 / 200 | iteration 20 / 171 | Total Loss: 3.623832941055298 | KNN Loss: 3.615786552429199 | CLS Loss: 0.008046336472034454\n",
      "Epoch 166 / 200 | iteration 30 / 171 | Total Loss: 3.6487889289855957 | KNN Loss: 3.637784242630005 | CLS Loss: 0.011004574596881866\n",
      "Epoch 166 / 200 | iteration 40 / 171 | Total Loss: 3.6008312702178955 | KNN Loss: 3.5838160514831543 | CLS Loss: 0.01701510325074196\n",
      "Epoch 166 / 200 | iteration 50 / 171 | Total Loss: 3.5768914222717285 | KNN Loss: 3.566270589828491 | CLS Loss: 0.010620719753205776\n",
      "Epoch 166 / 200 | iteration 60 / 171 | Total Loss: 3.5975863933563232 | KNN Loss: 3.583625555038452 | CLS Loss: 0.0139608820900321\n",
      "Epoch 166 / 200 | iteration 70 / 171 | Total Loss: 3.629424810409546 | KNN Loss: 3.623863935470581 | CLS Loss: 0.005560831632465124\n",
      "Epoch 166 / 200 | iteration 80 / 171 | Total Loss: 3.597243070602417 | KNN Loss: 3.578577756881714 | CLS Loss: 0.018665213137865067\n",
      "Epoch 166 / 200 | iteration 90 / 171 | Total Loss: 3.5724377632141113 | KNN Loss: 3.571272611618042 | CLS Loss: 0.0011651536915451288\n",
      "Epoch 166 / 200 | iteration 100 / 171 | Total Loss: 3.6005172729492188 | KNN Loss: 3.59858775138855 | CLS Loss: 0.001929550082422793\n",
      "Epoch 166 / 200 | iteration 110 / 171 | Total Loss: 3.6132757663726807 | KNN Loss: 3.597259521484375 | CLS Loss: 0.016016336157917976\n",
      "Epoch 166 / 200 | iteration 120 / 171 | Total Loss: 3.624779224395752 | KNN Loss: 3.611276388168335 | CLS Loss: 0.01350276917219162\n",
      "Epoch 166 / 200 | iteration 130 / 171 | Total Loss: 3.636810541152954 | KNN Loss: 3.6210501194000244 | CLS Loss: 0.015760334208607674\n",
      "Epoch 166 / 200 | iteration 140 / 171 | Total Loss: 3.6025443077087402 | KNN Loss: 3.5900936126708984 | CLS Loss: 0.012450726702809334\n",
      "Epoch 166 / 200 | iteration 150 / 171 | Total Loss: 3.665823459625244 | KNN Loss: 3.655289649963379 | CLS Loss: 0.010533714666962624\n",
      "Epoch 166 / 200 | iteration 160 / 171 | Total Loss: 3.58640456199646 | KNN Loss: 3.5712838172912598 | CLS Loss: 0.015120714902877808\n",
      "Epoch 166 / 200 | iteration 170 / 171 | Total Loss: 3.5900256633758545 | KNN Loss: 3.568086624145508 | CLS Loss: 0.021939007565379143\n",
      "Epoch: 166, Loss: 3.6105, Train: 0.9965, Valid: 0.9865, Best: 0.9881\n",
      "Epoch 167 / 200 | iteration 0 / 171 | Total Loss: 3.569160223007202 | KNN Loss: 3.5678319931030273 | CLS Loss: 0.0013281535357236862\n",
      "Epoch 167 / 200 | iteration 10 / 171 | Total Loss: 3.570904016494751 | KNN Loss: 3.5681815147399902 | CLS Loss: 0.002722544828429818\n",
      "Epoch 167 / 200 | iteration 20 / 171 | Total Loss: 3.5989837646484375 | KNN Loss: 3.589661121368408 | CLS Loss: 0.009322594851255417\n",
      "Epoch 167 / 200 | iteration 30 / 171 | Total Loss: 3.6368279457092285 | KNN Loss: 3.6216843128204346 | CLS Loss: 0.015143539756536484\n",
      "Epoch 167 / 200 | iteration 40 / 171 | Total Loss: 3.5959017276763916 | KNN Loss: 3.585217237472534 | CLS Loss: 0.010684527456760406\n",
      "Epoch 167 / 200 | iteration 50 / 171 | Total Loss: 3.6161880493164062 | KNN Loss: 3.5665273666381836 | CLS Loss: 0.04966079071164131\n",
      "Epoch 167 / 200 | iteration 60 / 171 | Total Loss: 3.638892889022827 | KNN Loss: 3.6256909370422363 | CLS Loss: 0.013201870955526829\n",
      "Epoch 167 / 200 | iteration 70 / 171 | Total Loss: 3.6700053215026855 | KNN Loss: 3.6668155193328857 | CLS Loss: 0.003189692972227931\n",
      "Epoch 167 / 200 | iteration 80 / 171 | Total Loss: 3.619178056716919 | KNN Loss: 3.615291118621826 | CLS Loss: 0.003886913415044546\n",
      "Epoch 167 / 200 | iteration 90 / 171 | Total Loss: 3.5578646659851074 | KNN Loss: 3.549114942550659 | CLS Loss: 0.008749688044190407\n",
      "Epoch 167 / 200 | iteration 100 / 171 | Total Loss: 3.5732717514038086 | KNN Loss: 3.569549322128296 | CLS Loss: 0.003722355468198657\n",
      "Epoch 167 / 200 | iteration 110 / 171 | Total Loss: 3.655566692352295 | KNN Loss: 3.637136459350586 | CLS Loss: 0.018430326133966446\n",
      "Epoch 167 / 200 | iteration 120 / 171 | Total Loss: 3.599705934524536 | KNN Loss: 3.5784778594970703 | CLS Loss: 0.021228106692433357\n",
      "Epoch 167 / 200 | iteration 130 / 171 | Total Loss: 3.6065354347229004 | KNN Loss: 3.598637580871582 | CLS Loss: 0.00789793860167265\n",
      "Epoch 167 / 200 | iteration 140 / 171 | Total Loss: 3.6865384578704834 | KNN Loss: 3.672602415084839 | CLS Loss: 0.013935989700257778\n",
      "Epoch 167 / 200 | iteration 150 / 171 | Total Loss: 3.6307125091552734 | KNN Loss: 3.6244609355926514 | CLS Loss: 0.006251606624573469\n",
      "Epoch 167 / 200 | iteration 160 / 171 | Total Loss: 3.5920186042785645 | KNN Loss: 3.583712100982666 | CLS Loss: 0.008306429721415043\n",
      "Epoch 167 / 200 | iteration 170 / 171 | Total Loss: 3.5862855911254883 | KNN Loss: 3.5823047161102295 | CLS Loss: 0.003980771638453007\n",
      "Epoch: 167, Loss: 3.6114, Train: 0.9973, Valid: 0.9870, Best: 0.9881\n",
      "Epoch 168 / 200 | iteration 0 / 171 | Total Loss: 3.595439910888672 | KNN Loss: 3.591813802719116 | CLS Loss: 0.003626049030572176\n",
      "Epoch 168 / 200 | iteration 10 / 171 | Total Loss: 3.582277536392212 | KNN Loss: 3.5803937911987305 | CLS Loss: 0.0018838468240574002\n",
      "Epoch 168 / 200 | iteration 20 / 171 | Total Loss: 3.613499879837036 | KNN Loss: 3.607213020324707 | CLS Loss: 0.006286753341555595\n",
      "Epoch 168 / 200 | iteration 30 / 171 | Total Loss: 3.6104116439819336 | KNN Loss: 3.6052916049957275 | CLS Loss: 0.005120003595948219\n",
      "Epoch 168 / 200 | iteration 40 / 171 | Total Loss: 3.6773064136505127 | KNN Loss: 3.6534903049468994 | CLS Loss: 0.02381613478064537\n",
      "Epoch 168 / 200 | iteration 50 / 171 | Total Loss: 3.5896480083465576 | KNN Loss: 3.5835154056549072 | CLS Loss: 0.00613250071182847\n",
      "Epoch 168 / 200 | iteration 60 / 171 | Total Loss: 3.6265132427215576 | KNN Loss: 3.61537766456604 | CLS Loss: 0.011135516688227654\n",
      "Epoch 168 / 200 | iteration 70 / 171 | Total Loss: 3.5798420906066895 | KNN Loss: 3.5674006938934326 | CLS Loss: 0.012441450729966164\n",
      "Epoch 168 / 200 | iteration 80 / 171 | Total Loss: 3.557565450668335 | KNN Loss: 3.5558066368103027 | CLS Loss: 0.0017588995397090912\n",
      "Epoch 168 / 200 | iteration 90 / 171 | Total Loss: 3.6334476470947266 | KNN Loss: 3.61245059967041 | CLS Loss: 0.02099696174263954\n",
      "Epoch 168 / 200 | iteration 100 / 171 | Total Loss: 3.6212966442108154 | KNN Loss: 3.6132335662841797 | CLS Loss: 0.008063143119215965\n",
      "Epoch 168 / 200 | iteration 110 / 171 | Total Loss: 3.59445858001709 | KNN Loss: 3.583146095275879 | CLS Loss: 0.011312560178339481\n",
      "Epoch 168 / 200 | iteration 120 / 171 | Total Loss: 3.5991439819335938 | KNN Loss: 3.5963690280914307 | CLS Loss: 0.0027749422006309032\n",
      "Epoch 168 / 200 | iteration 130 / 171 | Total Loss: 3.5819082260131836 | KNN Loss: 3.581028699874878 | CLS Loss: 0.000879608211107552\n",
      "Epoch 168 / 200 | iteration 140 / 171 | Total Loss: 3.6114766597747803 | KNN Loss: 3.597653388977051 | CLS Loss: 0.013823223300278187\n",
      "Epoch 168 / 200 | iteration 150 / 171 | Total Loss: 3.5877246856689453 | KNN Loss: 3.5729098320007324 | CLS Loss: 0.014814883470535278\n",
      "Epoch 168 / 200 | iteration 160 / 171 | Total Loss: 3.583414316177368 | KNN Loss: 3.575613021850586 | CLS Loss: 0.007801273837685585\n",
      "Epoch 168 / 200 | iteration 170 / 171 | Total Loss: 3.6181588172912598 | KNN Loss: 3.6040124893188477 | CLS Loss: 0.014146399684250355\n",
      "Epoch: 168, Loss: 3.5996, Train: 0.9975, Valid: 0.9870, Best: 0.9881\n",
      "Epoch 169 / 200 | iteration 0 / 171 | Total Loss: 3.6055212020874023 | KNN Loss: 3.5995373725891113 | CLS Loss: 0.005983712617307901\n",
      "Epoch 169 / 200 | iteration 10 / 171 | Total Loss: 3.5849733352661133 | KNN Loss: 3.582827568054199 | CLS Loss: 0.002145705046132207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 / 200 | iteration 20 / 171 | Total Loss: 3.5800859928131104 | KNN Loss: 3.572683572769165 | CLS Loss: 0.007402312941849232\n",
      "Epoch 169 / 200 | iteration 30 / 171 | Total Loss: 3.6201202869415283 | KNN Loss: 3.6089909076690674 | CLS Loss: 0.011129427701234818\n",
      "Epoch 169 / 200 | iteration 40 / 171 | Total Loss: 3.6165590286254883 | KNN Loss: 3.613389492034912 | CLS Loss: 0.0031694984063506126\n",
      "Epoch 169 / 200 | iteration 50 / 171 | Total Loss: 3.6751906871795654 | KNN Loss: 3.64603590965271 | CLS Loss: 0.02915477566421032\n",
      "Epoch 169 / 200 | iteration 60 / 171 | Total Loss: 3.593156576156616 | KNN Loss: 3.5811197757720947 | CLS Loss: 0.012036804109811783\n",
      "Epoch 169 / 200 | iteration 70 / 171 | Total Loss: 3.574723482131958 | KNN Loss: 3.5601401329040527 | CLS Loss: 0.014583430252969265\n",
      "Epoch 169 / 200 | iteration 80 / 171 | Total Loss: 3.6079561710357666 | KNN Loss: 3.597006320953369 | CLS Loss: 0.010949870571494102\n",
      "Epoch 169 / 200 | iteration 90 / 171 | Total Loss: 3.6253714561462402 | KNN Loss: 3.6111669540405273 | CLS Loss: 0.014204392209649086\n",
      "Epoch 169 / 200 | iteration 100 / 171 | Total Loss: 3.5972437858581543 | KNN Loss: 3.585514545440674 | CLS Loss: 0.011729235760867596\n",
      "Epoch 169 / 200 | iteration 110 / 171 | Total Loss: 3.6394476890563965 | KNN Loss: 3.6330912113189697 | CLS Loss: 0.006356464233249426\n",
      "Epoch 169 / 200 | iteration 120 / 171 | Total Loss: 3.6182613372802734 | KNN Loss: 3.60758376121521 | CLS Loss: 0.010677671991288662\n",
      "Epoch 169 / 200 | iteration 130 / 171 | Total Loss: 3.612513780593872 | KNN Loss: 3.6109726428985596 | CLS Loss: 0.001541254692710936\n",
      "Epoch 169 / 200 | iteration 140 / 171 | Total Loss: 3.6189565658569336 | KNN Loss: 3.6132760047912598 | CLS Loss: 0.005680553149431944\n",
      "Epoch 169 / 200 | iteration 150 / 171 | Total Loss: 3.573223352432251 | KNN Loss: 3.5707321166992188 | CLS Loss: 0.0024911307264119387\n",
      "Epoch 169 / 200 | iteration 160 / 171 | Total Loss: 3.5927014350891113 | KNN Loss: 3.579232692718506 | CLS Loss: 0.013468743301928043\n",
      "Epoch 169 / 200 | iteration 170 / 171 | Total Loss: 3.639777183532715 | KNN Loss: 3.636936902999878 | CLS Loss: 0.00284030893817544\n",
      "Epoch: 169, Loss: 3.6072, Train: 0.9974, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 170 / 200 | iteration 0 / 171 | Total Loss: 3.6452386379241943 | KNN Loss: 3.638845682144165 | CLS Loss: 0.006393012590706348\n",
      "Epoch 170 / 200 | iteration 10 / 171 | Total Loss: 3.6145286560058594 | KNN Loss: 3.6091110706329346 | CLS Loss: 0.0054176668636500835\n",
      "Epoch 170 / 200 | iteration 20 / 171 | Total Loss: 3.642442226409912 | KNN Loss: 3.614515542984009 | CLS Loss: 0.027926642447710037\n",
      "Epoch 170 / 200 | iteration 30 / 171 | Total Loss: 3.6004905700683594 | KNN Loss: 3.5804011821746826 | CLS Loss: 0.020089447498321533\n",
      "Epoch 170 / 200 | iteration 40 / 171 | Total Loss: 3.588392496109009 | KNN Loss: 3.5786871910095215 | CLS Loss: 0.009705284610390663\n",
      "Epoch 170 / 200 | iteration 50 / 171 | Total Loss: 3.5866384506225586 | KNN Loss: 3.5692648887634277 | CLS Loss: 0.01737355627119541\n",
      "Epoch 170 / 200 | iteration 60 / 171 | Total Loss: 3.591845989227295 | KNN Loss: 3.5766921043395996 | CLS Loss: 0.015153921209275723\n",
      "Epoch 170 / 200 | iteration 70 / 171 | Total Loss: 3.586421489715576 | KNN Loss: 3.583603858947754 | CLS Loss: 0.0028175916522741318\n",
      "Epoch 170 / 200 | iteration 80 / 171 | Total Loss: 3.623615264892578 | KNN Loss: 3.6185293197631836 | CLS Loss: 0.005085974931716919\n",
      "Epoch 170 / 200 | iteration 90 / 171 | Total Loss: 3.5740644931793213 | KNN Loss: 3.563711643218994 | CLS Loss: 0.010352949611842632\n",
      "Epoch 170 / 200 | iteration 100 / 171 | Total Loss: 3.6232898235321045 | KNN Loss: 3.6212825775146484 | CLS Loss: 0.0020071426406502724\n",
      "Epoch 170 / 200 | iteration 110 / 171 | Total Loss: 3.609518527984619 | KNN Loss: 3.583003520965576 | CLS Loss: 0.026515111327171326\n",
      "Epoch 170 / 200 | iteration 120 / 171 | Total Loss: 3.5955164432525635 | KNN Loss: 3.587218999862671 | CLS Loss: 0.008297394961118698\n",
      "Epoch 170 / 200 | iteration 130 / 171 | Total Loss: 3.5876448154449463 | KNN Loss: 3.568692684173584 | CLS Loss: 0.01895204745233059\n",
      "Epoch 170 / 200 | iteration 140 / 171 | Total Loss: 3.6122140884399414 | KNN Loss: 3.6059441566467285 | CLS Loss: 0.006269895005971193\n",
      "Epoch 170 / 200 | iteration 150 / 171 | Total Loss: 3.5810670852661133 | KNN Loss: 3.579127073287964 | CLS Loss: 0.0019399605225771666\n",
      "Epoch 170 / 200 | iteration 160 / 171 | Total Loss: 3.5914061069488525 | KNN Loss: 3.5815534591674805 | CLS Loss: 0.009852534160017967\n",
      "Epoch 170 / 200 | iteration 170 / 171 | Total Loss: 3.6700005531311035 | KNN Loss: 3.6633567810058594 | CLS Loss: 0.0066437493078410625\n",
      "Epoch: 170, Loss: 3.6075, Train: 0.9979, Valid: 0.9874, Best: 0.9881\n",
      "Epoch 171 / 200 | iteration 0 / 171 | Total Loss: 3.59541654586792 | KNN Loss: 3.583580732345581 | CLS Loss: 0.011835872195661068\n",
      "Epoch 171 / 200 | iteration 10 / 171 | Total Loss: 3.607175588607788 | KNN Loss: 3.6056642532348633 | CLS Loss: 0.0015112236142158508\n",
      "Epoch 171 / 200 | iteration 20 / 171 | Total Loss: 3.594472885131836 | KNN Loss: 3.5749948024749756 | CLS Loss: 0.019478149712085724\n",
      "Epoch 171 / 200 | iteration 30 / 171 | Total Loss: 3.6018226146698 | KNN Loss: 3.5860626697540283 | CLS Loss: 0.015759998932480812\n",
      "Epoch 171 / 200 | iteration 40 / 171 | Total Loss: 3.59421706199646 | KNN Loss: 3.5726828575134277 | CLS Loss: 0.0215341504663229\n",
      "Epoch 171 / 200 | iteration 50 / 171 | Total Loss: 3.5806350708007812 | KNN Loss: 3.569463014602661 | CLS Loss: 0.011172016151249409\n",
      "Epoch 171 / 200 | iteration 60 / 171 | Total Loss: 3.605973958969116 | KNN Loss: 3.6007401943206787 | CLS Loss: 0.005233881063759327\n",
      "Epoch 171 / 200 | iteration 70 / 171 | Total Loss: 3.619025707244873 | KNN Loss: 3.608036518096924 | CLS Loss: 0.010989194735884666\n",
      "Epoch 171 / 200 | iteration 80 / 171 | Total Loss: 3.5902950763702393 | KNN Loss: 3.5753092765808105 | CLS Loss: 0.014985775575041771\n",
      "Epoch 171 / 200 | iteration 90 / 171 | Total Loss: 3.62115478515625 | KNN Loss: 3.613518476486206 | CLS Loss: 0.007636386901140213\n",
      "Epoch 171 / 200 | iteration 100 / 171 | Total Loss: 3.628304958343506 | KNN Loss: 3.6049745082855225 | CLS Loss: 0.023330535739660263\n",
      "Epoch 171 / 200 | iteration 110 / 171 | Total Loss: 3.6489310264587402 | KNN Loss: 3.6422431468963623 | CLS Loss: 0.006687814369797707\n",
      "Epoch 171 / 200 | iteration 120 / 171 | Total Loss: 3.611494302749634 | KNN Loss: 3.605938673019409 | CLS Loss: 0.005555571522563696\n",
      "Epoch 171 / 200 | iteration 130 / 171 | Total Loss: 3.6322619915008545 | KNN Loss: 3.6118931770324707 | CLS Loss: 0.020368771627545357\n",
      "Epoch 171 / 200 | iteration 140 / 171 | Total Loss: 3.605215072631836 | KNN Loss: 3.5775654315948486 | CLS Loss: 0.027649570256471634\n",
      "Epoch 171 / 200 | iteration 150 / 171 | Total Loss: 3.5952951908111572 | KNN Loss: 3.571603536605835 | CLS Loss: 0.02369164675474167\n",
      "Epoch 171 / 200 | iteration 160 / 171 | Total Loss: 3.5859618186950684 | KNN Loss: 3.5721545219421387 | CLS Loss: 0.013807208277285099\n",
      "Epoch 171 / 200 | iteration 170 / 171 | Total Loss: 3.570060968399048 | KNN Loss: 3.5631320476531982 | CLS Loss: 0.0069289375096559525\n",
      "Epoch: 171, Loss: 3.6115, Train: 0.9975, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 172 / 200 | iteration 0 / 171 | Total Loss: 3.6127800941467285 | KNN Loss: 3.590310573577881 | CLS Loss: 0.022469500079751015\n",
      "Epoch 172 / 200 | iteration 10 / 171 | Total Loss: 3.559091806411743 | KNN Loss: 3.552177667617798 | CLS Loss: 0.006914079189300537\n",
      "Epoch 172 / 200 | iteration 20 / 171 | Total Loss: 3.6127710342407227 | KNN Loss: 3.6010241508483887 | CLS Loss: 0.0117469048127532\n",
      "Epoch 172 / 200 | iteration 30 / 171 | Total Loss: 3.6220476627349854 | KNN Loss: 3.6182241439819336 | CLS Loss: 0.0038235587999224663\n",
      "Epoch 172 / 200 | iteration 40 / 171 | Total Loss: 3.570657730102539 | KNN Loss: 3.5582985877990723 | CLS Loss: 0.012359133921563625\n",
      "Epoch 172 / 200 | iteration 50 / 171 | Total Loss: 3.641964912414551 | KNN Loss: 3.612297773361206 | CLS Loss: 0.029667099937796593\n",
      "Epoch 172 / 200 | iteration 60 / 171 | Total Loss: 3.5676019191741943 | KNN Loss: 3.5623698234558105 | CLS Loss: 0.005232187919318676\n",
      "Epoch 172 / 200 | iteration 70 / 171 | Total Loss: 3.5910873413085938 | KNN Loss: 3.5822267532348633 | CLS Loss: 0.008860548958182335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 / 200 | iteration 80 / 171 | Total Loss: 3.6310698986053467 | KNN Loss: 3.6195900440216064 | CLS Loss: 0.011479861102998257\n",
      "Epoch 172 / 200 | iteration 90 / 171 | Total Loss: 3.6158447265625 | KNN Loss: 3.5708298683166504 | CLS Loss: 0.04501485452055931\n",
      "Epoch 172 / 200 | iteration 100 / 171 | Total Loss: 3.632399797439575 | KNN Loss: 3.629894495010376 | CLS Loss: 0.0025053992867469788\n",
      "Epoch 172 / 200 | iteration 110 / 171 | Total Loss: 3.60424542427063 | KNN Loss: 3.586005687713623 | CLS Loss: 0.018239634111523628\n",
      "Epoch 172 / 200 | iteration 120 / 171 | Total Loss: 3.5701873302459717 | KNN Loss: 3.562110185623169 | CLS Loss: 0.008077147416770458\n",
      "Epoch 172 / 200 | iteration 130 / 171 | Total Loss: 3.5933268070220947 | KNN Loss: 3.5916860103607178 | CLS Loss: 0.0016408308874815702\n",
      "Epoch 172 / 200 | iteration 140 / 171 | Total Loss: 3.588416814804077 | KNN Loss: 3.5773844718933105 | CLS Loss: 0.01103235874325037\n",
      "Epoch 172 / 200 | iteration 150 / 171 | Total Loss: 3.5487191677093506 | KNN Loss: 3.5424082279205322 | CLS Loss: 0.006311000324785709\n",
      "Epoch 172 / 200 | iteration 160 / 171 | Total Loss: 3.6176207065582275 | KNN Loss: 3.5940518379211426 | CLS Loss: 0.023568974807858467\n",
      "Epoch 172 / 200 | iteration 170 / 171 | Total Loss: 3.594505548477173 | KNN Loss: 3.583767890930176 | CLS Loss: 0.010737770237028599\n",
      "Epoch: 172, Loss: 3.6089, Train: 0.9950, Valid: 0.9854, Best: 0.9881\n",
      "Epoch 173 / 200 | iteration 0 / 171 | Total Loss: 3.629988670349121 | KNN Loss: 3.6156904697418213 | CLS Loss: 0.014298126101493835\n",
      "Epoch 173 / 200 | iteration 10 / 171 | Total Loss: 3.6331963539123535 | KNN Loss: 3.6231563091278076 | CLS Loss: 0.0100400997325778\n",
      "Epoch 173 / 200 | iteration 20 / 171 | Total Loss: 3.682267189025879 | KNN Loss: 3.658017158508301 | CLS Loss: 0.0242499727755785\n",
      "Epoch 173 / 200 | iteration 30 / 171 | Total Loss: 3.569033145904541 | KNN Loss: 3.557706832885742 | CLS Loss: 0.011326241306960583\n",
      "Epoch 173 / 200 | iteration 40 / 171 | Total Loss: 3.5937023162841797 | KNN Loss: 3.58246111869812 | CLS Loss: 0.011241281405091286\n",
      "Epoch 173 / 200 | iteration 50 / 171 | Total Loss: 3.694373607635498 | KNN Loss: 3.692563533782959 | CLS Loss: 0.0018101383466273546\n",
      "Epoch 173 / 200 | iteration 60 / 171 | Total Loss: 3.607707977294922 | KNN Loss: 3.601282835006714 | CLS Loss: 0.006425226107239723\n",
      "Epoch 173 / 200 | iteration 70 / 171 | Total Loss: 3.566654682159424 | KNN Loss: 3.5646586418151855 | CLS Loss: 0.001996148144826293\n",
      "Epoch 173 / 200 | iteration 80 / 171 | Total Loss: 3.601835012435913 | KNN Loss: 3.5934019088745117 | CLS Loss: 0.008433172479271889\n",
      "Epoch 173 / 200 | iteration 90 / 171 | Total Loss: 3.5855419635772705 | KNN Loss: 3.5659077167510986 | CLS Loss: 0.01963433064520359\n",
      "Epoch 173 / 200 | iteration 100 / 171 | Total Loss: 3.699812650680542 | KNN Loss: 3.67158579826355 | CLS Loss: 0.028226805850863457\n",
      "Epoch 173 / 200 | iteration 110 / 171 | Total Loss: 3.624840259552002 | KNN Loss: 3.587249279022217 | CLS Loss: 0.03759091719985008\n",
      "Epoch 173 / 200 | iteration 120 / 171 | Total Loss: 3.606414556503296 | KNN Loss: 3.6002745628356934 | CLS Loss: 0.0061399070546031\n",
      "Epoch 173 / 200 | iteration 130 / 171 | Total Loss: 3.577467203140259 | KNN Loss: 3.563424587249756 | CLS Loss: 0.014042654074728489\n",
      "Epoch 173 / 200 | iteration 140 / 171 | Total Loss: 3.5916075706481934 | KNN Loss: 3.5828166007995605 | CLS Loss: 0.008790909312665462\n",
      "Epoch 173 / 200 | iteration 150 / 171 | Total Loss: 3.647066593170166 | KNN Loss: 3.6390652656555176 | CLS Loss: 0.00800130981951952\n",
      "Epoch 173 / 200 | iteration 160 / 171 | Total Loss: 3.6902825832366943 | KNN Loss: 3.676142692565918 | CLS Loss: 0.014139977283775806\n",
      "Epoch 173 / 200 | iteration 170 / 171 | Total Loss: 3.6264922618865967 | KNN Loss: 3.6228582859039307 | CLS Loss: 0.003633989719673991\n",
      "Epoch: 173, Loss: 3.6168, Train: 0.9964, Valid: 0.9864, Best: 0.9881\n",
      "Epoch 174 / 200 | iteration 0 / 171 | Total Loss: 3.6118829250335693 | KNN Loss: 3.5886480808258057 | CLS Loss: 0.023234929889440536\n",
      "Epoch 174 / 200 | iteration 10 / 171 | Total Loss: 3.560544490814209 | KNN Loss: 3.5484609603881836 | CLS Loss: 0.012083555571734905\n",
      "Epoch 174 / 200 | iteration 20 / 171 | Total Loss: 3.6161651611328125 | KNN Loss: 3.5955328941345215 | CLS Loss: 0.020632212981581688\n",
      "Epoch 174 / 200 | iteration 30 / 171 | Total Loss: 3.611847162246704 | KNN Loss: 3.605057716369629 | CLS Loss: 0.006789504550397396\n",
      "Epoch 174 / 200 | iteration 40 / 171 | Total Loss: 3.6157095432281494 | KNN Loss: 3.6112914085388184 | CLS Loss: 0.004418116062879562\n",
      "Epoch 174 / 200 | iteration 50 / 171 | Total Loss: 3.5934932231903076 | KNN Loss: 3.591482400894165 | CLS Loss: 0.0020108334720134735\n",
      "Epoch 174 / 200 | iteration 60 / 171 | Total Loss: 3.5581424236297607 | KNN Loss: 3.55645489692688 | CLS Loss: 0.0016875860746949911\n",
      "Epoch 174 / 200 | iteration 70 / 171 | Total Loss: 3.663234233856201 | KNN Loss: 3.653846502304077 | CLS Loss: 0.009387653321027756\n",
      "Epoch 174 / 200 | iteration 80 / 171 | Total Loss: 3.586505889892578 | KNN Loss: 3.5671744346618652 | CLS Loss: 0.01933155581355095\n",
      "Epoch 174 / 200 | iteration 90 / 171 | Total Loss: 3.609011173248291 | KNN Loss: 3.5983755588531494 | CLS Loss: 0.010635537095367908\n",
      "Epoch 174 / 200 | iteration 100 / 171 | Total Loss: 3.6001975536346436 | KNN Loss: 3.598878860473633 | CLS Loss: 0.0013187500881031156\n",
      "Epoch 174 / 200 | iteration 110 / 171 | Total Loss: 3.6270954608917236 | KNN Loss: 3.6052448749542236 | CLS Loss: 0.02185061201453209\n",
      "Epoch 174 / 200 | iteration 120 / 171 | Total Loss: 3.6108264923095703 | KNN Loss: 3.60636830329895 | CLS Loss: 0.0044582015834748745\n",
      "Epoch 174 / 200 | iteration 130 / 171 | Total Loss: 3.5550127029418945 | KNN Loss: 3.5524086952209473 | CLS Loss: 0.0026041180826723576\n",
      "Epoch 174 / 200 | iteration 140 / 171 | Total Loss: 3.5774972438812256 | KNN Loss: 3.5717833042144775 | CLS Loss: 0.005714022554457188\n",
      "Epoch 174 / 200 | iteration 150 / 171 | Total Loss: 3.6376757621765137 | KNN Loss: 3.6245343685150146 | CLS Loss: 0.013141326606273651\n",
      "Epoch 174 / 200 | iteration 160 / 171 | Total Loss: 3.620906352996826 | KNN Loss: 3.6044766902923584 | CLS Loss: 0.016429781913757324\n",
      "Epoch 174 / 200 | iteration 170 / 171 | Total Loss: 3.6396560668945312 | KNN Loss: 3.634648084640503 | CLS Loss: 0.005008019506931305\n",
      "Epoch: 174, Loss: 3.6073, Train: 0.9972, Valid: 0.9855, Best: 0.9881\n",
      "Epoch 175 / 200 | iteration 0 / 171 | Total Loss: 3.573421001434326 | KNN Loss: 3.5654115676879883 | CLS Loss: 0.008009329438209534\n",
      "Epoch 175 / 200 | iteration 10 / 171 | Total Loss: 3.5779025554656982 | KNN Loss: 3.5687453746795654 | CLS Loss: 0.009157294407486916\n",
      "Epoch 175 / 200 | iteration 20 / 171 | Total Loss: 3.58455491065979 | KNN Loss: 3.581636428833008 | CLS Loss: 0.002918579149991274\n",
      "Epoch 175 / 200 | iteration 30 / 171 | Total Loss: 3.6110899448394775 | KNN Loss: 3.610318899154663 | CLS Loss: 0.0007710189092904329\n",
      "Epoch 175 / 200 | iteration 40 / 171 | Total Loss: 3.6378350257873535 | KNN Loss: 3.6323139667510986 | CLS Loss: 0.005520984064787626\n",
      "Epoch 175 / 200 | iteration 50 / 171 | Total Loss: 3.581575870513916 | KNN Loss: 3.571854591369629 | CLS Loss: 0.009721360169351101\n",
      "Epoch 175 / 200 | iteration 60 / 171 | Total Loss: 3.595499277114868 | KNN Loss: 3.5872669219970703 | CLS Loss: 0.008232463151216507\n",
      "Epoch 175 / 200 | iteration 70 / 171 | Total Loss: 3.6026108264923096 | KNN Loss: 3.595418691635132 | CLS Loss: 0.0071921683847904205\n",
      "Epoch 175 / 200 | iteration 80 / 171 | Total Loss: 3.6139023303985596 | KNN Loss: 3.6055173873901367 | CLS Loss: 0.008384856395423412\n",
      "Epoch 175 / 200 | iteration 90 / 171 | Total Loss: 3.585479497909546 | KNN Loss: 3.569260835647583 | CLS Loss: 0.01621858775615692\n",
      "Epoch 175 / 200 | iteration 100 / 171 | Total Loss: 3.665058135986328 | KNN Loss: 3.6558382511138916 | CLS Loss: 0.009219871833920479\n",
      "Epoch 175 / 200 | iteration 110 / 171 | Total Loss: 3.5876481533050537 | KNN Loss: 3.573505163192749 | CLS Loss: 0.014142881147563457\n",
      "Epoch 175 / 200 | iteration 120 / 171 | Total Loss: 3.610276222229004 | KNN Loss: 3.5932302474975586 | CLS Loss: 0.01704598218202591\n",
      "Epoch 175 / 200 | iteration 130 / 171 | Total Loss: 3.606088399887085 | KNN Loss: 3.5988852977752686 | CLS Loss: 0.007203141693025827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175 / 200 | iteration 140 / 171 | Total Loss: 3.677370071411133 | KNN Loss: 3.6745712757110596 | CLS Loss: 0.002798736561089754\n",
      "Epoch 175 / 200 | iteration 150 / 171 | Total Loss: 3.6616055965423584 | KNN Loss: 3.658848285675049 | CLS Loss: 0.002757239155471325\n",
      "Epoch 175 / 200 | iteration 160 / 171 | Total Loss: 3.6153523921966553 | KNN Loss: 3.5960094928741455 | CLS Loss: 0.019342787563800812\n",
      "Epoch 175 / 200 | iteration 170 / 171 | Total Loss: 3.623452663421631 | KNN Loss: 3.6061508655548096 | CLS Loss: 0.01730176992714405\n",
      "Epoch: 175, Loss: 3.6059, Train: 0.9951, Valid: 0.9851, Best: 0.9881\n",
      "Epoch 176 / 200 | iteration 0 / 171 | Total Loss: 3.6335887908935547 | KNN Loss: 3.613145112991333 | CLS Loss: 0.02044370397925377\n",
      "Epoch 176 / 200 | iteration 10 / 171 | Total Loss: 3.6115128993988037 | KNN Loss: 3.5786967277526855 | CLS Loss: 0.03281623497605324\n",
      "Epoch 176 / 200 | iteration 20 / 171 | Total Loss: 3.627920150756836 | KNN Loss: 3.6090309619903564 | CLS Loss: 0.01888924092054367\n",
      "Epoch 176 / 200 | iteration 30 / 171 | Total Loss: 3.644643783569336 | KNN Loss: 3.627699613571167 | CLS Loss: 0.01694408804178238\n",
      "Epoch 176 / 200 | iteration 40 / 171 | Total Loss: 3.5976858139038086 | KNN Loss: 3.5892646312713623 | CLS Loss: 0.008421231061220169\n",
      "Epoch 176 / 200 | iteration 50 / 171 | Total Loss: 3.613671064376831 | KNN Loss: 3.599968671798706 | CLS Loss: 0.013702450320124626\n",
      "Epoch 176 / 200 | iteration 60 / 171 | Total Loss: 3.5996451377868652 | KNN Loss: 3.5962445735931396 | CLS Loss: 0.0034005206543952227\n",
      "Epoch 176 / 200 | iteration 70 / 171 | Total Loss: 3.5957798957824707 | KNN Loss: 3.584059000015259 | CLS Loss: 0.011720951646566391\n",
      "Epoch 176 / 200 | iteration 80 / 171 | Total Loss: 3.578524112701416 | KNN Loss: 3.57655930519104 | CLS Loss: 0.0019649025052785873\n",
      "Epoch 176 / 200 | iteration 90 / 171 | Total Loss: 3.6272666454315186 | KNN Loss: 3.5909018516540527 | CLS Loss: 0.03636486828327179\n",
      "Epoch 176 / 200 | iteration 100 / 171 | Total Loss: 3.6096911430358887 | KNN Loss: 3.598179578781128 | CLS Loss: 0.011511590331792831\n",
      "Epoch 176 / 200 | iteration 110 / 171 | Total Loss: 3.6063437461853027 | KNN Loss: 3.582561492919922 | CLS Loss: 0.023782216012477875\n",
      "Epoch 176 / 200 | iteration 120 / 171 | Total Loss: 3.5996742248535156 | KNN Loss: 3.579627752304077 | CLS Loss: 0.020046424120664597\n",
      "Epoch 176 / 200 | iteration 130 / 171 | Total Loss: 3.6030852794647217 | KNN Loss: 3.594313859939575 | CLS Loss: 0.00877150148153305\n",
      "Epoch 176 / 200 | iteration 140 / 171 | Total Loss: 3.552912712097168 | KNN Loss: 3.549692392349243 | CLS Loss: 0.0032203260343521833\n",
      "Epoch 176 / 200 | iteration 150 / 171 | Total Loss: 3.622838258743286 | KNN Loss: 3.619786024093628 | CLS Loss: 0.0030523084569722414\n",
      "Epoch 176 / 200 | iteration 160 / 171 | Total Loss: 3.583388090133667 | KNN Loss: 3.581028461456299 | CLS Loss: 0.0023596803657710552\n",
      "Epoch 176 / 200 | iteration 170 / 171 | Total Loss: 3.5947701930999756 | KNN Loss: 3.579582929611206 | CLS Loss: 0.015187333337962627\n",
      "Epoch: 176, Loss: 3.6077, Train: 0.9971, Valid: 0.9863, Best: 0.9881\n",
      "Epoch 177 / 200 | iteration 0 / 171 | Total Loss: 3.552980899810791 | KNN Loss: 3.54849910736084 | CLS Loss: 0.004481736104935408\n",
      "Epoch 177 / 200 | iteration 10 / 171 | Total Loss: 3.5888521671295166 | KNN Loss: 3.584426164627075 | CLS Loss: 0.004425979219377041\n",
      "Epoch 177 / 200 | iteration 20 / 171 | Total Loss: 3.601706027984619 | KNN Loss: 3.597789764404297 | CLS Loss: 0.003916253335773945\n",
      "Epoch 177 / 200 | iteration 30 / 171 | Total Loss: 3.5927956104278564 | KNN Loss: 3.588533878326416 | CLS Loss: 0.0042616259306669235\n",
      "Epoch 177 / 200 | iteration 40 / 171 | Total Loss: 3.618051052093506 | KNN Loss: 3.6162610054016113 | CLS Loss: 0.0017899504164233804\n",
      "Epoch 177 / 200 | iteration 50 / 171 | Total Loss: 3.5897653102874756 | KNN Loss: 3.5844757556915283 | CLS Loss: 0.005289673339575529\n",
      "Epoch 177 / 200 | iteration 60 / 171 | Total Loss: 3.615100383758545 | KNN Loss: 3.595954656600952 | CLS Loss: 0.019145609810948372\n",
      "Epoch 177 / 200 | iteration 70 / 171 | Total Loss: 3.584266424179077 | KNN Loss: 3.580376625061035 | CLS Loss: 0.0038898552302271128\n",
      "Epoch 177 / 200 | iteration 80 / 171 | Total Loss: 3.5836920738220215 | KNN Loss: 3.57030987739563 | CLS Loss: 0.013382235541939735\n",
      "Epoch 177 / 200 | iteration 90 / 171 | Total Loss: 3.5931713581085205 | KNN Loss: 3.5899858474731445 | CLS Loss: 0.0031854722183197737\n",
      "Epoch 177 / 200 | iteration 100 / 171 | Total Loss: 3.6330344676971436 | KNN Loss: 3.6215014457702637 | CLS Loss: 0.011533004231750965\n",
      "Epoch 177 / 200 | iteration 110 / 171 | Total Loss: 3.6025261878967285 | KNN Loss: 3.576373338699341 | CLS Loss: 0.02615285851061344\n",
      "Epoch 177 / 200 | iteration 120 / 171 | Total Loss: 3.6188833713531494 | KNN Loss: 3.6082639694213867 | CLS Loss: 0.01061942894011736\n",
      "Epoch 177 / 200 | iteration 130 / 171 | Total Loss: 3.601240634918213 | KNN Loss: 3.5812742710113525 | CLS Loss: 0.01996644027531147\n",
      "Epoch 177 / 200 | iteration 140 / 171 | Total Loss: 3.590017318725586 | KNN Loss: 3.5758204460144043 | CLS Loss: 0.014196870848536491\n",
      "Epoch 177 / 200 | iteration 150 / 171 | Total Loss: 3.610353708267212 | KNN Loss: 3.5767128467559814 | CLS Loss: 0.03364075720310211\n",
      "Epoch 177 / 200 | iteration 160 / 171 | Total Loss: 3.571455240249634 | KNN Loss: 3.5641984939575195 | CLS Loss: 0.007256642449647188\n",
      "Epoch 177 / 200 | iteration 170 / 171 | Total Loss: 3.5834333896636963 | KNN Loss: 3.5749869346618652 | CLS Loss: 0.008446501567959785\n",
      "Epoch: 177, Loss: 3.6035, Train: 0.9960, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 178 / 200 | iteration 0 / 171 | Total Loss: 3.644589424133301 | KNN Loss: 3.6243062019348145 | CLS Loss: 0.02028333581984043\n",
      "Epoch 178 / 200 | iteration 10 / 171 | Total Loss: 3.5884315967559814 | KNN Loss: 3.5791170597076416 | CLS Loss: 0.00931455660611391\n",
      "Epoch 178 / 200 | iteration 20 / 171 | Total Loss: 3.6290090084075928 | KNN Loss: 3.610386371612549 | CLS Loss: 0.018622692674398422\n",
      "Epoch 178 / 200 | iteration 30 / 171 | Total Loss: 3.6127378940582275 | KNN Loss: 3.6083247661590576 | CLS Loss: 0.0044131800532341\n",
      "Epoch 178 / 200 | iteration 40 / 171 | Total Loss: 3.637394905090332 | KNN Loss: 3.6109559535980225 | CLS Loss: 0.026438897475600243\n",
      "Epoch 178 / 200 | iteration 50 / 171 | Total Loss: 3.614774465560913 | KNN Loss: 3.6086111068725586 | CLS Loss: 0.00616341270506382\n",
      "Epoch 178 / 200 | iteration 60 / 171 | Total Loss: 3.5889155864715576 | KNN Loss: 3.582547426223755 | CLS Loss: 0.006368229631334543\n",
      "Epoch 178 / 200 | iteration 70 / 171 | Total Loss: 3.6003072261810303 | KNN Loss: 3.5992350578308105 | CLS Loss: 0.0010721798753365874\n",
      "Epoch 178 / 200 | iteration 80 / 171 | Total Loss: 3.5953314304351807 | KNN Loss: 3.589824676513672 | CLS Loss: 0.005506720393896103\n",
      "Epoch 178 / 200 | iteration 90 / 171 | Total Loss: 3.5907607078552246 | KNN Loss: 3.5874264240264893 | CLS Loss: 0.003334358800202608\n",
      "Epoch 178 / 200 | iteration 100 / 171 | Total Loss: 3.5676944255828857 | KNN Loss: 3.5619378089904785 | CLS Loss: 0.005756585393100977\n",
      "Epoch 178 / 200 | iteration 110 / 171 | Total Loss: 3.618657112121582 | KNN Loss: 3.6061360836029053 | CLS Loss: 0.012521091848611832\n",
      "Epoch 178 / 200 | iteration 120 / 171 | Total Loss: 3.61220383644104 | KNN Loss: 3.6068167686462402 | CLS Loss: 0.005386969540268183\n",
      "Epoch 178 / 200 | iteration 130 / 171 | Total Loss: 3.637824773788452 | KNN Loss: 3.62233829498291 | CLS Loss: 0.015486489050090313\n",
      "Epoch 178 / 200 | iteration 140 / 171 | Total Loss: 3.6128621101379395 | KNN Loss: 3.589064836502075 | CLS Loss: 0.023797214031219482\n",
      "Epoch 178 / 200 | iteration 150 / 171 | Total Loss: 3.6301627159118652 | KNN Loss: 3.6137502193450928 | CLS Loss: 0.016412556171417236\n",
      "Epoch 178 / 200 | iteration 160 / 171 | Total Loss: 3.5949370861053467 | KNN Loss: 3.5921473503112793 | CLS Loss: 0.0027896289248019457\n",
      "Epoch 178 / 200 | iteration 170 / 171 | Total Loss: 3.5667102336883545 | KNN Loss: 3.5644330978393555 | CLS Loss: 0.0022771263029426336\n",
      "Epoch: 178, Loss: 3.6049, Train: 0.9971, Valid: 0.9858, Best: 0.9881\n",
      "Epoch 179 / 200 | iteration 0 / 171 | Total Loss: 3.5881855487823486 | KNN Loss: 3.578225612640381 | CLS Loss: 0.009959925897419453\n",
      "Epoch 179 / 200 | iteration 10 / 171 | Total Loss: 3.58023738861084 | KNN Loss: 3.5738062858581543 | CLS Loss: 0.006431072484701872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179 / 200 | iteration 20 / 171 | Total Loss: 3.615893840789795 | KNN Loss: 3.6083104610443115 | CLS Loss: 0.007583432365208864\n",
      "Epoch 179 / 200 | iteration 30 / 171 | Total Loss: 3.598613739013672 | KNN Loss: 3.588073253631592 | CLS Loss: 0.010540553368628025\n",
      "Epoch 179 / 200 | iteration 40 / 171 | Total Loss: 3.5743699073791504 | KNN Loss: 3.5663187503814697 | CLS Loss: 0.008051042445003986\n",
      "Epoch 179 / 200 | iteration 50 / 171 | Total Loss: 3.6808083057403564 | KNN Loss: 3.6779603958129883 | CLS Loss: 0.002847852883860469\n",
      "Epoch 179 / 200 | iteration 60 / 171 | Total Loss: 3.6325833797454834 | KNN Loss: 3.605116844177246 | CLS Loss: 0.027466539293527603\n",
      "Epoch 179 / 200 | iteration 70 / 171 | Total Loss: 3.6561825275421143 | KNN Loss: 3.6430938243865967 | CLS Loss: 0.013088789768517017\n",
      "Epoch 179 / 200 | iteration 80 / 171 | Total Loss: 3.620182752609253 | KNN Loss: 3.612419366836548 | CLS Loss: 0.00776332151144743\n",
      "Epoch 179 / 200 | iteration 90 / 171 | Total Loss: 3.617846727371216 | KNN Loss: 3.6009562015533447 | CLS Loss: 0.01689053140580654\n",
      "Epoch 179 / 200 | iteration 100 / 171 | Total Loss: 3.632039785385132 | KNN Loss: 3.622481346130371 | CLS Loss: 0.009558464400470257\n",
      "Epoch 179 / 200 | iteration 110 / 171 | Total Loss: 3.599991798400879 | KNN Loss: 3.594581127166748 | CLS Loss: 0.005410654470324516\n",
      "Epoch 179 / 200 | iteration 120 / 171 | Total Loss: 3.618664026260376 | KNN Loss: 3.601726531982422 | CLS Loss: 0.01693747565150261\n",
      "Epoch 179 / 200 | iteration 130 / 171 | Total Loss: 3.6532201766967773 | KNN Loss: 3.642467737197876 | CLS Loss: 0.010752443224191666\n",
      "Epoch 179 / 200 | iteration 140 / 171 | Total Loss: 3.593407154083252 | KNN Loss: 3.5883800983428955 | CLS Loss: 0.005027129780501127\n",
      "Epoch 179 / 200 | iteration 150 / 171 | Total Loss: 3.563960075378418 | KNN Loss: 3.554361343383789 | CLS Loss: 0.009598697535693645\n",
      "Epoch 179 / 200 | iteration 160 / 171 | Total Loss: 3.612426996231079 | KNN Loss: 3.6076042652130127 | CLS Loss: 0.0048227920196950436\n",
      "Epoch 179 / 200 | iteration 170 / 171 | Total Loss: 3.6040337085723877 | KNN Loss: 3.592325448989868 | CLS Loss: 0.011708308011293411\n",
      "Epoch: 179, Loss: 3.6069, Train: 0.9969, Valid: 0.9864, Best: 0.9881\n",
      "Epoch 180 / 200 | iteration 0 / 171 | Total Loss: 3.578618049621582 | KNN Loss: 3.576970100402832 | CLS Loss: 0.0016479275655001402\n",
      "Epoch 180 / 200 | iteration 10 / 171 | Total Loss: 3.5742833614349365 | KNN Loss: 3.568513870239258 | CLS Loss: 0.005769393872469664\n",
      "Epoch 180 / 200 | iteration 20 / 171 | Total Loss: 3.577423572540283 | KNN Loss: 3.573798656463623 | CLS Loss: 0.0036248229444026947\n",
      "Epoch 180 / 200 | iteration 30 / 171 | Total Loss: 3.5879366397857666 | KNN Loss: 3.574843645095825 | CLS Loss: 0.013093039393424988\n",
      "Epoch 180 / 200 | iteration 40 / 171 | Total Loss: 3.653449773788452 | KNN Loss: 3.643862247467041 | CLS Loss: 0.009587541222572327\n",
      "Epoch 180 / 200 | iteration 50 / 171 | Total Loss: 3.6169631481170654 | KNN Loss: 3.5976297855377197 | CLS Loss: 0.01933334954082966\n",
      "Epoch 180 / 200 | iteration 60 / 171 | Total Loss: 3.633638620376587 | KNN Loss: 3.614095449447632 | CLS Loss: 0.019543161615729332\n",
      "Epoch 180 / 200 | iteration 70 / 171 | Total Loss: 3.6207101345062256 | KNN Loss: 3.581188440322876 | CLS Loss: 0.03952174261212349\n",
      "Epoch 180 / 200 | iteration 80 / 171 | Total Loss: 3.6109678745269775 | KNN Loss: 3.608600616455078 | CLS Loss: 0.002367202425375581\n",
      "Epoch 180 / 200 | iteration 90 / 171 | Total Loss: 3.612675905227661 | KNN Loss: 3.5918610095977783 | CLS Loss: 0.020815007388591766\n",
      "Epoch 180 / 200 | iteration 100 / 171 | Total Loss: 3.6055357456207275 | KNN Loss: 3.602931022644043 | CLS Loss: 0.002604666631668806\n",
      "Epoch 180 / 200 | iteration 110 / 171 | Total Loss: 3.5940208435058594 | KNN Loss: 3.587756872177124 | CLS Loss: 0.0062640453688800335\n",
      "Epoch 180 / 200 | iteration 120 / 171 | Total Loss: 3.6228771209716797 | KNN Loss: 3.614959478378296 | CLS Loss: 0.00791752990335226\n",
      "Epoch 180 / 200 | iteration 130 / 171 | Total Loss: 3.577361583709717 | KNN Loss: 3.5716915130615234 | CLS Loss: 0.005669974721968174\n",
      "Epoch 180 / 200 | iteration 140 / 171 | Total Loss: 3.6422207355499268 | KNN Loss: 3.6266367435455322 | CLS Loss: 0.015583916567265987\n",
      "Epoch 180 / 200 | iteration 150 / 171 | Total Loss: 3.596686840057373 | KNN Loss: 3.5864343643188477 | CLS Loss: 0.010252561420202255\n",
      "Epoch 180 / 200 | iteration 160 / 171 | Total Loss: 3.718541383743286 | KNN Loss: 3.6913259029388428 | CLS Loss: 0.027215363457798958\n",
      "Epoch 180 / 200 | iteration 170 / 171 | Total Loss: 3.6251184940338135 | KNN Loss: 3.6136889457702637 | CLS Loss: 0.011429479345679283\n",
      "Epoch: 180, Loss: 3.6083, Train: 0.9974, Valid: 0.9866, Best: 0.9881\n",
      "Epoch 181 / 200 | iteration 0 / 171 | Total Loss: 3.591229200363159 | KNN Loss: 3.582864761352539 | CLS Loss: 0.008364522829651833\n",
      "Epoch 181 / 200 | iteration 10 / 171 | Total Loss: 3.6369338035583496 | KNN Loss: 3.6266767978668213 | CLS Loss: 0.01025698333978653\n",
      "Epoch 181 / 200 | iteration 20 / 171 | Total Loss: 3.5942230224609375 | KNN Loss: 3.5927813053131104 | CLS Loss: 0.0014417408965528011\n",
      "Epoch 181 / 200 | iteration 30 / 171 | Total Loss: 3.5862033367156982 | KNN Loss: 3.582859754562378 | CLS Loss: 0.003343692049384117\n",
      "Epoch 181 / 200 | iteration 40 / 171 | Total Loss: 3.5735909938812256 | KNN Loss: 3.569723129272461 | CLS Loss: 0.003867979161441326\n",
      "Epoch 181 / 200 | iteration 50 / 171 | Total Loss: 3.5883963108062744 | KNN Loss: 3.569931745529175 | CLS Loss: 0.018464475870132446\n",
      "Epoch 181 / 200 | iteration 60 / 171 | Total Loss: 3.5710668563842773 | KNN Loss: 3.5690340995788574 | CLS Loss: 0.002032747957855463\n",
      "Epoch 181 / 200 | iteration 70 / 171 | Total Loss: 3.606846332550049 | KNN Loss: 3.59309983253479 | CLS Loss: 0.013746436685323715\n",
      "Epoch 181 / 200 | iteration 80 / 171 | Total Loss: 3.635685920715332 | KNN Loss: 3.6252524852752686 | CLS Loss: 0.010433358140289783\n",
      "Epoch 181 / 200 | iteration 90 / 171 | Total Loss: 3.6170506477355957 | KNN Loss: 3.609705686569214 | CLS Loss: 0.007344861980527639\n",
      "Epoch 181 / 200 | iteration 100 / 171 | Total Loss: 3.6301183700561523 | KNN Loss: 3.621826410293579 | CLS Loss: 0.008291885256767273\n",
      "Epoch 181 / 200 | iteration 110 / 171 | Total Loss: 3.61518931388855 | KNN Loss: 3.6029610633850098 | CLS Loss: 0.012228185310959816\n",
      "Epoch 181 / 200 | iteration 120 / 171 | Total Loss: 3.599522590637207 | KNN Loss: 3.5954723358154297 | CLS Loss: 0.004050270654261112\n",
      "Epoch 181 / 200 | iteration 130 / 171 | Total Loss: 3.5770022869110107 | KNN Loss: 3.5560643672943115 | CLS Loss: 0.020937971770763397\n",
      "Epoch 181 / 200 | iteration 140 / 171 | Total Loss: 3.573842763900757 | KNN Loss: 3.5652661323547363 | CLS Loss: 0.008576658554375172\n",
      "Epoch 181 / 200 | iteration 150 / 171 | Total Loss: 3.647686719894409 | KNN Loss: 3.6313369274139404 | CLS Loss: 0.01634969189763069\n",
      "Epoch 181 / 200 | iteration 160 / 171 | Total Loss: 3.6085121631622314 | KNN Loss: 3.5874321460723877 | CLS Loss: 0.02107994630932808\n",
      "Epoch 181 / 200 | iteration 170 / 171 | Total Loss: 3.6156623363494873 | KNN Loss: 3.6118104457855225 | CLS Loss: 0.0038519646041095257\n",
      "Epoch: 181, Loss: 3.6089, Train: 0.9964, Valid: 0.9866, Best: 0.9881\n",
      "Epoch 182 / 200 | iteration 0 / 171 | Total Loss: 3.6092448234558105 | KNN Loss: 3.607128620147705 | CLS Loss: 0.0021161395125091076\n",
      "Epoch 182 / 200 | iteration 10 / 171 | Total Loss: 3.614090919494629 | KNN Loss: 3.587601661682129 | CLS Loss: 0.026489296928048134\n",
      "Epoch 182 / 200 | iteration 20 / 171 | Total Loss: 3.6029834747314453 | KNN Loss: 3.5971884727478027 | CLS Loss: 0.005795057862997055\n",
      "Epoch 182 / 200 | iteration 30 / 171 | Total Loss: 3.6361844539642334 | KNN Loss: 3.6155362129211426 | CLS Loss: 0.020648283883929253\n",
      "Epoch 182 / 200 | iteration 40 / 171 | Total Loss: 3.583793878555298 | KNN Loss: 3.5759639739990234 | CLS Loss: 0.007829966023564339\n",
      "Epoch 182 / 200 | iteration 50 / 171 | Total Loss: 3.5779223442077637 | KNN Loss: 3.572352170944214 | CLS Loss: 0.005570118315517902\n",
      "Epoch 182 / 200 | iteration 60 / 171 | Total Loss: 3.681150197982788 | KNN Loss: 3.650552272796631 | CLS Loss: 0.030597874894738197\n",
      "Epoch 182 / 200 | iteration 70 / 171 | Total Loss: 3.6012206077575684 | KNN Loss: 3.597555160522461 | CLS Loss: 0.0036654560826718807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 / 200 | iteration 80 / 171 | Total Loss: 3.622291088104248 | KNN Loss: 3.59264874458313 | CLS Loss: 0.029642246663570404\n",
      "Epoch 182 / 200 | iteration 90 / 171 | Total Loss: 3.6464555263519287 | KNN Loss: 3.636695384979248 | CLS Loss: 0.009760159999132156\n",
      "Epoch 182 / 200 | iteration 100 / 171 | Total Loss: 3.6399755477905273 | KNN Loss: 3.6218209266662598 | CLS Loss: 0.018154628574848175\n",
      "Epoch 182 / 200 | iteration 110 / 171 | Total Loss: 3.610546350479126 | KNN Loss: 3.5860025882720947 | CLS Loss: 0.024543670937418938\n",
      "Epoch 182 / 200 | iteration 120 / 171 | Total Loss: 3.594552516937256 | KNN Loss: 3.5824785232543945 | CLS Loss: 0.012074087746441364\n",
      "Epoch 182 / 200 | iteration 130 / 171 | Total Loss: 3.5958774089813232 | KNN Loss: 3.592085123062134 | CLS Loss: 0.0037921948824077845\n",
      "Epoch 182 / 200 | iteration 140 / 171 | Total Loss: 3.604705572128296 | KNN Loss: 3.601583242416382 | CLS Loss: 0.0031223229598253965\n",
      "Epoch 182 / 200 | iteration 150 / 171 | Total Loss: 3.584325075149536 | KNN Loss: 3.5792572498321533 | CLS Loss: 0.005067717749625444\n",
      "Epoch 182 / 200 | iteration 160 / 171 | Total Loss: 3.6370160579681396 | KNN Loss: 3.6286885738372803 | CLS Loss: 0.008327544666826725\n",
      "Epoch 182 / 200 | iteration 170 / 171 | Total Loss: 3.670104742050171 | KNN Loss: 3.644329309463501 | CLS Loss: 0.025775324553251266\n",
      "Epoch: 182, Loss: 3.6155, Train: 0.9966, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 183 / 200 | iteration 0 / 171 | Total Loss: 3.6496143341064453 | KNN Loss: 3.6287951469421387 | CLS Loss: 0.02081912010908127\n",
      "Epoch 183 / 200 | iteration 10 / 171 | Total Loss: 3.5951852798461914 | KNN Loss: 3.5874130725860596 | CLS Loss: 0.007772264536470175\n",
      "Epoch 183 / 200 | iteration 20 / 171 | Total Loss: 3.6174185276031494 | KNN Loss: 3.595892906188965 | CLS Loss: 0.02152559906244278\n",
      "Epoch 183 / 200 | iteration 30 / 171 | Total Loss: 3.591040849685669 | KNN Loss: 3.580850124359131 | CLS Loss: 0.010190756060183048\n",
      "Epoch 183 / 200 | iteration 40 / 171 | Total Loss: 3.606966495513916 | KNN Loss: 3.595186710357666 | CLS Loss: 0.011779769323766232\n",
      "Epoch 183 / 200 | iteration 50 / 171 | Total Loss: 3.5830869674682617 | KNN Loss: 3.5761618614196777 | CLS Loss: 0.006925155408680439\n",
      "Epoch 183 / 200 | iteration 60 / 171 | Total Loss: 3.6048316955566406 | KNN Loss: 3.601452589035034 | CLS Loss: 0.003379052272066474\n",
      "Epoch 183 / 200 | iteration 70 / 171 | Total Loss: 3.607395648956299 | KNN Loss: 3.6061227321624756 | CLS Loss: 0.0012727988651022315\n",
      "Epoch 183 / 200 | iteration 80 / 171 | Total Loss: 3.6102871894836426 | KNN Loss: 3.6007959842681885 | CLS Loss: 0.00949122291058302\n",
      "Epoch 183 / 200 | iteration 90 / 171 | Total Loss: 3.61159086227417 | KNN Loss: 3.610341787338257 | CLS Loss: 0.0012491648085415363\n",
      "Epoch 183 / 200 | iteration 100 / 171 | Total Loss: 3.585484027862549 | KNN Loss: 3.57684326171875 | CLS Loss: 0.008640829473733902\n",
      "Epoch 183 / 200 | iteration 110 / 171 | Total Loss: 3.6356441974639893 | KNN Loss: 3.630509614944458 | CLS Loss: 0.005134575068950653\n",
      "Epoch 183 / 200 | iteration 120 / 171 | Total Loss: 3.6593708992004395 | KNN Loss: 3.6436171531677246 | CLS Loss: 0.015753719955682755\n",
      "Epoch 183 / 200 | iteration 130 / 171 | Total Loss: 3.6225454807281494 | KNN Loss: 3.6047446727752686 | CLS Loss: 0.01780085079371929\n",
      "Epoch 183 / 200 | iteration 140 / 171 | Total Loss: 3.63852858543396 | KNN Loss: 3.6139485836029053 | CLS Loss: 0.02457994967699051\n",
      "Epoch 183 / 200 | iteration 150 / 171 | Total Loss: 3.70221209526062 | KNN Loss: 3.696531295776367 | CLS Loss: 0.00568070774897933\n",
      "Epoch 183 / 200 | iteration 160 / 171 | Total Loss: 3.621838331222534 | KNN Loss: 3.602811098098755 | CLS Loss: 0.019027182832360268\n",
      "Epoch 183 / 200 | iteration 170 / 171 | Total Loss: 3.614164352416992 | KNN Loss: 3.604865312576294 | CLS Loss: 0.009299040772020817\n",
      "Epoch: 183, Loss: 3.6114, Train: 0.9973, Valid: 0.9879, Best: 0.9881\n",
      "Epoch 184 / 200 | iteration 0 / 171 | Total Loss: 3.642005443572998 | KNN Loss: 3.629685163497925 | CLS Loss: 0.012320221401751041\n",
      "Epoch 184 / 200 | iteration 10 / 171 | Total Loss: 3.627370834350586 | KNN Loss: 3.6165363788604736 | CLS Loss: 0.01083449274301529\n",
      "Epoch 184 / 200 | iteration 20 / 171 | Total Loss: 3.6230223178863525 | KNN Loss: 3.608412981033325 | CLS Loss: 0.014609439298510551\n",
      "Epoch 184 / 200 | iteration 30 / 171 | Total Loss: 3.596752166748047 | KNN Loss: 3.5923190116882324 | CLS Loss: 0.004433130845427513\n",
      "Epoch 184 / 200 | iteration 40 / 171 | Total Loss: 3.57537579536438 | KNN Loss: 3.5664589405059814 | CLS Loss: 0.008916812017560005\n",
      "Epoch 184 / 200 | iteration 50 / 171 | Total Loss: 3.6044769287109375 | KNN Loss: 3.585461139678955 | CLS Loss: 0.01901566982269287\n",
      "Epoch 184 / 200 | iteration 60 / 171 | Total Loss: 3.5866386890411377 | KNN Loss: 3.579160213470459 | CLS Loss: 0.007478592451661825\n",
      "Epoch 184 / 200 | iteration 70 / 171 | Total Loss: 3.6621382236480713 | KNN Loss: 3.656108856201172 | CLS Loss: 0.006029336713254452\n",
      "Epoch 184 / 200 | iteration 80 / 171 | Total Loss: 3.659864902496338 | KNN Loss: 3.623990297317505 | CLS Loss: 0.03587456792593002\n",
      "Epoch 184 / 200 | iteration 90 / 171 | Total Loss: 3.5774481296539307 | KNN Loss: 3.563674211502075 | CLS Loss: 0.013773884624242783\n",
      "Epoch 184 / 200 | iteration 100 / 171 | Total Loss: 3.6317710876464844 | KNN Loss: 3.617156744003296 | CLS Loss: 0.014614311046898365\n",
      "Epoch 184 / 200 | iteration 110 / 171 | Total Loss: 3.658757448196411 | KNN Loss: 3.6524200439453125 | CLS Loss: 0.00633746013045311\n",
      "Epoch 184 / 200 | iteration 120 / 171 | Total Loss: 3.594052314758301 | KNN Loss: 3.586890697479248 | CLS Loss: 0.007161572575569153\n",
      "Epoch 184 / 200 | iteration 130 / 171 | Total Loss: 3.6430580615997314 | KNN Loss: 3.6043035984039307 | CLS Loss: 0.03875447437167168\n",
      "Epoch 184 / 200 | iteration 140 / 171 | Total Loss: 3.6374292373657227 | KNN Loss: 3.6139793395996094 | CLS Loss: 0.023449795320630074\n",
      "Epoch 184 / 200 | iteration 150 / 171 | Total Loss: 3.6039159297943115 | KNN Loss: 3.5718846321105957 | CLS Loss: 0.032031260430812836\n",
      "Epoch 184 / 200 | iteration 160 / 171 | Total Loss: 3.6109182834625244 | KNN Loss: 3.586270570755005 | CLS Loss: 0.024647627025842667\n",
      "Epoch 184 / 200 | iteration 170 / 171 | Total Loss: 3.630800247192383 | KNN Loss: 3.6116836071014404 | CLS Loss: 0.0191165991127491\n",
      "Epoch: 184, Loss: 3.6114, Train: 0.9966, Valid: 0.9866, Best: 0.9881\n",
      "Epoch 185 / 200 | iteration 0 / 171 | Total Loss: 3.5620710849761963 | KNN Loss: 3.5595741271972656 | CLS Loss: 0.002497028326615691\n",
      "Epoch 185 / 200 | iteration 10 / 171 | Total Loss: 3.6090643405914307 | KNN Loss: 3.6071717739105225 | CLS Loss: 0.00189268181566149\n",
      "Epoch 185 / 200 | iteration 20 / 171 | Total Loss: 3.6427245140075684 | KNN Loss: 3.636216640472412 | CLS Loss: 0.006507758982479572\n",
      "Epoch 185 / 200 | iteration 30 / 171 | Total Loss: 3.593820810317993 | KNN Loss: 3.5813844203948975 | CLS Loss: 0.01243629027158022\n",
      "Epoch 185 / 200 | iteration 40 / 171 | Total Loss: 3.5981380939483643 | KNN Loss: 3.5702595710754395 | CLS Loss: 0.027878576889634132\n",
      "Epoch 185 / 200 | iteration 50 / 171 | Total Loss: 3.603285789489746 | KNN Loss: 3.5914900302886963 | CLS Loss: 0.011795797385275364\n",
      "Epoch 185 / 200 | iteration 60 / 171 | Total Loss: 3.582624912261963 | KNN Loss: 3.576108694076538 | CLS Loss: 0.006516266148537397\n",
      "Epoch 185 / 200 | iteration 70 / 171 | Total Loss: 3.6387734413146973 | KNN Loss: 3.6243226528167725 | CLS Loss: 0.014450741931796074\n",
      "Epoch 185 / 200 | iteration 80 / 171 | Total Loss: 3.601386785507202 | KNN Loss: 3.5917282104492188 | CLS Loss: 0.00965855922549963\n",
      "Epoch 185 / 200 | iteration 90 / 171 | Total Loss: 3.604037046432495 | KNN Loss: 3.601033926010132 | CLS Loss: 0.003003160236403346\n",
      "Epoch 185 / 200 | iteration 100 / 171 | Total Loss: 3.5759289264678955 | KNN Loss: 3.575226068496704 | CLS Loss: 0.0007029711850918829\n",
      "Epoch 185 / 200 | iteration 110 / 171 | Total Loss: 3.6083247661590576 | KNN Loss: 3.6027908325195312 | CLS Loss: 0.005533869378268719\n",
      "Epoch 185 / 200 | iteration 120 / 171 | Total Loss: 3.6458873748779297 | KNN Loss: 3.625652313232422 | CLS Loss: 0.02023499831557274\n",
      "Epoch 185 / 200 | iteration 130 / 171 | Total Loss: 3.625608205795288 | KNN Loss: 3.6240038871765137 | CLS Loss: 0.0016043195500969887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185 / 200 | iteration 140 / 171 | Total Loss: 3.5805492401123047 | KNN Loss: 3.5769805908203125 | CLS Loss: 0.003568677231669426\n",
      "Epoch 185 / 200 | iteration 150 / 171 | Total Loss: 3.5757715702056885 | KNN Loss: 3.57362961769104 | CLS Loss: 0.0021419499535113573\n",
      "Epoch 185 / 200 | iteration 160 / 171 | Total Loss: 3.6233317852020264 | KNN Loss: 3.606220006942749 | CLS Loss: 0.017111727967858315\n",
      "Epoch 185 / 200 | iteration 170 / 171 | Total Loss: 3.6639420986175537 | KNN Loss: 3.6395184993743896 | CLS Loss: 0.024423567578196526\n",
      "Epoch: 185, Loss: 3.6137, Train: 0.9960, Valid: 0.9851, Best: 0.9881\n",
      "Epoch 186 / 200 | iteration 0 / 171 | Total Loss: 3.584944725036621 | KNN Loss: 3.572535514831543 | CLS Loss: 0.012409098446369171\n",
      "Epoch 186 / 200 | iteration 10 / 171 | Total Loss: 3.581165313720703 | KNN Loss: 3.576125383377075 | CLS Loss: 0.005039928946644068\n",
      "Epoch 186 / 200 | iteration 20 / 171 | Total Loss: 3.6369593143463135 | KNN Loss: 3.624846935272217 | CLS Loss: 0.012112475000321865\n",
      "Epoch 186 / 200 | iteration 30 / 171 | Total Loss: 3.5847055912017822 | KNN Loss: 3.580124855041504 | CLS Loss: 0.0045806970447301865\n",
      "Epoch 186 / 200 | iteration 40 / 171 | Total Loss: 3.62432599067688 | KNN Loss: 3.6012580394744873 | CLS Loss: 0.023067979142069817\n",
      "Epoch 186 / 200 | iteration 50 / 171 | Total Loss: 3.592672348022461 | KNN Loss: 3.5698437690734863 | CLS Loss: 0.022828485816717148\n",
      "Epoch 186 / 200 | iteration 60 / 171 | Total Loss: 3.6182613372802734 | KNN Loss: 3.573725700378418 | CLS Loss: 0.04453566297888756\n",
      "Epoch 186 / 200 | iteration 70 / 171 | Total Loss: 3.601449728012085 | KNN Loss: 3.5892245769500732 | CLS Loss: 0.012225034646689892\n",
      "Epoch 186 / 200 | iteration 80 / 171 | Total Loss: 3.654836893081665 | KNN Loss: 3.6481735706329346 | CLS Loss: 0.0066632856614887714\n",
      "Epoch 186 / 200 | iteration 90 / 171 | Total Loss: 3.6478540897369385 | KNN Loss: 3.6421291828155518 | CLS Loss: 0.005724994465708733\n",
      "Epoch 186 / 200 | iteration 100 / 171 | Total Loss: 3.628671884536743 | KNN Loss: 3.6071054935455322 | CLS Loss: 0.021566398441791534\n",
      "Epoch 186 / 200 | iteration 110 / 171 | Total Loss: 3.592529535293579 | KNN Loss: 3.5912065505981445 | CLS Loss: 0.0013229174073785543\n",
      "Epoch 186 / 200 | iteration 120 / 171 | Total Loss: 3.5997540950775146 | KNN Loss: 3.565786838531494 | CLS Loss: 0.033967237919569016\n",
      "Epoch 186 / 200 | iteration 130 / 171 | Total Loss: 3.5547866821289062 | KNN Loss: 3.5522470474243164 | CLS Loss: 0.0025397324934601784\n",
      "Epoch 186 / 200 | iteration 140 / 171 | Total Loss: 3.563386917114258 | KNN Loss: 3.562211751937866 | CLS Loss: 0.0011751825222745538\n",
      "Epoch 186 / 200 | iteration 150 / 171 | Total Loss: 3.63832950592041 | KNN Loss: 3.633561611175537 | CLS Loss: 0.004767829552292824\n",
      "Epoch 186 / 200 | iteration 160 / 171 | Total Loss: 3.6004955768585205 | KNN Loss: 3.5900912284851074 | CLS Loss: 0.010404390282928944\n",
      "Epoch 186 / 200 | iteration 170 / 171 | Total Loss: 3.583919048309326 | KNN Loss: 3.562983989715576 | CLS Loss: 0.020934998989105225\n",
      "Epoch: 186, Loss: 3.6086, Train: 0.9957, Valid: 0.9861, Best: 0.9881\n",
      "Epoch 187 / 200 | iteration 0 / 171 | Total Loss: 3.635554075241089 | KNN Loss: 3.6088013648986816 | CLS Loss: 0.026752643287181854\n",
      "Epoch 187 / 200 | iteration 10 / 171 | Total Loss: 3.596857786178589 | KNN Loss: 3.572540521621704 | CLS Loss: 0.024317216128110886\n",
      "Epoch 187 / 200 | iteration 20 / 171 | Total Loss: 3.6212191581726074 | KNN Loss: 3.6041505336761475 | CLS Loss: 0.017068559303879738\n",
      "Epoch 187 / 200 | iteration 30 / 171 | Total Loss: 3.5958468914031982 | KNN Loss: 3.5944983959198 | CLS Loss: 0.001348605495877564\n",
      "Epoch 187 / 200 | iteration 40 / 171 | Total Loss: 3.5909194946289062 | KNN Loss: 3.571943521499634 | CLS Loss: 0.01897607184946537\n",
      "Epoch 187 / 200 | iteration 50 / 171 | Total Loss: 3.627579689025879 | KNN Loss: 3.601668119430542 | CLS Loss: 0.025911672040820122\n",
      "Epoch 187 / 200 | iteration 60 / 171 | Total Loss: 3.6264922618865967 | KNN Loss: 3.618481159210205 | CLS Loss: 0.008011095225811005\n",
      "Epoch 187 / 200 | iteration 70 / 171 | Total Loss: 3.6266584396362305 | KNN Loss: 3.611772060394287 | CLS Loss: 0.014886289834976196\n",
      "Epoch 187 / 200 | iteration 80 / 171 | Total Loss: 3.5747427940368652 | KNN Loss: 3.5734074115753174 | CLS Loss: 0.0013353850226849318\n",
      "Epoch 187 / 200 | iteration 90 / 171 | Total Loss: 3.6014926433563232 | KNN Loss: 3.5972254276275635 | CLS Loss: 0.004267189186066389\n",
      "Epoch 187 / 200 | iteration 100 / 171 | Total Loss: 3.5736844539642334 | KNN Loss: 3.5633411407470703 | CLS Loss: 0.010343354195356369\n",
      "Epoch 187 / 200 | iteration 110 / 171 | Total Loss: 3.604534149169922 | KNN Loss: 3.598978281021118 | CLS Loss: 0.0055558220483362675\n",
      "Epoch 187 / 200 | iteration 120 / 171 | Total Loss: 3.579862594604492 | KNN Loss: 3.5763485431671143 | CLS Loss: 0.0035140288528054953\n",
      "Epoch 187 / 200 | iteration 130 / 171 | Total Loss: 3.618007183074951 | KNN Loss: 3.608616352081299 | CLS Loss: 0.009390905499458313\n",
      "Epoch 187 / 200 | iteration 140 / 171 | Total Loss: 3.5907115936279297 | KNN Loss: 3.5870463848114014 | CLS Loss: 0.0036651690024882555\n",
      "Epoch 187 / 200 | iteration 150 / 171 | Total Loss: 3.6030454635620117 | KNN Loss: 3.5941245555877686 | CLS Loss: 0.008921013213694096\n",
      "Epoch 187 / 200 | iteration 160 / 171 | Total Loss: 3.635993003845215 | KNN Loss: 3.5990450382232666 | CLS Loss: 0.03694796562194824\n",
      "Epoch 187 / 200 | iteration 170 / 171 | Total Loss: 3.5993199348449707 | KNN Loss: 3.58096981048584 | CLS Loss: 0.01835012249648571\n",
      "Epoch: 187, Loss: 3.6100, Train: 0.9963, Valid: 0.9866, Best: 0.9881\n",
      "Epoch 188 / 200 | iteration 0 / 171 | Total Loss: 3.641772747039795 | KNN Loss: 3.62770414352417 | CLS Loss: 0.014068606309592724\n",
      "Epoch 188 / 200 | iteration 10 / 171 | Total Loss: 3.5864498615264893 | KNN Loss: 3.5792181491851807 | CLS Loss: 0.007231693249195814\n",
      "Epoch 188 / 200 | iteration 20 / 171 | Total Loss: 3.6199333667755127 | KNN Loss: 3.6086907386779785 | CLS Loss: 0.011242596432566643\n",
      "Epoch 188 / 200 | iteration 30 / 171 | Total Loss: 3.638148307800293 | KNN Loss: 3.6324515342712402 | CLS Loss: 0.005696769338101149\n",
      "Epoch 188 / 200 | iteration 40 / 171 | Total Loss: 3.5891730785369873 | KNN Loss: 3.584799289703369 | CLS Loss: 0.004373702686280012\n",
      "Epoch 188 / 200 | iteration 50 / 171 | Total Loss: 3.594674825668335 | KNN Loss: 3.589256763458252 | CLS Loss: 0.0054181525483727455\n",
      "Epoch 188 / 200 | iteration 60 / 171 | Total Loss: 3.5561468601226807 | KNN Loss: 3.5510268211364746 | CLS Loss: 0.0051199449226260185\n",
      "Epoch 188 / 200 | iteration 70 / 171 | Total Loss: 3.5872926712036133 | KNN Loss: 3.5602622032165527 | CLS Loss: 0.027030421420931816\n",
      "Epoch 188 / 200 | iteration 80 / 171 | Total Loss: 3.6047120094299316 | KNN Loss: 3.587744951248169 | CLS Loss: 0.0169670507311821\n",
      "Epoch 188 / 200 | iteration 90 / 171 | Total Loss: 3.5813636779785156 | KNN Loss: 3.5793333053588867 | CLS Loss: 0.002030452247709036\n",
      "Epoch 188 / 200 | iteration 100 / 171 | Total Loss: 3.589001417160034 | KNN Loss: 3.5864288806915283 | CLS Loss: 0.002572626108303666\n",
      "Epoch 188 / 200 | iteration 110 / 171 | Total Loss: 3.6265995502471924 | KNN Loss: 3.618962049484253 | CLS Loss: 0.007637568283826113\n",
      "Epoch 188 / 200 | iteration 120 / 171 | Total Loss: 3.594135284423828 | KNN Loss: 3.5838029384613037 | CLS Loss: 0.010332428850233555\n",
      "Epoch 188 / 200 | iteration 130 / 171 | Total Loss: 3.5858027935028076 | KNN Loss: 3.581822156906128 | CLS Loss: 0.003980571869760752\n",
      "Epoch 188 / 200 | iteration 140 / 171 | Total Loss: 3.6378302574157715 | KNN Loss: 3.635226249694824 | CLS Loss: 0.0026041134260594845\n",
      "Epoch 188 / 200 | iteration 150 / 171 | Total Loss: 3.5693552494049072 | KNN Loss: 3.562110185623169 | CLS Loss: 0.007245174143463373\n",
      "Epoch 188 / 200 | iteration 160 / 171 | Total Loss: 3.6276018619537354 | KNN Loss: 3.6134254932403564 | CLS Loss: 0.014176382683217525\n",
      "Epoch 188 / 200 | iteration 170 / 171 | Total Loss: 3.616990089416504 | KNN Loss: 3.590726613998413 | CLS Loss: 0.026263538748025894\n",
      "Epoch: 188, Loss: 3.6078, Train: 0.9952, Valid: 0.9858, Best: 0.9881\n",
      "Epoch 189 / 200 | iteration 0 / 171 | Total Loss: 3.6397159099578857 | KNN Loss: 3.631258726119995 | CLS Loss: 0.008457140997052193\n",
      "Epoch 189 / 200 | iteration 10 / 171 | Total Loss: 3.599241018295288 | KNN Loss: 3.592364549636841 | CLS Loss: 0.00687645748257637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 / 200 | iteration 20 / 171 | Total Loss: 3.6054458618164062 | KNN Loss: 3.597970724105835 | CLS Loss: 0.007475217338651419\n",
      "Epoch 189 / 200 | iteration 30 / 171 | Total Loss: 3.614314079284668 | KNN Loss: 3.59910249710083 | CLS Loss: 0.015211476944386959\n",
      "Epoch 189 / 200 | iteration 40 / 171 | Total Loss: 3.598947525024414 | KNN Loss: 3.5901756286621094 | CLS Loss: 0.008771778084337711\n",
      "Epoch 189 / 200 | iteration 50 / 171 | Total Loss: 3.5944154262542725 | KNN Loss: 3.579150438308716 | CLS Loss: 0.015265066176652908\n",
      "Epoch 189 / 200 | iteration 60 / 171 | Total Loss: 3.6110453605651855 | KNN Loss: 3.5961081981658936 | CLS Loss: 0.01493705902248621\n",
      "Epoch 189 / 200 | iteration 70 / 171 | Total Loss: 3.5712316036224365 | KNN Loss: 3.556103467941284 | CLS Loss: 0.01512810867279768\n",
      "Epoch 189 / 200 | iteration 80 / 171 | Total Loss: 3.6456170082092285 | KNN Loss: 3.6373629570007324 | CLS Loss: 0.008254148066043854\n",
      "Epoch 189 / 200 | iteration 90 / 171 | Total Loss: 3.6576714515686035 | KNN Loss: 3.632004976272583 | CLS Loss: 0.02566637098789215\n",
      "Epoch 189 / 200 | iteration 100 / 171 | Total Loss: 3.55539608001709 | KNN Loss: 3.5535271167755127 | CLS Loss: 0.0018689449643716216\n",
      "Epoch 189 / 200 | iteration 110 / 171 | Total Loss: 3.619206666946411 | KNN Loss: 3.60099458694458 | CLS Loss: 0.018212197348475456\n",
      "Epoch 189 / 200 | iteration 120 / 171 | Total Loss: 3.5767340660095215 | KNN Loss: 3.574838399887085 | CLS Loss: 0.001895593828521669\n",
      "Epoch 189 / 200 | iteration 130 / 171 | Total Loss: 3.623004674911499 | KNN Loss: 3.6044631004333496 | CLS Loss: 0.018541667610406876\n",
      "Epoch 189 / 200 | iteration 140 / 171 | Total Loss: 3.617847442626953 | KNN Loss: 3.610564708709717 | CLS Loss: 0.00728267477825284\n",
      "Epoch 189 / 200 | iteration 150 / 171 | Total Loss: 3.6027956008911133 | KNN Loss: 3.5986428260803223 | CLS Loss: 0.004152831621468067\n",
      "Epoch 189 / 200 | iteration 160 / 171 | Total Loss: 3.6446456909179688 | KNN Loss: 3.618093967437744 | CLS Loss: 0.02655176818370819\n",
      "Epoch 189 / 200 | iteration 170 / 171 | Total Loss: 3.623612403869629 | KNN Loss: 3.6050992012023926 | CLS Loss: 0.01851324550807476\n",
      "Epoch: 189, Loss: 3.6073, Train: 0.9971, Valid: 0.9862, Best: 0.9881\n",
      "Epoch 190 / 200 | iteration 0 / 171 | Total Loss: 3.5842931270599365 | KNN Loss: 3.582343578338623 | CLS Loss: 0.0019494318403303623\n",
      "Epoch 190 / 200 | iteration 10 / 171 | Total Loss: 3.565103054046631 | KNN Loss: 3.5600264072418213 | CLS Loss: 0.005076678469777107\n",
      "Epoch 190 / 200 | iteration 20 / 171 | Total Loss: 3.5734872817993164 | KNN Loss: 3.57201886177063 | CLS Loss: 0.0014684529742226005\n",
      "Epoch 190 / 200 | iteration 30 / 171 | Total Loss: 3.6504781246185303 | KNN Loss: 3.6476495265960693 | CLS Loss: 0.002828592201694846\n",
      "Epoch 190 / 200 | iteration 40 / 171 | Total Loss: 3.6221225261688232 | KNN Loss: 3.6109673976898193 | CLS Loss: 0.01115510892122984\n",
      "Epoch 190 / 200 | iteration 50 / 171 | Total Loss: 3.6057615280151367 | KNN Loss: 3.5999081134796143 | CLS Loss: 0.00585333863273263\n",
      "Epoch 190 / 200 | iteration 60 / 171 | Total Loss: 3.5930416584014893 | KNN Loss: 3.5898306369781494 | CLS Loss: 0.0032109441235661507\n",
      "Epoch 190 / 200 | iteration 70 / 171 | Total Loss: 3.5909018516540527 | KNN Loss: 3.5786452293395996 | CLS Loss: 0.012256670743227005\n",
      "Epoch 190 / 200 | iteration 80 / 171 | Total Loss: 3.6077728271484375 | KNN Loss: 3.5978641510009766 | CLS Loss: 0.009908784180879593\n",
      "Epoch 190 / 200 | iteration 90 / 171 | Total Loss: 3.652405261993408 | KNN Loss: 3.64137601852417 | CLS Loss: 0.011029243469238281\n",
      "Epoch 190 / 200 | iteration 100 / 171 | Total Loss: 3.617504358291626 | KNN Loss: 3.611163854598999 | CLS Loss: 0.006340544670820236\n",
      "Epoch 190 / 200 | iteration 110 / 171 | Total Loss: 3.6029953956604004 | KNN Loss: 3.587714195251465 | CLS Loss: 0.015281084924936295\n",
      "Epoch 190 / 200 | iteration 120 / 171 | Total Loss: 3.6149377822875977 | KNN Loss: 3.6070504188537598 | CLS Loss: 0.007887479849159718\n",
      "Epoch 190 / 200 | iteration 130 / 171 | Total Loss: 3.593653678894043 | KNN Loss: 3.5854365825653076 | CLS Loss: 0.008216987363994122\n",
      "Epoch 190 / 200 | iteration 140 / 171 | Total Loss: 3.604135513305664 | KNN Loss: 3.594438314437866 | CLS Loss: 0.009697215631604195\n",
      "Epoch 190 / 200 | iteration 150 / 171 | Total Loss: 3.612245559692383 | KNN Loss: 3.584848642349243 | CLS Loss: 0.027396975085139275\n",
      "Epoch 190 / 200 | iteration 160 / 171 | Total Loss: 3.586649179458618 | KNN Loss: 3.5775465965270996 | CLS Loss: 0.009102588519454002\n",
      "Epoch 190 / 200 | iteration 170 / 171 | Total Loss: 3.629256010055542 | KNN Loss: 3.6158571243286133 | CLS Loss: 0.013398912735283375\n",
      "Epoch: 190, Loss: 3.6105, Train: 0.9978, Valid: 0.9869, Best: 0.9881\n",
      "Epoch 191 / 200 | iteration 0 / 171 | Total Loss: 3.585914134979248 | KNN Loss: 3.5836071968078613 | CLS Loss: 0.0023068543523550034\n",
      "Epoch 191 / 200 | iteration 10 / 171 | Total Loss: 3.5861904621124268 | KNN Loss: 3.5851309299468994 | CLS Loss: 0.0010595018975436687\n",
      "Epoch 191 / 200 | iteration 20 / 171 | Total Loss: 3.6133642196655273 | KNN Loss: 3.607569932937622 | CLS Loss: 0.005794241093099117\n",
      "Epoch 191 / 200 | iteration 30 / 171 | Total Loss: 3.652526617050171 | KNN Loss: 3.6228575706481934 | CLS Loss: 0.02966904267668724\n",
      "Epoch 191 / 200 | iteration 40 / 171 | Total Loss: 3.6157987117767334 | KNN Loss: 3.6079201698303223 | CLS Loss: 0.00787865836173296\n",
      "Epoch 191 / 200 | iteration 50 / 171 | Total Loss: 3.6078383922576904 | KNN Loss: 3.5891244411468506 | CLS Loss: 0.018713969737291336\n",
      "Epoch 191 / 200 | iteration 60 / 171 | Total Loss: 3.631897449493408 | KNN Loss: 3.616548776626587 | CLS Loss: 0.015348754823207855\n",
      "Epoch 191 / 200 | iteration 70 / 171 | Total Loss: 3.6105668544769287 | KNN Loss: 3.5663557052612305 | CLS Loss: 0.04421123117208481\n",
      "Epoch 191 / 200 | iteration 80 / 171 | Total Loss: 3.6119441986083984 | KNN Loss: 3.6046900749206543 | CLS Loss: 0.007254010532051325\n",
      "Epoch 191 / 200 | iteration 90 / 171 | Total Loss: 3.5934898853302 | KNN Loss: 3.5833115577697754 | CLS Loss: 0.010178358294069767\n",
      "Epoch 191 / 200 | iteration 100 / 171 | Total Loss: 3.6314170360565186 | KNN Loss: 3.6309328079223633 | CLS Loss: 0.00048418561345897615\n",
      "Epoch 191 / 200 | iteration 110 / 171 | Total Loss: 3.596205711364746 | KNN Loss: 3.5855019092559814 | CLS Loss: 0.01070371549576521\n",
      "Epoch 191 / 200 | iteration 120 / 171 | Total Loss: 3.6263697147369385 | KNN Loss: 3.622664451599121 | CLS Loss: 0.0037053010892122984\n",
      "Epoch 191 / 200 | iteration 130 / 171 | Total Loss: 3.657994031906128 | KNN Loss: 3.646221399307251 | CLS Loss: 0.011772647500038147\n",
      "Epoch 191 / 200 | iteration 140 / 171 | Total Loss: 3.577303886413574 | KNN Loss: 3.574556589126587 | CLS Loss: 0.0027473755180835724\n",
      "Epoch 191 / 200 | iteration 150 / 171 | Total Loss: 3.5803768634796143 | KNN Loss: 3.5753071308135986 | CLS Loss: 0.005069730803370476\n",
      "Epoch 191 / 200 | iteration 160 / 171 | Total Loss: 3.587252140045166 | KNN Loss: 3.5834524631500244 | CLS Loss: 0.003799564903602004\n",
      "Epoch 191 / 200 | iteration 170 / 171 | Total Loss: 3.636737585067749 | KNN Loss: 3.614692211151123 | CLS Loss: 0.02204534411430359\n",
      "Epoch: 191, Loss: 3.6168, Train: 0.9963, Valid: 0.9863, Best: 0.9881\n",
      "Epoch 192 / 200 | iteration 0 / 171 | Total Loss: 3.614377021789551 | KNN Loss: 3.5977962017059326 | CLS Loss: 0.016580933704972267\n",
      "Epoch 192 / 200 | iteration 10 / 171 | Total Loss: 3.598795175552368 | KNN Loss: 3.590183734893799 | CLS Loss: 0.008611492812633514\n",
      "Epoch 192 / 200 | iteration 20 / 171 | Total Loss: 3.609827756881714 | KNN Loss: 3.601417303085327 | CLS Loss: 0.00841042585670948\n",
      "Epoch 192 / 200 | iteration 30 / 171 | Total Loss: 3.6062564849853516 | KNN Loss: 3.600799798965454 | CLS Loss: 0.005456695333123207\n",
      "Epoch 192 / 200 | iteration 40 / 171 | Total Loss: 3.6094486713409424 | KNN Loss: 3.606595277786255 | CLS Loss: 0.002853348385542631\n",
      "Epoch 192 / 200 | iteration 50 / 171 | Total Loss: 3.599046230316162 | KNN Loss: 3.5985989570617676 | CLS Loss: 0.0004472484579309821\n",
      "Epoch 192 / 200 | iteration 60 / 171 | Total Loss: 3.584421396255493 | KNN Loss: 3.5807790756225586 | CLS Loss: 0.00364243658259511\n",
      "Epoch 192 / 200 | iteration 70 / 171 | Total Loss: 3.6563448905944824 | KNN Loss: 3.640131711959839 | CLS Loss: 0.016213208436965942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 / 200 | iteration 80 / 171 | Total Loss: 3.5929462909698486 | KNN Loss: 3.5877981185913086 | CLS Loss: 0.005148110445588827\n",
      "Epoch 192 / 200 | iteration 90 / 171 | Total Loss: 3.596129894256592 | KNN Loss: 3.588235855102539 | CLS Loss: 0.007894113659858704\n",
      "Epoch 192 / 200 | iteration 100 / 171 | Total Loss: 3.62921142578125 | KNN Loss: 3.6154186725616455 | CLS Loss: 0.013792778365314007\n",
      "Epoch 192 / 200 | iteration 110 / 171 | Total Loss: 3.6082143783569336 | KNN Loss: 3.606281280517578 | CLS Loss: 0.0019331170478835702\n",
      "Epoch 192 / 200 | iteration 120 / 171 | Total Loss: 3.6608004570007324 | KNN Loss: 3.642062187194824 | CLS Loss: 0.01873824931681156\n",
      "Epoch 192 / 200 | iteration 130 / 171 | Total Loss: 3.7065107822418213 | KNN Loss: 3.680169105529785 | CLS Loss: 0.02634158544242382\n",
      "Epoch 192 / 200 | iteration 140 / 171 | Total Loss: 3.6399686336517334 | KNN Loss: 3.6156833171844482 | CLS Loss: 0.024285387247800827\n",
      "Epoch 192 / 200 | iteration 150 / 171 | Total Loss: 3.6050477027893066 | KNN Loss: 3.589755058288574 | CLS Loss: 0.015292633324861526\n",
      "Epoch 192 / 200 | iteration 160 / 171 | Total Loss: 3.6549839973449707 | KNN Loss: 3.6275601387023926 | CLS Loss: 0.02742387354373932\n",
      "Epoch 192 / 200 | iteration 170 / 171 | Total Loss: 3.5867371559143066 | KNN Loss: 3.573366641998291 | CLS Loss: 0.013370596803724766\n",
      "Epoch: 192, Loss: 3.6137, Train: 0.9954, Valid: 0.9854, Best: 0.9881\n",
      "Epoch 193 / 200 | iteration 0 / 171 | Total Loss: 3.652965545654297 | KNN Loss: 3.64278244972229 | CLS Loss: 0.01018314715474844\n",
      "Epoch 193 / 200 | iteration 10 / 171 | Total Loss: 3.562680721282959 | KNN Loss: 3.558776378631592 | CLS Loss: 0.003904447890818119\n",
      "Epoch 193 / 200 | iteration 20 / 171 | Total Loss: 3.644695520401001 | KNN Loss: 3.615036964416504 | CLS Loss: 0.02965846285223961\n",
      "Epoch 193 / 200 | iteration 30 / 171 | Total Loss: 3.6139166355133057 | KNN Loss: 3.5856666564941406 | CLS Loss: 0.02825005352497101\n",
      "Epoch 193 / 200 | iteration 40 / 171 | Total Loss: 3.596881151199341 | KNN Loss: 3.593590021133423 | CLS Loss: 0.0032911680173128843\n",
      "Epoch 193 / 200 | iteration 50 / 171 | Total Loss: 3.6664340496063232 | KNN Loss: 3.6576788425445557 | CLS Loss: 0.008755209855735302\n",
      "Epoch 193 / 200 | iteration 60 / 171 | Total Loss: 3.613375663757324 | KNN Loss: 3.597506284713745 | CLS Loss: 0.01586943306028843\n",
      "Epoch 193 / 200 | iteration 70 / 171 | Total Loss: 3.59043025970459 | KNN Loss: 3.5886240005493164 | CLS Loss: 0.0018063472816720605\n",
      "Epoch 193 / 200 | iteration 80 / 171 | Total Loss: 3.5814974308013916 | KNN Loss: 3.5785417556762695 | CLS Loss: 0.002955683274194598\n",
      "Epoch 193 / 200 | iteration 90 / 171 | Total Loss: 3.6355416774749756 | KNN Loss: 3.6142518520355225 | CLS Loss: 0.021289797499775887\n",
      "Epoch 193 / 200 | iteration 100 / 171 | Total Loss: 3.6153979301452637 | KNN Loss: 3.6117069721221924 | CLS Loss: 0.0036910432390868664\n",
      "Epoch 193 / 200 | iteration 110 / 171 | Total Loss: 3.594273090362549 | KNN Loss: 3.5803308486938477 | CLS Loss: 0.013942182995378971\n",
      "Epoch 193 / 200 | iteration 120 / 171 | Total Loss: 3.6331522464752197 | KNN Loss: 3.624394178390503 | CLS Loss: 0.008758076466619968\n",
      "Epoch 193 / 200 | iteration 130 / 171 | Total Loss: 3.592745304107666 | KNN Loss: 3.5830087661743164 | CLS Loss: 0.009736422449350357\n",
      "Epoch 193 / 200 | iteration 140 / 171 | Total Loss: 3.569427251815796 | KNN Loss: 3.56843638420105 | CLS Loss: 0.0009907592320814729\n",
      "Epoch 193 / 200 | iteration 150 / 171 | Total Loss: 3.605670690536499 | KNN Loss: 3.577414035797119 | CLS Loss: 0.02825668640434742\n",
      "Epoch 193 / 200 | iteration 160 / 171 | Total Loss: 3.616365909576416 | KNN Loss: 3.59183931350708 | CLS Loss: 0.02452666312456131\n",
      "Epoch 193 / 200 | iteration 170 / 171 | Total Loss: 3.6105799674987793 | KNN Loss: 3.59963321685791 | CLS Loss: 0.01094665378332138\n",
      "Epoch: 193, Loss: 3.6095, Train: 0.9969, Valid: 0.9865, Best: 0.9881\n",
      "Epoch 194 / 200 | iteration 0 / 171 | Total Loss: 3.5896196365356445 | KNN Loss: 3.580787420272827 | CLS Loss: 0.00883230846375227\n",
      "Epoch 194 / 200 | iteration 10 / 171 | Total Loss: 3.631910562515259 | KNN Loss: 3.6255605220794678 | CLS Loss: 0.006350014358758926\n",
      "Epoch 194 / 200 | iteration 20 / 171 | Total Loss: 3.641033411026001 | KNN Loss: 3.605652093887329 | CLS Loss: 0.03538123890757561\n",
      "Epoch 194 / 200 | iteration 30 / 171 | Total Loss: 3.6724612712860107 | KNN Loss: 3.638984441757202 | CLS Loss: 0.03347685560584068\n",
      "Epoch 194 / 200 | iteration 40 / 171 | Total Loss: 3.6206605434417725 | KNN Loss: 3.5988149642944336 | CLS Loss: 0.021845679730176926\n",
      "Epoch 194 / 200 | iteration 50 / 171 | Total Loss: 3.5954842567443848 | KNN Loss: 3.591442823410034 | CLS Loss: 0.00404145335778594\n",
      "Epoch 194 / 200 | iteration 60 / 171 | Total Loss: 3.5935230255126953 | KNN Loss: 3.588773727416992 | CLS Loss: 0.004749293904751539\n",
      "Epoch 194 / 200 | iteration 70 / 171 | Total Loss: 3.5867443084716797 | KNN Loss: 3.5713648796081543 | CLS Loss: 0.015379312448203564\n",
      "Epoch 194 / 200 | iteration 80 / 171 | Total Loss: 3.5884788036346436 | KNN Loss: 3.5853805541992188 | CLS Loss: 0.003098192624747753\n",
      "Epoch 194 / 200 | iteration 90 / 171 | Total Loss: 3.6252453327178955 | KNN Loss: 3.6182847023010254 | CLS Loss: 0.006960656028240919\n",
      "Epoch 194 / 200 | iteration 100 / 171 | Total Loss: 3.5789389610290527 | KNN Loss: 3.57653546333313 | CLS Loss: 0.0024036034010350704\n",
      "Epoch 194 / 200 | iteration 110 / 171 | Total Loss: 3.584927558898926 | KNN Loss: 3.5612480640411377 | CLS Loss: 0.023679442703723907\n",
      "Epoch 194 / 200 | iteration 120 / 171 | Total Loss: 3.593559503555298 | KNN Loss: 3.580120325088501 | CLS Loss: 0.013439185917377472\n",
      "Epoch 194 / 200 | iteration 130 / 171 | Total Loss: 3.600153923034668 | KNN Loss: 3.574183225631714 | CLS Loss: 0.025970717892050743\n",
      "Epoch 194 / 200 | iteration 140 / 171 | Total Loss: 3.594599723815918 | KNN Loss: 3.584026336669922 | CLS Loss: 0.01057333592325449\n",
      "Epoch 194 / 200 | iteration 150 / 171 | Total Loss: 3.634247303009033 | KNN Loss: 3.625049352645874 | CLS Loss: 0.009198043495416641\n",
      "Epoch 194 / 200 | iteration 160 / 171 | Total Loss: 3.6253480911254883 | KNN Loss: 3.616478681564331 | CLS Loss: 0.00886931736022234\n",
      "Epoch 194 / 200 | iteration 170 / 171 | Total Loss: 3.613879919052124 | KNN Loss: 3.6084089279174805 | CLS Loss: 0.0054709417745471\n",
      "Epoch: 194, Loss: 3.6081, Train: 0.9966, Valid: 0.9853, Best: 0.9881\n",
      "Epoch 195 / 200 | iteration 0 / 171 | Total Loss: 3.600144386291504 | KNN Loss: 3.5929453372955322 | CLS Loss: 0.007198941893875599\n",
      "Epoch 195 / 200 | iteration 10 / 171 | Total Loss: 3.5674991607666016 | KNN Loss: 3.563821792602539 | CLS Loss: 0.0036773374304175377\n",
      "Epoch 195 / 200 | iteration 20 / 171 | Total Loss: 3.5629258155822754 | KNN Loss: 3.5572309494018555 | CLS Loss: 0.005694977473467588\n",
      "Epoch 195 / 200 | iteration 30 / 171 | Total Loss: 3.5944252014160156 | KNN Loss: 3.573474645614624 | CLS Loss: 0.020950529724359512\n",
      "Epoch 195 / 200 | iteration 40 / 171 | Total Loss: 3.6554818153381348 | KNN Loss: 3.5866527557373047 | CLS Loss: 0.06882917135953903\n",
      "Epoch 195 / 200 | iteration 50 / 171 | Total Loss: 3.608384132385254 | KNN Loss: 3.599893569946289 | CLS Loss: 0.00849067885428667\n",
      "Epoch 195 / 200 | iteration 60 / 171 | Total Loss: 3.591521978378296 | KNN Loss: 3.569810390472412 | CLS Loss: 0.021711556240916252\n",
      "Epoch 195 / 200 | iteration 70 / 171 | Total Loss: 3.678966522216797 | KNN Loss: 3.657069444656372 | CLS Loss: 0.02189711295068264\n",
      "Epoch 195 / 200 | iteration 80 / 171 | Total Loss: 3.5932834148406982 | KNN Loss: 3.58587384223938 | CLS Loss: 0.007409479934722185\n",
      "Epoch 195 / 200 | iteration 90 / 171 | Total Loss: 3.586372137069702 | KNN Loss: 3.580914258956909 | CLS Loss: 0.005457965191453695\n",
      "Epoch 195 / 200 | iteration 100 / 171 | Total Loss: 3.6273717880249023 | KNN Loss: 3.606602907180786 | CLS Loss: 0.02076887898147106\n",
      "Epoch 195 / 200 | iteration 110 / 171 | Total Loss: 3.594736099243164 | KNN Loss: 3.573357105255127 | CLS Loss: 0.021379100158810616\n",
      "Epoch 195 / 200 | iteration 120 / 171 | Total Loss: 3.6468894481658936 | KNN Loss: 3.638850688934326 | CLS Loss: 0.008038661442697048\n",
      "Epoch 195 / 200 | iteration 130 / 171 | Total Loss: 3.6332967281341553 | KNN Loss: 3.620990753173828 | CLS Loss: 0.012305868789553642\n",
      "Epoch 195 / 200 | iteration 140 / 171 | Total Loss: 3.5934479236602783 | KNN Loss: 3.5865390300750732 | CLS Loss: 0.006908929906785488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195 / 200 | iteration 150 / 171 | Total Loss: 3.6351470947265625 | KNN Loss: 3.6327919960021973 | CLS Loss: 0.0023551343474537134\n",
      "Epoch 195 / 200 | iteration 160 / 171 | Total Loss: 3.559770345687866 | KNN Loss: 3.5528485774993896 | CLS Loss: 0.0069217742420732975\n",
      "Epoch 195 / 200 | iteration 170 / 171 | Total Loss: 3.5854344367980957 | KNN Loss: 3.576892375946045 | CLS Loss: 0.008541978895664215\n",
      "Epoch: 195, Loss: 3.6105, Train: 0.9979, Valid: 0.9871, Best: 0.9881\n",
      "Epoch 196 / 200 | iteration 0 / 171 | Total Loss: 3.591273784637451 | KNN Loss: 3.5829689502716064 | CLS Loss: 0.008304794318974018\n",
      "Epoch 196 / 200 | iteration 10 / 171 | Total Loss: 3.5628163814544678 | KNN Loss: 3.5591280460357666 | CLS Loss: 0.0036883633583784103\n",
      "Epoch 196 / 200 | iteration 20 / 171 | Total Loss: 3.576659917831421 | KNN Loss: 3.5755321979522705 | CLS Loss: 0.0011278289603069425\n",
      "Epoch 196 / 200 | iteration 30 / 171 | Total Loss: 3.5898005962371826 | KNN Loss: 3.5870003700256348 | CLS Loss: 0.0028003354091197252\n",
      "Epoch 196 / 200 | iteration 40 / 171 | Total Loss: 3.579240560531616 | KNN Loss: 3.5702009201049805 | CLS Loss: 0.009039569646120071\n",
      "Epoch 196 / 200 | iteration 50 / 171 | Total Loss: 3.5830113887786865 | KNN Loss: 3.564150810241699 | CLS Loss: 0.018860571086406708\n",
      "Epoch 196 / 200 | iteration 60 / 171 | Total Loss: 3.603912115097046 | KNN Loss: 3.595101833343506 | CLS Loss: 0.008810190483927727\n",
      "Epoch 196 / 200 | iteration 70 / 171 | Total Loss: 3.6362144947052 | KNN Loss: 3.625880718231201 | CLS Loss: 0.010333792306482792\n",
      "Epoch 196 / 200 | iteration 80 / 171 | Total Loss: 3.6421408653259277 | KNN Loss: 3.6290969848632812 | CLS Loss: 0.013043776154518127\n",
      "Epoch 196 / 200 | iteration 90 / 171 | Total Loss: 3.594776153564453 | KNN Loss: 3.590282440185547 | CLS Loss: 0.004493614658713341\n",
      "Epoch 196 / 200 | iteration 100 / 171 | Total Loss: 3.604109287261963 | KNN Loss: 3.5888524055480957 | CLS Loss: 0.015256858430802822\n",
      "Epoch 196 / 200 | iteration 110 / 171 | Total Loss: 3.6190059185028076 | KNN Loss: 3.5781240463256836 | CLS Loss: 0.04088176041841507\n",
      "Epoch 196 / 200 | iteration 120 / 171 | Total Loss: 3.60762882232666 | KNN Loss: 3.5974223613739014 | CLS Loss: 0.010206579230725765\n",
      "Epoch 196 / 200 | iteration 130 / 171 | Total Loss: 3.6616644859313965 | KNN Loss: 3.627126693725586 | CLS Loss: 0.03453779220581055\n",
      "Epoch 196 / 200 | iteration 140 / 171 | Total Loss: 3.6112897396087646 | KNN Loss: 3.6032745838165283 | CLS Loss: 0.008015187457203865\n",
      "Epoch 196 / 200 | iteration 150 / 171 | Total Loss: 3.639145851135254 | KNN Loss: 3.629099130630493 | CLS Loss: 0.010046643204987049\n",
      "Epoch 196 / 200 | iteration 160 / 171 | Total Loss: 3.606428861618042 | KNN Loss: 3.60014271736145 | CLS Loss: 0.006286154966801405\n",
      "Epoch 196 / 200 | iteration 170 / 171 | Total Loss: 3.6122424602508545 | KNN Loss: 3.6058244705200195 | CLS Loss: 0.006418000441044569\n",
      "Epoch: 196, Loss: 3.6055, Train: 0.9973, Valid: 0.9866, Best: 0.9881\n",
      "Epoch 197 / 200 | iteration 0 / 171 | Total Loss: 3.602809429168701 | KNN Loss: 3.5981380939483643 | CLS Loss: 0.0046714115887880325\n",
      "Epoch 197 / 200 | iteration 10 / 171 | Total Loss: 3.6113717555999756 | KNN Loss: 3.6089372634887695 | CLS Loss: 0.0024344634730368853\n",
      "Epoch 197 / 200 | iteration 20 / 171 | Total Loss: 3.635152816772461 | KNN Loss: 3.633934736251831 | CLS Loss: 0.0012179628247395158\n",
      "Epoch 197 / 200 | iteration 30 / 171 | Total Loss: 3.6009979248046875 | KNN Loss: 3.595533847808838 | CLS Loss: 0.005464107729494572\n",
      "Epoch 197 / 200 | iteration 40 / 171 | Total Loss: 3.604410409927368 | KNN Loss: 3.594741106033325 | CLS Loss: 0.009669418446719646\n",
      "Epoch 197 / 200 | iteration 50 / 171 | Total Loss: 3.6707167625427246 | KNN Loss: 3.665623664855957 | CLS Loss: 0.005093061365187168\n",
      "Epoch 197 / 200 | iteration 60 / 171 | Total Loss: 3.5817227363586426 | KNN Loss: 3.5768823623657227 | CLS Loss: 0.004840286448597908\n",
      "Epoch 197 / 200 | iteration 70 / 171 | Total Loss: 3.6234593391418457 | KNN Loss: 3.6129415035247803 | CLS Loss: 0.010517722927033901\n",
      "Epoch 197 / 200 | iteration 80 / 171 | Total Loss: 3.640970230102539 | KNN Loss: 3.629092216491699 | CLS Loss: 0.011877895332872868\n",
      "Epoch 197 / 200 | iteration 90 / 171 | Total Loss: 3.6101460456848145 | KNN Loss: 3.6061294078826904 | CLS Loss: 0.004016689956188202\n",
      "Epoch 197 / 200 | iteration 100 / 171 | Total Loss: 3.6210007667541504 | KNN Loss: 3.6060569286346436 | CLS Loss: 0.014943760819733143\n",
      "Epoch 197 / 200 | iteration 110 / 171 | Total Loss: 3.577092170715332 | KNN Loss: 3.5727946758270264 | CLS Loss: 0.004297472070902586\n",
      "Epoch 197 / 200 | iteration 120 / 171 | Total Loss: 3.628653049468994 | KNN Loss: 3.6187126636505127 | CLS Loss: 0.009940452873706818\n",
      "Epoch 197 / 200 | iteration 130 / 171 | Total Loss: 3.5695343017578125 | KNN Loss: 3.5679092407226562 | CLS Loss: 0.0016251615015789866\n",
      "Epoch 197 / 200 | iteration 140 / 171 | Total Loss: 3.596686840057373 | KNN Loss: 3.588073253631592 | CLS Loss: 0.008613507263362408\n",
      "Epoch 197 / 200 | iteration 150 / 171 | Total Loss: 3.575948476791382 | KNN Loss: 3.563448429107666 | CLS Loss: 0.01250006165355444\n",
      "Epoch 197 / 200 | iteration 160 / 171 | Total Loss: 3.613879442214966 | KNN Loss: 3.604475259780884 | CLS Loss: 0.009404084645211697\n",
      "Epoch 197 / 200 | iteration 170 / 171 | Total Loss: 3.574302911758423 | KNN Loss: 3.568068027496338 | CLS Loss: 0.006234954576939344\n",
      "Epoch: 197, Loss: 3.6058, Train: 0.9974, Valid: 0.9872, Best: 0.9881\n",
      "Epoch 198 / 200 | iteration 0 / 171 | Total Loss: 3.6300125122070312 | KNN Loss: 3.6112000942230225 | CLS Loss: 0.018812445923686028\n",
      "Epoch 198 / 200 | iteration 10 / 171 | Total Loss: 3.561231851577759 | KNN Loss: 3.550812244415283 | CLS Loss: 0.01041954942047596\n",
      "Epoch 198 / 200 | iteration 20 / 171 | Total Loss: 3.619814395904541 | KNN Loss: 3.616856813430786 | CLS Loss: 0.002957673044875264\n",
      "Epoch 198 / 200 | iteration 30 / 171 | Total Loss: 3.60837721824646 | KNN Loss: 3.6017298698425293 | CLS Loss: 0.0066474131308496\n",
      "Epoch 198 / 200 | iteration 40 / 171 | Total Loss: 3.629747152328491 | KNN Loss: 3.6216466426849365 | CLS Loss: 0.008100582286715508\n",
      "Epoch 198 / 200 | iteration 50 / 171 | Total Loss: 3.6389265060424805 | KNN Loss: 3.6177468299865723 | CLS Loss: 0.02117975428700447\n",
      "Epoch 198 / 200 | iteration 60 / 171 | Total Loss: 3.638693332672119 | KNN Loss: 3.6299667358398438 | CLS Loss: 0.008726605214178562\n",
      "Epoch 198 / 200 | iteration 70 / 171 | Total Loss: 3.5928680896759033 | KNN Loss: 3.5887107849121094 | CLS Loss: 0.004157373681664467\n",
      "Epoch 198 / 200 | iteration 80 / 171 | Total Loss: 3.5977516174316406 | KNN Loss: 3.5824131965637207 | CLS Loss: 0.015338389202952385\n",
      "Epoch 198 / 200 | iteration 90 / 171 | Total Loss: 3.6472532749176025 | KNN Loss: 3.643529176712036 | CLS Loss: 0.003724011592566967\n",
      "Epoch 198 / 200 | iteration 100 / 171 | Total Loss: 3.580824613571167 | KNN Loss: 3.5725114345550537 | CLS Loss: 0.008313106372952461\n",
      "Epoch 198 / 200 | iteration 110 / 171 | Total Loss: 3.61367130279541 | KNN Loss: 3.608093500137329 | CLS Loss: 0.005577703472226858\n",
      "Epoch 198 / 200 | iteration 120 / 171 | Total Loss: 3.637253999710083 | KNN Loss: 3.599992036819458 | CLS Loss: 0.037261929363012314\n",
      "Epoch 198 / 200 | iteration 130 / 171 | Total Loss: 3.5985934734344482 | KNN Loss: 3.5908291339874268 | CLS Loss: 0.007764293812215328\n",
      "Epoch 198 / 200 | iteration 140 / 171 | Total Loss: 3.6594603061676025 | KNN Loss: 3.649927854537964 | CLS Loss: 0.009532500989735126\n",
      "Epoch 198 / 200 | iteration 150 / 171 | Total Loss: 3.6176540851593018 | KNN Loss: 3.5959999561309814 | CLS Loss: 0.021654164418578148\n",
      "Epoch 198 / 200 | iteration 160 / 171 | Total Loss: 3.66011905670166 | KNN Loss: 3.6381516456604004 | CLS Loss: 0.02196735143661499\n",
      "Epoch 198 / 200 | iteration 170 / 171 | Total Loss: 3.603238582611084 | KNN Loss: 3.5801005363464355 | CLS Loss: 0.023138107731938362\n",
      "Epoch: 198, Loss: 3.6047, Train: 0.9959, Valid: 0.9856, Best: 0.9881\n",
      "Epoch 199 / 200 | iteration 0 / 171 | Total Loss: 3.6051290035247803 | KNN Loss: 3.5905582904815674 | CLS Loss: 0.014570639468729496\n",
      "Epoch 199 / 200 | iteration 10 / 171 | Total Loss: 3.6015424728393555 | KNN Loss: 3.5988550186157227 | CLS Loss: 0.0026875343173742294\n",
      "Epoch 199 / 200 | iteration 20 / 171 | Total Loss: 3.6382040977478027 | KNN Loss: 3.635601758956909 | CLS Loss: 0.002602341817691922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 / 200 | iteration 30 / 171 | Total Loss: 3.6455960273742676 | KNN Loss: 3.640336275100708 | CLS Loss: 0.005259797442704439\n",
      "Epoch 199 / 200 | iteration 40 / 171 | Total Loss: 3.6235580444335938 | KNN Loss: 3.5912466049194336 | CLS Loss: 0.032311420887708664\n",
      "Epoch 199 / 200 | iteration 50 / 171 | Total Loss: 3.664645195007324 | KNN Loss: 3.6504340171813965 | CLS Loss: 0.014211189933121204\n",
      "Epoch 199 / 200 | iteration 60 / 171 | Total Loss: 3.5963103771209717 | KNN Loss: 3.581380605697632 | CLS Loss: 0.014929704368114471\n",
      "Epoch 199 / 200 | iteration 70 / 171 | Total Loss: 3.5769057273864746 | KNN Loss: 3.571948766708374 | CLS Loss: 0.004956903867423534\n",
      "Epoch 199 / 200 | iteration 80 / 171 | Total Loss: 3.5752196311950684 | KNN Loss: 3.5630714893341064 | CLS Loss: 0.012148236855864525\n",
      "Epoch 199 / 200 | iteration 90 / 171 | Total Loss: 3.600748062133789 | KNN Loss: 3.584953546524048 | CLS Loss: 0.015794595703482628\n",
      "Epoch 199 / 200 | iteration 100 / 171 | Total Loss: 3.5609066486358643 | KNN Loss: 3.5592164993286133 | CLS Loss: 0.0016901083290576935\n",
      "Epoch 199 / 200 | iteration 110 / 171 | Total Loss: 3.6098968982696533 | KNN Loss: 3.607590913772583 | CLS Loss: 0.0023060294333845377\n",
      "Epoch 199 / 200 | iteration 120 / 171 | Total Loss: 3.6072940826416016 | KNN Loss: 3.599916696548462 | CLS Loss: 0.007377433590590954\n",
      "Epoch 199 / 200 | iteration 130 / 171 | Total Loss: 3.6072261333465576 | KNN Loss: 3.59676194190979 | CLS Loss: 0.010464091785252094\n",
      "Epoch 199 / 200 | iteration 140 / 171 | Total Loss: 3.6068568229675293 | KNN Loss: 3.603053331375122 | CLS Loss: 0.0038034894969314337\n",
      "Epoch 199 / 200 | iteration 150 / 171 | Total Loss: 3.5893545150756836 | KNN Loss: 3.579899311065674 | CLS Loss: 0.00945526733994484\n",
      "Epoch 199 / 200 | iteration 160 / 171 | Total Loss: 3.6617612838745117 | KNN Loss: 3.6474761962890625 | CLS Loss: 0.014285112731158733\n",
      "Epoch 199 / 200 | iteration 170 / 171 | Total Loss: 3.641714572906494 | KNN Loss: 3.624654769897461 | CLS Loss: 0.017059797421097755\n",
      "Epoch: 199, Loss: 3.6058, Train: 0.9966, Valid: 0.9861, Best: 0.9881\n",
      "Epoch 200 / 200 | iteration 0 / 171 | Total Loss: 3.663025379180908 | KNN Loss: 3.6427297592163086 | CLS Loss: 0.02029573544859886\n",
      "Epoch 200 / 200 | iteration 10 / 171 | Total Loss: 3.6030116081237793 | KNN Loss: 3.5971028804779053 | CLS Loss: 0.005908660590648651\n",
      "Epoch 200 / 200 | iteration 20 / 171 | Total Loss: 3.6363701820373535 | KNN Loss: 3.634561061859131 | CLS Loss: 0.0018092385726049542\n",
      "Epoch 200 / 200 | iteration 30 / 171 | Total Loss: 3.657299757003784 | KNN Loss: 3.642613172531128 | CLS Loss: 0.014686555601656437\n",
      "Epoch 200 / 200 | iteration 40 / 171 | Total Loss: 3.5854640007019043 | KNN Loss: 3.576490640640259 | CLS Loss: 0.008973478339612484\n",
      "Epoch 200 / 200 | iteration 50 / 171 | Total Loss: 3.703080654144287 | KNN Loss: 3.689669132232666 | CLS Loss: 0.013411560095846653\n",
      "Epoch 200 / 200 | iteration 60 / 171 | Total Loss: 3.598203659057617 | KNN Loss: 3.5909690856933594 | CLS Loss: 0.007234528660774231\n",
      "Epoch 200 / 200 | iteration 70 / 171 | Total Loss: 3.6287455558776855 | KNN Loss: 3.6251399517059326 | CLS Loss: 0.003605698235332966\n",
      "Epoch 200 / 200 | iteration 80 / 171 | Total Loss: 3.6034557819366455 | KNN Loss: 3.5916266441345215 | CLS Loss: 0.011829252354800701\n",
      "Epoch 200 / 200 | iteration 90 / 171 | Total Loss: 3.556978940963745 | KNN Loss: 3.555860996246338 | CLS Loss: 0.0011178901186212897\n",
      "Epoch 200 / 200 | iteration 100 / 171 | Total Loss: 3.593904495239258 | KNN Loss: 3.589479684829712 | CLS Loss: 0.004424807149916887\n",
      "Epoch 200 / 200 | iteration 110 / 171 | Total Loss: 3.5614829063415527 | KNN Loss: 3.551861524581909 | CLS Loss: 0.009621307253837585\n",
      "Epoch 200 / 200 | iteration 120 / 171 | Total Loss: 3.580400228500366 | KNN Loss: 3.577827215194702 | CLS Loss: 0.0025729606859385967\n",
      "Epoch 200 / 200 | iteration 130 / 171 | Total Loss: 3.6124672889709473 | KNN Loss: 3.596529722213745 | CLS Loss: 0.0159376822412014\n",
      "Epoch 200 / 200 | iteration 140 / 171 | Total Loss: 3.5643725395202637 | KNN Loss: 3.560734748840332 | CLS Loss: 0.003637847723439336\n",
      "Epoch 200 / 200 | iteration 150 / 171 | Total Loss: 3.5931763648986816 | KNN Loss: 3.585742473602295 | CLS Loss: 0.007433893159031868\n",
      "Epoch 200 / 200 | iteration 160 / 171 | Total Loss: 3.688502311706543 | KNN Loss: 3.678574800491333 | CLS Loss: 0.009927397593855858\n",
      "Epoch 200 / 200 | iteration 170 / 171 | Total Loss: 3.5682225227355957 | KNN Loss: 3.563826084136963 | CLS Loss: 0.004396550823003054\n",
      "Epoch: 200, Loss: 3.6001, Train: 0.9981, Valid: 0.9870, Best: 0.9881\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9870, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b103168d4141f9ab922145ce34cb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9488ae6008f433f8f8098a5ac5a709b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1911620b53d149aeb6d24a0fdfc4f0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9027ffe442a7477895a326dafe8c918a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f23081608041e3b0d88924f5bebd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.9703074322781051\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33ab0c68710406fbf36b187807d5d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "layer 7: 0.0\n",
      "layer 8: 0.0\n",
      "layer 9: 0.0\n",
      "layer 10: 0.0\n",
      "Epoch: 00 | Batch: 000 / 042 | Total loss: 1.627 | Reg loss: 0.014 | Tree loss: 1.627 | Accuracy: 0.072266 | 3.746 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 01 | Batch: 000 / 042 | Total loss: 1.587 | Reg loss: 0.006 | Tree loss: 1.587 | Accuracy: 0.429688 | 3.663 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 02 | Batch: 000 / 042 | Total loss: 1.569 | Reg loss: 0.008 | Tree loss: 1.569 | Accuracy: 0.445312 | 3.661 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 03 | Batch: 000 / 042 | Total loss: 1.540 | Reg loss: 0.009 | Tree loss: 1.540 | Accuracy: 0.441406 | 3.669 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 04 | Batch: 000 / 042 | Total loss: 1.481 | Reg loss: 0.010 | Tree loss: 1.481 | Accuracy: 0.460938 | 3.715 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 05 | Batch: 000 / 042 | Total loss: 1.437 | Reg loss: 0.011 | Tree loss: 1.437 | Accuracy: 0.501953 | 3.763 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 06 | Batch: 000 / 042 | Total loss: 1.404 | Reg loss: 0.011 | Tree loss: 1.404 | Accuracy: 0.490234 | 3.794 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 07 | Batch: 000 / 042 | Total loss: 1.341 | Reg loss: 0.011 | Tree loss: 1.341 | Accuracy: 0.580078 | 3.813 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 08 | Batch: 000 / 042 | Total loss: 1.374 | Reg loss: 0.011 | Tree loss: 1.374 | Accuracy: 0.503906 | 3.827 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 09 | Batch: 000 / 042 | Total loss: 1.367 | Reg loss: 0.012 | Tree loss: 1.367 | Accuracy: 0.511719 | 3.838 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 10 | Batch: 000 / 042 | Total loss: 1.282 | Reg loss: 0.012 | Tree loss: 1.282 | Accuracy: 0.582031 | 3.848 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 11 | Batch: 000 / 042 | Total loss: 1.298 | Reg loss: 0.012 | Tree loss: 1.298 | Accuracy: 0.572266 | 3.855 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 12 | Batch: 000 / 042 | Total loss: 1.317 | Reg loss: 0.012 | Tree loss: 1.317 | Accuracy: 0.554688 | 3.862 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 13 | Batch: 000 / 042 | Total loss: 1.244 | Reg loss: 0.013 | Tree loss: 1.244 | Accuracy: 0.607422 | 3.868 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 14 | Batch: 000 / 042 | Total loss: 1.238 | Reg loss: 0.013 | Tree loss: 1.238 | Accuracy: 0.601562 | 3.873 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 15 | Batch: 000 / 042 | Total loss: 1.233 | Reg loss: 0.013 | Tree loss: 1.233 | Accuracy: 0.597656 | 3.876 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 16 | Batch: 000 / 042 | Total loss: 1.226 | Reg loss: 0.013 | Tree loss: 1.226 | Accuracy: 0.607422 | 3.879 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 17 | Batch: 000 / 042 | Total loss: 1.245 | Reg loss: 0.013 | Tree loss: 1.245 | Accuracy: 0.591797 | 3.882 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 18 | Batch: 000 / 042 | Total loss: 1.263 | Reg loss: 0.014 | Tree loss: 1.263 | Accuracy: 0.560547 | 3.886 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 19 | Batch: 000 / 042 | Total loss: 1.232 | Reg loss: 0.014 | Tree loss: 1.232 | Accuracy: 0.587891 | 3.888 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 20 | Batch: 000 / 042 | Total loss: 1.231 | Reg loss: 0.014 | Tree loss: 1.231 | Accuracy: 0.574219 | 3.89 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 21 | Batch: 000 / 042 | Total loss: 1.200 | Reg loss: 0.014 | Tree loss: 1.200 | Accuracy: 0.595703 | 3.892 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 22 | Batch: 000 / 042 | Total loss: 1.204 | Reg loss: 0.014 | Tree loss: 1.204 | Accuracy: 0.585938 | 3.895 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 23 | Batch: 000 / 042 | Total loss: 1.209 | Reg loss: 0.014 | Tree loss: 1.209 | Accuracy: 0.585938 | 3.897 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 24 | Batch: 000 / 042 | Total loss: 1.211 | Reg loss: 0.014 | Tree loss: 1.211 | Accuracy: 0.603516 | 3.899 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 25 | Batch: 000 / 042 | Total loss: 1.172 | Reg loss: 0.014 | Tree loss: 1.172 | Accuracy: 0.630859 | 3.901 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 26 | Batch: 000 / 042 | Total loss: 1.229 | Reg loss: 0.014 | Tree loss: 1.229 | Accuracy: 0.566406 | 3.903 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 27 | Batch: 000 / 042 | Total loss: 1.205 | Reg loss: 0.014 | Tree loss: 1.205 | Accuracy: 0.578125 | 3.905 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 28 | Batch: 000 / 042 | Total loss: 1.136 | Reg loss: 0.015 | Tree loss: 1.136 | Accuracy: 0.642578 | 3.906 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 29 | Batch: 000 / 042 | Total loss: 1.149 | Reg loss: 0.015 | Tree loss: 1.149 | Accuracy: 0.630859 | 3.908 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 30 | Batch: 000 / 042 | Total loss: 1.196 | Reg loss: 0.015 | Tree loss: 1.196 | Accuracy: 0.605469 | 3.909 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 31 | Batch: 000 / 042 | Total loss: 1.196 | Reg loss: 0.015 | Tree loss: 1.196 | Accuracy: 0.591797 | 3.911 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 32 | Batch: 000 / 042 | Total loss: 1.184 | Reg loss: 0.015 | Tree loss: 1.184 | Accuracy: 0.617188 | 3.912 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 33 | Batch: 000 / 042 | Total loss: 1.172 | Reg loss: 0.015 | Tree loss: 1.172 | Accuracy: 0.615234 | 3.913 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 34 | Batch: 000 / 042 | Total loss: 1.214 | Reg loss: 0.015 | Tree loss: 1.214 | Accuracy: 0.613281 | 3.913 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Batch: 000 / 042 | Total loss: 1.214 | Reg loss: 0.015 | Tree loss: 1.214 | Accuracy: 0.607422 | 3.915 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 36 | Batch: 000 / 042 | Total loss: 1.184 | Reg loss: 0.015 | Tree loss: 1.184 | Accuracy: 0.615234 | 3.915 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 37 | Batch: 000 / 042 | Total loss: 1.249 | Reg loss: 0.015 | Tree loss: 1.249 | Accuracy: 0.582031 | 3.916 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 38 | Batch: 000 / 042 | Total loss: 1.163 | Reg loss: 0.014 | Tree loss: 1.163 | Accuracy: 0.626953 | 3.917 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 39 | Batch: 000 / 042 | Total loss: 1.163 | Reg loss: 0.014 | Tree loss: 1.163 | Accuracy: 0.628906 | 3.917 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 40 | Batch: 000 / 042 | Total loss: 1.211 | Reg loss: 0.014 | Tree loss: 1.211 | Accuracy: 0.611328 | 3.918 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 41 | Batch: 000 / 042 | Total loss: 1.180 | Reg loss: 0.014 | Tree loss: 1.180 | Accuracy: 0.630859 | 3.919 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 42 | Batch: 000 / 042 | Total loss: 1.116 | Reg loss: 0.014 | Tree loss: 1.116 | Accuracy: 0.669922 | 3.919 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 43 | Batch: 000 / 042 | Total loss: 1.194 | Reg loss: 0.014 | Tree loss: 1.194 | Accuracy: 0.605469 | 3.921 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 44 | Batch: 000 / 042 | Total loss: 1.181 | Reg loss: 0.014 | Tree loss: 1.181 | Accuracy: 0.611328 | 3.921 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 45 | Batch: 000 / 042 | Total loss: 1.188 | Reg loss: 0.014 | Tree loss: 1.188 | Accuracy: 0.615234 | 3.921 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 46 | Batch: 000 / 042 | Total loss: 1.205 | Reg loss: 0.014 | Tree loss: 1.205 | Accuracy: 0.597656 | 3.922 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 47 | Batch: 000 / 042 | Total loss: 1.115 | Reg loss: 0.014 | Tree loss: 1.115 | Accuracy: 0.667969 | 3.922 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 48 | Batch: 000 / 042 | Total loss: 1.204 | Reg loss: 0.014 | Tree loss: 1.204 | Accuracy: 0.617188 | 3.923 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 49 | Batch: 000 / 042 | Total loss: 1.159 | Reg loss: 0.014 | Tree loss: 1.159 | Accuracy: 0.638672 | 3.923 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 50 | Batch: 000 / 042 | Total loss: 1.189 | Reg loss: 0.014 | Tree loss: 1.189 | Accuracy: 0.621094 | 3.923 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 51 | Batch: 000 / 042 | Total loss: 1.153 | Reg loss: 0.014 | Tree loss: 1.153 | Accuracy: 0.623047 | 3.924 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 52 | Batch: 000 / 042 | Total loss: 1.210 | Reg loss: 0.014 | Tree loss: 1.210 | Accuracy: 0.628906 | 3.924 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 | Batch: 000 / 042 | Total loss: 1.147 | Reg loss: 0.014 | Tree loss: 1.147 | Accuracy: 0.640625 | 3.924 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 54 | Batch: 000 / 042 | Total loss: 1.218 | Reg loss: 0.014 | Tree loss: 1.218 | Accuracy: 0.599609 | 3.924 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 55 | Batch: 000 / 042 | Total loss: 1.238 | Reg loss: 0.014 | Tree loss: 1.238 | Accuracy: 0.585938 | 3.925 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 56 | Batch: 000 / 042 | Total loss: 1.121 | Reg loss: 0.014 | Tree loss: 1.121 | Accuracy: 0.662109 | 3.925 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 57 | Batch: 000 / 042 | Total loss: 1.124 | Reg loss: 0.014 | Tree loss: 1.124 | Accuracy: 0.666016 | 3.925 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 58 | Batch: 000 / 042 | Total loss: 1.159 | Reg loss: 0.014 | Tree loss: 1.159 | Accuracy: 0.617188 | 3.926 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 59 | Batch: 000 / 042 | Total loss: 1.132 | Reg loss: 0.014 | Tree loss: 1.132 | Accuracy: 0.646484 | 3.926 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 60 | Batch: 000 / 042 | Total loss: 1.185 | Reg loss: 0.014 | Tree loss: 1.185 | Accuracy: 0.605469 | 3.926 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 61 | Batch: 000 / 042 | Total loss: 1.181 | Reg loss: 0.014 | Tree loss: 1.181 | Accuracy: 0.621094 | 3.926 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 62 | Batch: 000 / 042 | Total loss: 1.165 | Reg loss: 0.014 | Tree loss: 1.165 | Accuracy: 0.638672 | 3.926 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
